{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xefdNhESLXg-"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "## Instructions\n",
        "- Your submission should be the `.ipynb` file with your name,\n",
        "  like `YusufMesbah.ipynb`. it should include the answers to the questions in\n",
        "  markdown cells.\n",
        "- You are expected to follow the best practices for code writing and model\n",
        "training. Poor coding style will be penalized.\n",
        "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
        "Plagiarism in the code will result in failing. If you use code from the\n",
        "internet, cite it.\n",
        "- If the instructions seem vague, use common sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4VwnrHaeLXhB"
      },
      "source": [
        "# Task 1: ANN (30%)\n",
        "For this task, you are required to build a fully connect feed-forward ANN model\n",
        "for a multi-label regression problem.\n",
        "\n",
        "For the given data, you need do proper data preprocessing, design the ANN model,\n",
        "then fine-tune your model architecture (number of layers, number of neurons,\n",
        "activation function, learning rate, momentum, regularization).\n",
        "\n",
        "For evaluating your model, do $80/20$ train test split.\n",
        "\n",
        "### Data\n",
        "You will be working with the data in `Task 1.csv` for predicting students'\n",
        "scores in 3 different exams: math, reading and writing. The columns include:\n",
        " - gender\n",
        " - race\n",
        " - parental level of education\n",
        " - lunch meal plan at school\n",
        " - whether the student undertook the test preparation course"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "#Numpy: Used for getting random values for hyper-parameter tuning\n",
        "import numpy as np\n",
        "\n",
        "#Pandas: Used for loading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "#Sklearn: Used for data preparation \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "#Pytorch: Used for ANN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "gMIyr45wAJB2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the dataset\n",
        "\n",
        "df = pd.read_csv(\"Task 1.csv\")\n",
        "print(f'number of entries: {len(df)}')\n",
        "print(f'columns: {[column for column in df.columns]}')\n",
        "features = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
        "targets = ['math score', 'reading score', 'writing score']\n",
        "print(f\"features: {features}\")\n",
        "print(f\"targets: {targets}\")\n",
        "for feature in features:\n",
        "  values = df[feature].unique()\n",
        "  print(f'{feature}: {values}')"
      ],
      "metadata": {
        "id": "T8mzv0f_Bc-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406dc5b6-8d04-4f61-ce56-424e71ee74fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of entries: 1000\n",
            "columns: ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
            "features: ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
            "targets: ['math score', 'reading score', 'writing score']\n",
            "gender: ['male' 'female']\n",
            "race/ethnicity: ['group A' 'group D' 'group E' 'group B' 'group C']\n",
            "parental level of education: ['high school' 'some high school' 'some college' \"associate's degree\"\n",
            " \"bachelor's degree\" \"master's degree\"]\n",
            "lunch: ['standard' 'free/reduced']\n",
            "test preparation course: ['completed' 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation.\n",
        "#References: Lab 2, \n",
        "#            Assignment 1 submission\n",
        "\n",
        "#Features that have no natural ordered relationship\n",
        "onehot_features = {\n",
        "    'gender': ['male', 'female'],\n",
        "    'race/ethnicity': ['group A', 'group B', 'group C', 'group D', 'group E'] \n",
        "}\n",
        "#Features that have a natural ordered relationship\n",
        "ordinal_features = {\n",
        "    'parental level of education': ['some high school', 'high school', 'some college', \"associate's degree\", \"bachelor's degree\", \"master's degree\"],\n",
        "    'test preparation course': ['none', 'completed'],\n",
        "    'lunch': ['standard', 'free/reduced']\n",
        "}\n",
        "#note that test preparation course and lunch features will be represented in the same way whether they get encoded ordinally or with one hot method\n",
        "\n",
        "#Encoding categorical data\n",
        "def ordinal_encoder(df, feature_name, categories):\n",
        "  old_column = df[feature_name]\n",
        "  old_column = np.array(old_column).reshape(-1,1)\n",
        "  encoder = OrdinalEncoder(categories=[categories])\n",
        "  new_column = encoder.fit_transform(old_column)\n",
        "  new_column = pd.DataFrame(data=new_column, columns=[feature_name])\n",
        "  new_df = df.drop(feature_name, axis=1)\n",
        "  new_df = pd.concat([new_df, new_column], axis=1)\n",
        "  return new_df\n",
        "\n",
        "def onehot_encoder(df, features_names):\n",
        "  encoder = OneHotEncoder(sparse=False, drop='first') #encoder model imported from sklearn\n",
        "  new_columns = encoder.fit_transform(df[features_names])\n",
        "  new_columns = pd.DataFrame(new_columns, dtype=int, columns=encoder.get_feature_names_out(features_names))\n",
        "  new_df = df.drop(features_names, axis=1)\n",
        "  new_df = pd.concat([new_df, new_columns], axis=1)   \n",
        "\n",
        "  return new_df\n",
        "\n",
        "def categorical_encoder(df, ordinal_features, onehot_features):\n",
        "  new_df = df\n",
        "  for key, val in ordinal_features.items():\n",
        "    new_df = ordinal_encoder(new_df, key, val)\n",
        "  onehot_features_names = []\n",
        "  for key, val in onehot_features.items():\n",
        "    onehot_features_names.append(key)\n",
        "  new_df = onehot_encoder(new_df, onehot_features_names)\n",
        "  return new_df\n",
        "\n",
        "df = categorical_encoder(df=df, ordinal_features=ordinal_features, onehot_features=onehot_features)\n",
        "\n",
        "print(f'columns: {[column for column in df.columns]}')"
      ],
      "metadata": {
        "id": "_2fs6CE4Blrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7f6af5-c78c-4688-ca72-05672dc8727b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns: ['math score', 'reading score', 'writing score', 'parental level of education', 'test preparation course', 'lunch', 'gender_male', 'race/ethnicity_group B', 'race/ethnicity_group C', 'race/ethnicity_group D', 'race/ethnicity_group E']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting features and labels\n",
        "\n",
        "X = df.iloc[:, 3:].values #Features\n",
        "y = df.iloc[:, 0:3].values #Labels"
      ],
      "metadata": {
        "id": "7T5gLKUXBp-b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling\n",
        "\n",
        "def scaling(train, test, scaler=StandardScaler()):\n",
        "  scaler.fit(train)\n",
        "  train = scaler.transform(train)\n",
        "  test = scaler.transform(test)\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "V6JcArBQ3SRn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Custom Dataset in pytorch\n",
        "#Reference: Self Practice 7\n",
        "\n",
        "class CustumData(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super().__init__()\n",
        "    self.y = torch.tensor(y).float()\n",
        "    self.X = torch.tensor(X).float()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "tlTtBrifBtdX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NN Model\n",
        "#Reference: Lab 7 \n",
        "#           Lab 9\n",
        "#           https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html\n",
        "#           https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, units = 64, layers = 2, activation = nn.ReLU(), dropout = 0.25):\n",
        "    super(Net, self).__init__()\n",
        "    self.input = nn.Sequential(\n",
        "      nn.Linear(8 ,units),\n",
        "      activation\n",
        "    )\n",
        "    linear = nn.Sequential(\n",
        "      nn.Linear(units, units),\n",
        "      activation\n",
        "    )\n",
        "    self.linears = nn.ModuleList([linear for i in range(layers)])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.output = nn.Linear(units, 3)\n",
        "    \n",
        "  def forward(self, x):  \n",
        "    x = self.input(x)\n",
        "    for layer in self.linears:\n",
        "      x = layer(x)\n",
        "      x = self.dropout(x)\n",
        "    x = self.output(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "1iXI9PBxByoI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility\n",
        "\n",
        "def activation_function(name):\n",
        "  activation_dict = {\n",
        "    \"relu\": nn.ReLU(),\n",
        "    \"leaky\": nn.LeakyReLU(),\n",
        "    \"elu\": nn.ELU(),\n",
        "    \"hardswish\": nn.Hardswish(),\n",
        "    \"selu\": nn.SELU(),\n",
        "    \"silu\": nn.SiLU()\n",
        "  }\n",
        "  return activation_dict[name]\n"
      ],
      "metadata": {
        "id": "mdKfy8PtXeAK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training, Testing/Validation\n",
        "#Reference: Lab7\n",
        "\n",
        "def training(net, device, trainloader, criterion, optimizer):\n",
        "  #Training\n",
        "  net.train()\n",
        "  train_loss = 0.0\n",
        "  for data, targets in trainloader:\n",
        "    data = data.to(device).float()\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    outputs = net(data)\n",
        "\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item() * data.size(0)\n",
        "    \n",
        "  epoch_loss = train_loss / len(trainloader.dataset)\n",
        "  return epoch_loss\n",
        "\n",
        "def testing(net, device, testloader, criterion):\n",
        "  #Validation/Testing\n",
        "  net.eval()\n",
        "  test_loss = 0.0\n",
        "  for data, targets in testloader:\n",
        "    with torch.no_grad():\n",
        "      data = data.to(device).float()\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = net(data)\n",
        "\n",
        "      loss = criterion(outputs, targets)\n",
        "                \n",
        "      test_loss += loss.item() * data.size(0)\n",
        "      \n",
        "  epoch_loss = test_loss / len(testloader.dataset)\n",
        "  return epoch_loss\n",
        "\n",
        "def process(units, layers, active, lr, momentum, batch_size, dropout, epochs):\n",
        "  activation = activation_function(active)\n",
        "\n",
        "  net = Net(units, layers, activation, dropout)\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr, momentum)\n",
        "\n",
        "  criterion = nn.L1Loss()  \n",
        "\n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  \n",
        "  net.to(device)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2) #split 80/20\n",
        "\n",
        "  X_train, X_test = scaling(X_train, X_test, StandardScaler())\n",
        "\n",
        "  trainset = CustumData(X_train, y_train)\n",
        "  testset = CustumData(X_test, y_test) \n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  min_loss = 4*11*1001\n",
        "  log_interval = 50\n",
        "  for epoch in range(epochs):\n",
        "    train_loss= training(net, device, trainloader, criterion, optimizer)\n",
        "    val_loss = testing(net, device, testloader, criterion)\n",
        "    if epoch%log_interval == 0 or epoch == epochs-1:\n",
        "      print('---------------------------------------------------\\n')\n",
        "      print(f'Epoch {epoch+1}/{epochs}:')\n",
        "      print(f'Train:')\n",
        "      print(f'\\tLoss: {train_loss}')  \n",
        "      print(f'Validation:')\n",
        "      print(f'\\tLoss: {val_loss}\\n')\n",
        "      print('---------------------------------------------------')\n",
        "    if val_loss <= min_loss:\n",
        "      min_loss = val_loss\n",
        "\n",
        "  return min_loss"
      ],
      "metadata": {
        "id": "Vx1qwUBYB4gT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "03OfIyxULXhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861dd53f-32e9-434a-815f-b5c8c9a100bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.39689788818359\n",
            "Validation:\n",
            "\tLoss: 68.61956024169922\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.164575805664063\n",
            "Validation:\n",
            "\tLoss: 11.944896697998047\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.397598876953126\n",
            "Validation:\n",
            "\tLoss: 11.017986297607422\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 46/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.33331939697266\n",
            "Validation:\n",
            "\tLoss: 66.14340072631836\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 47/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.50859573364258\n",
            "Validation:\n",
            "\tLoss: 68.0019302368164\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 66.75657592773437\n",
            "Validation:\n",
            "\tLoss: 67.24838256835938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 63.158819580078124\n",
            "Validation:\n",
            "\tLoss: 63.613380432128906\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 48/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.26880249023438\n",
            "Validation:\n",
            "\tLoss: 67.3952767944336\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 16.489172592163087\n",
            "Validation:\n",
            "\tLoss: 14.722445106506347\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.51325912475586\n",
            "Validation:\n",
            "\tLoss: 11.340623512268067\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 49/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.22762084960938\n",
            "Validation:\n",
            "\tLoss: 66.28248809814453\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.65774917602539\n",
            "Validation:\n",
            "\tLoss: 10.785265998840332\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.483190803527831\n",
            "Validation:\n",
            "\tLoss: 10.465839309692383\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 50/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.19293487548828\n",
            "Validation:\n",
            "\tLoss: 68.76206329345703\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.162030372619629\n",
            "Validation:\n",
            "\tLoss: 9.490433387756347\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.723579139709473\n",
            "Validation:\n",
            "\tLoss: 9.531175060272217\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 51/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 56.04730690002442\n",
            "Validation:\n",
            "\tLoss: 37.69252700805664\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.65808864593506\n",
            "Validation:\n",
            "\tLoss: 11.130710792541503\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.614750862121582\n",
            "Validation:\n",
            "\tLoss: 11.51271411895752\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 52/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.53460418701172\n",
            "Validation:\n",
            "\tLoss: 64.800078125\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.994184532165526\n",
            "Validation:\n",
            "\tLoss: 10.879834747314453\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.661887893676758\n",
            "Validation:\n",
            "\tLoss: 10.539851531982421\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 53/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.5531655883789\n",
            "Validation:\n",
            "\tLoss: 64.39358734130859\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.714987602233887\n",
            "Validation:\n",
            "\tLoss: 11.345164909362794\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.308028526306153\n",
            "Validation:\n",
            "\tLoss: 10.862494888305664\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 54/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.12015869140625\n",
            "Validation:\n",
            "\tLoss: 69.37367248535156\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.987931251525879\n",
            "Validation:\n",
            "\tLoss: 12.255417823791504\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.018420219421387\n",
            "Validation:\n",
            "\tLoss: 10.381367683410645\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 55/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.04835678100586\n",
            "Validation:\n",
            "\tLoss: 66.00554473876953\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.514246978759765\n",
            "Validation:\n",
            "\tLoss: 10.754203910827636\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.401210632324219\n",
            "Validation:\n",
            "\tLoss: 11.230987854003907\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 56/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.78081695556641\n",
            "Validation:\n",
            "\tLoss: 67.36437225341797\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.677005271911622\n",
            "Validation:\n",
            "\tLoss: 10.698406219482422\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.776587944030762\n",
            "Validation:\n",
            "\tLoss: 10.7214994430542\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 57/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 63.62450408935547\n",
            "Validation:\n",
            "\tLoss: 55.73834091186524\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.082895011901856\n",
            "Validation:\n",
            "\tLoss: 11.557602882385254\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.792876167297363\n",
            "Validation:\n",
            "\tLoss: 11.224693222045898\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 58/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.46024520874023\n",
            "Validation:\n",
            "\tLoss: 67.8643310546875\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.866463317871094\n",
            "Validation:\n",
            "\tLoss: 10.955628356933595\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.940470733642577\n",
            "Validation:\n",
            "\tLoss: 11.133356647491455\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 59/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.30151275634766\n",
            "Validation:\n",
            "\tLoss: 67.01956939697266\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.182310523986816\n",
            "Validation:\n",
            "\tLoss: 10.976603507995605\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.646922721862794\n",
            "Validation:\n",
            "\tLoss: 11.074084281921387\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 60/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.58744598388672\n",
            "Validation:\n",
            "\tLoss: 68.06922149658203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.372911224365234\n",
            "Validation:\n",
            "\tLoss: 11.326659202575684\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.934596328735351\n",
            "Validation:\n",
            "\tLoss: 11.014556884765625\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 61/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.35667236328125\n",
            "Validation:\n",
            "\tLoss: 68.24665344238281\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.766961479187012\n",
            "Validation:\n",
            "\tLoss: 17.808099517822267\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.114725379943847\n",
            "Validation:\n",
            "\tLoss: 15.767510452270507\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 62/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.83810089111329\n",
            "Validation:\n",
            "\tLoss: 66.49943649291993\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.56702320098877\n",
            "Validation:\n",
            "\tLoss: 10.84018970489502\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.195264663696289\n",
            "Validation:\n",
            "\tLoss: 10.7784379196167\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 63/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.58020233154296\n",
            "Validation:\n",
            "\tLoss: 68.82377624511719\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 26.075714263916016\n",
            "Validation:\n",
            "\tLoss: 17.897552490234375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 15.389897575378418\n",
            "Validation:\n",
            "\tLoss: 17.246992111206055\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 64/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.61317504882813\n",
            "Validation:\n",
            "\tLoss: 67.49617004394531\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.976026573181151\n",
            "Validation:\n",
            "\tLoss: 11.378111801147462\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.718602027893066\n",
            "Validation:\n",
            "\tLoss: 11.194975814819337\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 65/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.47282501220702\n",
            "Validation:\n",
            "\tLoss: 68.2838119506836\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 66.82602447509765\n",
            "Validation:\n",
            "\tLoss: 67.63390350341797\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 65.90434112548829\n",
            "Validation:\n",
            "\tLoss: 66.7084881591797\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 66/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.85263809204102\n",
            "Validation:\n",
            "\tLoss: 66.00182510375977\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.813383045196533\n",
            "Validation:\n",
            "\tLoss: 12.300261573791504\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.533967266082763\n",
            "Validation:\n",
            "\tLoss: 10.106960716247558\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 67/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 68/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.67913940429688\n",
            "Validation:\n",
            "\tLoss: 67.06903839111328\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 25.954139633178713\n",
            "Validation:\n",
            "\tLoss: 21.740516662597656\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.333470497131348\n",
            "Validation:\n",
            "\tLoss: 12.869271278381348\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 69/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.54078857421875\n",
            "Validation:\n",
            "\tLoss: 67.90848541259766\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.22128318786621\n",
            "Validation:\n",
            "\tLoss: 12.190902709960938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.239219818115235\n",
            "Validation:\n",
            "\tLoss: 11.737828254699707\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 70/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.5057440185547\n",
            "Validation:\n",
            "\tLoss: 68.89888763427734\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 22.58064659118652\n",
            "Validation:\n",
            "\tLoss: 13.593094902038574\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 21.295665893554688\n",
            "Validation:\n",
            "\tLoss: 13.81538703918457\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 71/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 62.442855987548825\n",
            "Validation:\n",
            "\tLoss: 18.53237838745117\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.873826675415039\n",
            "Validation:\n",
            "\tLoss: 11.599071617126464\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.413985023498535\n",
            "Validation:\n",
            "\tLoss: 11.144626426696778\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 72/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.78057250976562\n",
            "Validation:\n",
            "\tLoss: 67.15757751464844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.46684913635254\n",
            "Validation:\n",
            "\tLoss: 10.946715354919434\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.25764747619629\n",
            "Validation:\n",
            "\tLoss: 10.7044677734375\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 73/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.31831237792969\n",
            "Validation:\n",
            "\tLoss: 66.86533905029297\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 74/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.91274810791016\n",
            "Validation:\n",
            "\tLoss: 64.67101135253907\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.441490516662597\n",
            "Validation:\n",
            "\tLoss: 11.382307243347167\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.20556484222412\n",
            "Validation:\n",
            "\tLoss: 11.376661567687988\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 75/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.32201232910157\n",
            "Validation:\n",
            "\tLoss: 69.09986633300781\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 65.42725128173828\n",
            "Validation:\n",
            "\tLoss: 67.16509124755859\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 34.00829246520996\n",
            "Validation:\n",
            "\tLoss: 23.00336326599121\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 76/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.44860305786133\n",
            "Validation:\n",
            "\tLoss: 67.40545928955078\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.549447746276856\n",
            "Validation:\n",
            "\tLoss: 11.099759788513184\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.242889900207519\n",
            "Validation:\n",
            "\tLoss: 10.196833267211915\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 77/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.7852978515625\n",
            "Validation:\n",
            "\tLoss: 67.28553649902344\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.518132209777832\n",
            "Validation:\n",
            "\tLoss: 11.796931037902832\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.222153129577636\n",
            "Validation:\n",
            "\tLoss: 10.938469543457032\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 78/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.68572448730468\n",
            "Validation:\n",
            "\tLoss: 65.83311920166015\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 16.5233557510376\n",
            "Validation:\n",
            "\tLoss: 11.74680404663086\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.580651588439942\n",
            "Validation:\n",
            "\tLoss: 11.386750755310059\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 79/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.33701080322265\n",
            "Validation:\n",
            "\tLoss: 67.00126647949219\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 21.37758743286133\n",
            "Validation:\n",
            "\tLoss: 12.47601318359375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 19.81514030456543\n",
            "Validation:\n",
            "\tLoss: 13.246563911437988\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 80/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.60517852783204\n",
            "Validation:\n",
            "\tLoss: 67.92179107666016\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.574092292785645\n",
            "Validation:\n",
            "\tLoss: 11.614176750183105\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.056876182556152\n",
            "Validation:\n",
            "\tLoss: 11.777785301208496\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 81/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.09597564697266\n",
            "Validation:\n",
            "\tLoss: 63.486355743408204\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 82/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.03205474853516\n",
            "Validation:\n",
            "\tLoss: 66.09429168701172\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 20.05113868713379\n",
            "Validation:\n",
            "\tLoss: 16.47234924316406\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 83/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.1052474975586\n",
            "Validation:\n",
            "\tLoss: 69.64593505859375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 50.30214965820313\n",
            "Validation:\n",
            "\tLoss: 52.78402328491211\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 33.537635803222656\n",
            "Validation:\n",
            "\tLoss: 36.09033966064453\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 84/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.70719024658203\n",
            "Validation:\n",
            "\tLoss: 67.16107696533203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.440817070007324\n",
            "Validation:\n",
            "\tLoss: 13.75543571472168\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.358297157287598\n",
            "Validation:\n",
            "\tLoss: 12.18100212097168\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 85/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.40989379882812\n",
            "Validation:\n",
            "\tLoss: 65.82919372558594\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.919172248840333\n",
            "Validation:\n",
            "\tLoss: 12.064263801574707\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.806907653808594\n",
            "Validation:\n",
            "\tLoss: 11.561226234436035\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 86/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.76097290039063\n",
            "Validation:\n",
            "\tLoss: 67.68597412109375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 27.905803451538088\n",
            "Validation:\n",
            "\tLoss: 10.476099014282227\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.97769172668457\n",
            "Validation:\n",
            "\tLoss: 10.340895652770996\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 87/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.2716195678711\n",
            "Validation:\n",
            "\tLoss: 69.31826141357422\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.15655216217041\n",
            "Validation:\n",
            "\tLoss: 12.012205848693847\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.145626106262206\n",
            "Validation:\n",
            "\tLoss: 10.762202415466309\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 88/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.18527862548828\n",
            "Validation:\n",
            "\tLoss: 66.96197235107422\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.84656951904297\n",
            "Validation:\n",
            "\tLoss: 10.918409233093263\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.165161437988282\n",
            "Validation:\n",
            "\tLoss: 10.998467330932618\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 89/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.65637298583984\n",
            "Validation:\n",
            "\tLoss: 67.05598846435547\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.616116104125975\n",
            "Validation:\n",
            "\tLoss: 11.426820716857911\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.249964294433592\n",
            "Validation:\n",
            "\tLoss: 12.969571342468262\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 90/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.61829544067383\n",
            "Validation:\n",
            "\tLoss: 57.90461990356445\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.877791175842285\n",
            "Validation:\n",
            "\tLoss: 10.336791038513184\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.76964443206787\n",
            "Validation:\n",
            "\tLoss: 10.277159996032715\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 91/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.09453308105469\n",
            "Validation:\n",
            "\tLoss: 67.52740844726563\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 44.52891616821289\n",
            "Validation:\n",
            "\tLoss: 45.324114685058596\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 24.11538948059082\n",
            "Validation:\n",
            "\tLoss: 24.921386642456056\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 92/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 93/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.90685943603516\n",
            "Validation:\n",
            "\tLoss: 65.17287048339844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.405067253112794\n",
            "Validation:\n",
            "\tLoss: 9.975372161865234\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.368279228210449\n",
            "Validation:\n",
            "\tLoss: 10.311307373046875\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 94/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.98987518310547\n",
            "Validation:\n",
            "\tLoss: 66.61485290527344\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.337266578674317\n",
            "Validation:\n",
            "\tLoss: 10.9232177734375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 15.127297325134277\n",
            "Validation:\n",
            "\tLoss: 10.127344131469727\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 95/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.53361724853515\n",
            "Validation:\n",
            "\tLoss: 68.2350082397461\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.164838447570801\n",
            "Validation:\n",
            "\tLoss: 10.628988265991211\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.75982723236084\n",
            "Validation:\n",
            "\tLoss: 11.276841163635254\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 96/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.06607376098633\n",
            "Validation:\n",
            "\tLoss: 68.31122711181641\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.720139808654785\n",
            "Validation:\n",
            "\tLoss: 9.940250358581544\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.443234519958496\n",
            "Validation:\n",
            "\tLoss: 10.027652740478516\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 97/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 60.49951820373535\n",
            "Validation:\n",
            "\tLoss: 16.17987533569336\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.055000915527344\n",
            "Validation:\n",
            "\tLoss: 11.450020027160644\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.59198429107666\n",
            "Validation:\n",
            "\tLoss: 10.5772896194458\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 98/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.68946044921876\n",
            "Validation:\n",
            "\tLoss: 68.03206634521484\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.23982707977295\n",
            "Validation:\n",
            "\tLoss: 12.313501358032227\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.870040283203124\n",
            "Validation:\n",
            "\tLoss: 10.965203285217285\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 99/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.24757934570313\n",
            "Validation:\n",
            "\tLoss: 66.18338775634766\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.533094787597655\n",
            "Validation:\n",
            "\tLoss: 12.028732299804688\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.819643936157227\n",
            "Validation:\n",
            "\tLoss: 10.86511516571045\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 100/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.4111099243164\n",
            "Validation:\n",
            "\tLoss: 68.31524993896484\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.379807243347168\n",
            "Validation:\n",
            "\tLoss: 11.60833137512207\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.17465015411377\n",
            "Validation:\n",
            "\tLoss: 10.616625022888183\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 101/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.77527130126953\n",
            "Validation:\n",
            "\tLoss: 67.85154327392578\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 67.11984466552734\n",
            "Validation:\n",
            "\tLoss: 67.19073272705079\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 65.58521514892578\n",
            "Validation:\n",
            "\tLoss: 65.64994018554688\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 102/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.56535202026367\n",
            "Validation:\n",
            "\tLoss: 67.69381713867188\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 103/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.82416778564453\n",
            "Validation:\n",
            "\tLoss: 67.23050689697266\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.259414558410645\n",
            "Validation:\n",
            "\tLoss: 12.309488296508789\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.77842586517334\n",
            "Validation:\n",
            "\tLoss: 12.45238208770752\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 104/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.15261444091797\n",
            "Validation:\n",
            "\tLoss: 68.41546844482421\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.94332275390625\n",
            "Validation:\n",
            "\tLoss: 11.009468231201172\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.35855312347412\n",
            "Validation:\n",
            "\tLoss: 10.825696907043458\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 105/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.52928314208984\n",
            "Validation:\n",
            "\tLoss: 67.31287384033203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.357823638916015\n",
            "Validation:\n",
            "\tLoss: 13.49484920501709\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.26806625366211\n",
            "Validation:\n",
            "\tLoss: 11.082311630249023\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 106/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.9869140625\n",
            "Validation:\n",
            "\tLoss: 66.52261352539062\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.660017890930176\n",
            "Validation:\n",
            "\tLoss: 11.277589797973633\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.373193130493163\n",
            "Validation:\n",
            "\tLoss: 11.021467208862305\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 107/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.92601654052734\n",
            "Validation:\n",
            "\tLoss: 67.14709655761719\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.789163246154786\n",
            "Validation:\n",
            "\tLoss: 11.453828887939453\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.183041725158692\n",
            "Validation:\n",
            "\tLoss: 11.067575225830078\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 108/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.3152944946289\n",
            "Validation:\n",
            "\tLoss: 69.61438293457032\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.729248085021972\n",
            "Validation:\n",
            "\tLoss: 11.830924224853515\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.467550354003906\n",
            "Validation:\n",
            "\tLoss: 11.404296417236328\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 109/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.08994781494141\n",
            "Validation:\n",
            "\tLoss: 66.15081024169922\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 67.52471282958984\n",
            "Validation:\n",
            "\tLoss: 65.58546447753906\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 66.86928924560547\n",
            "Validation:\n",
            "\tLoss: 64.92212677001953\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 110/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 54.52594703674316\n",
            "Validation:\n",
            "\tLoss: 13.515309104919433\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 111/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.72643188476563\n",
            "Validation:\n",
            "\tLoss: 67.73693084716797\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 21.449583053588867\n",
            "Validation:\n",
            "\tLoss: 12.093207359313965\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.904279403686523\n",
            "Validation:\n",
            "\tLoss: 11.633123397827148\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 112/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.47504501342773\n",
            "Validation:\n",
            "\tLoss: 54.593521423339844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 113/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.03375732421875\n",
            "Validation:\n",
            "\tLoss: 66.75074096679687\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 66.44868576049805\n",
            "Validation:\n",
            "\tLoss: 65.14499572753907\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.834131889343261\n",
            "Validation:\n",
            "\tLoss: 10.153583412170411\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 114/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.77682922363282\n",
            "Validation:\n",
            "\tLoss: 67.1683120727539\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 17.121332397460936\n",
            "Validation:\n",
            "\tLoss: 11.6112699508667\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.931563529968262\n",
            "Validation:\n",
            "\tLoss: 11.46408462524414\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 115/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.42420547485352\n",
            "Validation:\n",
            "\tLoss: 64.64160247802734\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.95132354736328\n",
            "Validation:\n",
            "\tLoss: 11.563817958831788\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.046891651153565\n",
            "Validation:\n",
            "\tLoss: 11.112275276184082\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 116/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.54973052978515\n",
            "Validation:\n",
            "\tLoss: 68.33409088134766\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.60216526031494\n",
            "Validation:\n",
            "\tLoss: 12.198339958190918\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.304590301513672\n",
            "Validation:\n",
            "\tLoss: 11.64917797088623\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 117/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.38850769042969\n",
            "Validation:\n",
            "\tLoss: 64.9758511352539\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.450836906433105\n",
            "Validation:\n",
            "\tLoss: 10.362602882385254\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.670331382751465\n",
            "Validation:\n",
            "\tLoss: 10.685098438262939\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 118/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.61240631103516\n",
            "Validation:\n",
            "\tLoss: 62.425259857177736\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.44233289718628\n",
            "Validation:\n",
            "\tLoss: 11.310857200622559\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.837972297668458\n",
            "Validation:\n",
            "\tLoss: 10.958341789245605\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 119/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.57442749023437\n",
            "Validation:\n",
            "\tLoss: 68.39860534667969\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 67.47089416503906\n",
            "Validation:\n",
            "\tLoss: 68.29476928710938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 67.35826446533203\n",
            "Validation:\n",
            "\tLoss: 68.18148040771484\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 120/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.57955307006836\n",
            "Validation:\n",
            "\tLoss: 67.42575927734374\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.13317440032959\n",
            "Validation:\n",
            "\tLoss: 11.395139770507813\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.502104301452636\n",
            "Validation:\n",
            "\tLoss: 12.354944648742675\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 121/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.14373168945312\n",
            "Validation:\n",
            "\tLoss: 65.00377258300782\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.559196319580078\n",
            "Validation:\n",
            "\tLoss: 13.805974979400634\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.876053085327147\n",
            "Validation:\n",
            "\tLoss: 13.60607666015625\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 122/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.18066040039062\n",
            "Validation:\n",
            "\tLoss: 68.40003204345703\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 29.3782169342041\n",
            "Validation:\n",
            "\tLoss: 14.479655952453614\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 21.82182762145996\n",
            "Validation:\n",
            "\tLoss: 13.45849464416504\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 123/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.22280181884766\n",
            "Validation:\n",
            "\tLoss: 65.02079772949219\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.25483341217041\n",
            "Validation:\n",
            "\tLoss: 11.226036071777344\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.180939483642579\n",
            "Validation:\n",
            "\tLoss: 11.18885326385498\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 124/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.96635620117188\n",
            "Validation:\n",
            "\tLoss: 66.3634033203125\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.896980514526367\n",
            "Validation:\n",
            "\tLoss: 10.98766803741455\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.89680591583252\n",
            "Validation:\n",
            "\tLoss: 12.673242568969727\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 125/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.89653289794921\n",
            "Validation:\n",
            "\tLoss: 66.64495086669922\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 28.674318618774414\n",
            "Validation:\n",
            "\tLoss: 23.857898712158203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 23.981182479858397\n",
            "Validation:\n",
            "\tLoss: 14.369363784790039\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 126/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.62745330810547\n",
            "Validation:\n",
            "\tLoss: 68.2933349609375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 67.22957305908203\n",
            "Validation:\n",
            "\tLoss: 67.89664459228516\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 66.67020263671876\n",
            "Validation:\n",
            "\tLoss: 67.3365478515625\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 127/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.67031158447266\n",
            "Validation:\n",
            "\tLoss: 66.67512725830078\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.759583435058595\n",
            "Validation:\n",
            "\tLoss: 12.191394309997559\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.832955169677735\n",
            "Validation:\n",
            "\tLoss: 12.146604194641114\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 128/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.88533508300782\n",
            "Validation:\n",
            "\tLoss: 65.65077178955079\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.651588554382323\n",
            "Validation:\n",
            "\tLoss: 11.705847549438477\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.644515953063966\n",
            "Validation:\n",
            "\tLoss: 11.178543167114258\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 129/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.22565795898437\n",
            "Validation:\n",
            "\tLoss: 68.05920227050781\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.116176643371581\n",
            "Validation:\n",
            "\tLoss: 12.024593353271484\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.607252502441407\n",
            "Validation:\n",
            "\tLoss: 10.586958770751954\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 130/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.62039779663085\n",
            "Validation:\n",
            "\tLoss: 66.85193969726562\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.410136451721192\n",
            "Validation:\n",
            "\tLoss: 11.080948333740235\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.794373741149903\n",
            "Validation:\n",
            "\tLoss: 10.727424850463867\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 131/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.83455963134766\n",
            "Validation:\n",
            "\tLoss: 66.43512725830078\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 132/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 59.39122756958008\n",
            "Validation:\n",
            "\tLoss: 19.303768310546875\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 133/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.00949493408203\n",
            "Validation:\n",
            "\tLoss: 65.38096862792969\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.965974082946778\n",
            "Validation:\n",
            "\tLoss: 10.925218391418458\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.400165519714356\n",
            "Validation:\n",
            "\tLoss: 10.364916038513183\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 134/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.55731430053712\n",
            "Validation:\n",
            "\tLoss: 66.60614654541016\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.047660827636719\n",
            "Validation:\n",
            "\tLoss: 11.783339233398438\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.98587230682373\n",
            "Validation:\n",
            "\tLoss: 11.761419639587402\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 135/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.47446716308593\n",
            "Validation:\n",
            "\tLoss: 68.31464385986328\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.943975143432617\n",
            "Validation:\n",
            "\tLoss: 13.64717960357666\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 19.44772590637207\n",
            "Validation:\n",
            "\tLoss: 12.447080612182617\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 136/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.1672998046875\n",
            "Validation:\n",
            "\tLoss: 69.65022430419921\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 29.777932434082032\n",
            "Validation:\n",
            "\tLoss: 20.617744750976563\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.11624710083008\n",
            "Validation:\n",
            "\tLoss: 11.64972152709961\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 137/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.57996673583985\n",
            "Validation:\n",
            "\tLoss: 68.49352844238281\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.229892234802247\n",
            "Validation:\n",
            "\tLoss: 11.036864051818847\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.874466590881347\n",
            "Validation:\n",
            "\tLoss: 11.28222038269043\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 138/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.51464218139648\n",
            "Validation:\n",
            "\tLoss: 66.59567962646484\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.985037460327149\n",
            "Validation:\n",
            "\tLoss: 12.946743583679199\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 15.099356231689454\n",
            "Validation:\n",
            "\tLoss: 12.986263275146484\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 139/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.75899612426758\n",
            "Validation:\n",
            "\tLoss: 67.47935729980469\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.887960662841795\n",
            "Validation:\n",
            "\tLoss: 13.578991813659668\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.568388175964355\n",
            "Validation:\n",
            "\tLoss: 11.40276123046875\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 140/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.66659057617187\n",
            "Validation:\n",
            "\tLoss: 66.6147689819336\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.855291709899902\n",
            "Validation:\n",
            "\tLoss: 10.754230499267578\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.641430473327636\n",
            "Validation:\n",
            "\tLoss: 12.358241081237793\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 141/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.24173645019532\n",
            "Validation:\n",
            "\tLoss: 68.4340463256836\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.723646774291993\n",
            "Validation:\n",
            "\tLoss: 11.498961067199707\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.713079681396485\n",
            "Validation:\n",
            "\tLoss: 13.278421020507812\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 142/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.68441009521484\n",
            "Validation:\n",
            "\tLoss: 67.70194244384766\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.58332977294922\n",
            "Validation:\n",
            "\tLoss: 13.344244956970215\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.56083526611328\n",
            "Validation:\n",
            "\tLoss: 13.641915321350098\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 143/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.57309295654296\n",
            "Validation:\n",
            "\tLoss: 67.85877227783203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.120837440490723\n",
            "Validation:\n",
            "\tLoss: 10.834393501281738\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.779318046569824\n",
            "Validation:\n",
            "\tLoss: 11.014909744262695\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 144/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.50782104492187\n",
            "Validation:\n",
            "\tLoss: 66.46841430664062\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.497893257141115\n",
            "Validation:\n",
            "\tLoss: 12.431007385253906\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.014168701171876\n",
            "Validation:\n",
            "\tLoss: 12.439250946044922\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 145/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.35615020751953\n",
            "Validation:\n",
            "\tLoss: 67.78486633300781\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 60.471497802734376\n",
            "Validation:\n",
            "\tLoss: 59.913917541503906\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 54.46573226928711\n",
            "Validation:\n",
            "\tLoss: 54.2841911315918\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 146/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.73307708740235\n",
            "Validation:\n",
            "\tLoss: 67.0165023803711\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 51.052615356445315\n",
            "Validation:\n",
            "\tLoss: 50.343406677246094\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 34.639725036621094\n",
            "Validation:\n",
            "\tLoss: 33.909793853759766\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 147/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 148/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.5570751953125\n",
            "Validation:\n",
            "\tLoss: 68.63349731445312\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 66.37898574829102\n",
            "Validation:\n",
            "\tLoss: 67.43366470336915\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.449346122741698\n",
            "Validation:\n",
            "\tLoss: 12.128403396606446\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 149/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.02714813232421\n",
            "Validation:\n",
            "\tLoss: 66.418212890625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.023825225830079\n",
            "Validation:\n",
            "\tLoss: 12.469715118408203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.133982276916504\n",
            "Validation:\n",
            "\tLoss: 11.398634910583496\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 150/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.80321197509765\n",
            "Validation:\n",
            "\tLoss: 67.3862075805664\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 67.64365447998047\n",
            "Validation:\n",
            "\tLoss: 67.22463989257812\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 67.46359771728515\n",
            "Validation:\n",
            "\tLoss: 67.04328918457031\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 151/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.4362954711914\n",
            "Validation:\n",
            "\tLoss: 66.68542388916016\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.512322540283202\n",
            "Validation:\n",
            "\tLoss: 11.637784271240234\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.816836242675782\n",
            "Validation:\n",
            "\tLoss: 11.866613311767578\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 152/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.54803680419921\n",
            "Validation:\n",
            "\tLoss: 68.39250946044922\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 33.88991897583008\n",
            "Validation:\n",
            "\tLoss: 18.79798126220703\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 20.056171035766603\n",
            "Validation:\n",
            "\tLoss: 10.121663093566895\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 153/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.8668423461914\n",
            "Validation:\n",
            "\tLoss: 66.4555810546875\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.330157165527345\n",
            "Validation:\n",
            "\tLoss: 11.274902534484863\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.483434257507325\n",
            "Validation:\n",
            "\tLoss: 10.714809608459472\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 154/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.86972747802734\n",
            "Validation:\n",
            "\tLoss: 66.74918426513672\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.250249252319335\n",
            "Validation:\n",
            "\tLoss: 12.919186363220215\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.675915832519532\n",
            "Validation:\n",
            "\tLoss: 11.533376808166503\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 155/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.00957565307617\n",
            "Validation:\n",
            "\tLoss: 64.23317199707031\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.523065643310547\n",
            "Validation:\n",
            "\tLoss: 11.05536647796631\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.874562377929687\n",
            "Validation:\n",
            "\tLoss: 11.473318138122558\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 156/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.41580688476563\n",
            "Validation:\n",
            "\tLoss: 67.1003662109375\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.361072616577147\n",
            "Validation:\n",
            "\tLoss: 11.436751976013184\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.359252128601074\n",
            "Validation:\n",
            "\tLoss: 10.79756175994873\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 157/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.26167999267578\n",
            "Validation:\n",
            "\tLoss: 68.97518157958984\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.692647857666016\n",
            "Validation:\n",
            "\tLoss: 11.17139217376709\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.688209648132323\n",
            "Validation:\n",
            "\tLoss: 10.42546215057373\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 158/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.72528228759765\n",
            "Validation:\n",
            "\tLoss: 65.11864837646485\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.349388580322266\n",
            "Validation:\n",
            "\tLoss: 13.411431694030762\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.797702713012695\n",
            "Validation:\n",
            "\tLoss: 12.204164123535156\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 159/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.09070587158203\n",
            "Validation:\n",
            "\tLoss: 64.92024719238282\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.023771591186524\n",
            "Validation:\n",
            "\tLoss: 11.279649543762208\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.895323829650879\n",
            "Validation:\n",
            "\tLoss: 13.498108940124512\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 160/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.83011169433594\n",
            "Validation:\n",
            "\tLoss: 66.52334442138672\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.823744087219238\n",
            "Validation:\n",
            "\tLoss: 12.73064510345459\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.73815460205078\n",
            "Validation:\n",
            "\tLoss: 14.010937004089355\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 161/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.98712860107422\n",
            "Validation:\n",
            "\tLoss: 65.99514343261718\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.132170867919921\n",
            "Validation:\n",
            "\tLoss: 10.72306999206543\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.435602989196777\n",
            "Validation:\n",
            "\tLoss: 11.644406700134278\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 162/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.91482772827149\n",
            "Validation:\n",
            "\tLoss: 64.46075347900391\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 163/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.38197326660156\n",
            "Validation:\n",
            "\tLoss: 68.33711242675781\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.893908882141114\n",
            "Validation:\n",
            "\tLoss: 10.703782081604004\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.48254539489746\n",
            "Validation:\n",
            "\tLoss: 11.603974342346191\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 164/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.30009353637695\n",
            "Validation:\n",
            "\tLoss: 68.19617767333985\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.532859916687011\n",
            "Validation:\n",
            "\tLoss: 10.67674228668213\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.671007194519042\n",
            "Validation:\n",
            "\tLoss: 10.358191680908202\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 165/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.2365640258789\n",
            "Validation:\n",
            "\tLoss: 66.15717315673828\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 63.781038970947264\n",
            "Validation:\n",
            "\tLoss: 61.698326110839844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 59.72292861938477\n",
            "Validation:\n",
            "\tLoss: 57.66082763671875\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 166/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.37993194580078\n",
            "Validation:\n",
            "\tLoss: 67.39906311035156\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.049585609436035\n",
            "Validation:\n",
            "\tLoss: 10.57541561126709\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.0040625\n",
            "Validation:\n",
            "\tLoss: 11.043099403381348\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 167/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.78839141845702\n",
            "Validation:\n",
            "\tLoss: 66.07476806640625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 168/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.44588928222656\n",
            "Validation:\n",
            "\tLoss: 68.33967590332031\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 19.651927795410156\n",
            "Validation:\n",
            "\tLoss: 13.057425498962402\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 18.409663009643555\n",
            "Validation:\n",
            "\tLoss: 14.1038179397583\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 169/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.33949981689453\n",
            "Validation:\n",
            "\tLoss: 68.56791931152344\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.323219757080079\n",
            "Validation:\n",
            "\tLoss: 11.097382659912109\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.422637481689453\n",
            "Validation:\n",
            "\tLoss: 11.411598205566406\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 170/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.45197448730468\n",
            "Validation:\n",
            "\tLoss: 68.21451782226562\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.866092872619628\n",
            "Validation:\n",
            "\tLoss: 12.304557800292969\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.013150329589843\n",
            "Validation:\n",
            "\tLoss: 12.973851203918457\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 171/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.30981384277344\n",
            "Validation:\n",
            "\tLoss: 68.00303833007813\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.200714149475097\n",
            "Validation:\n",
            "\tLoss: 11.150248680114746\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.01939266204834\n",
            "Validation:\n",
            "\tLoss: 11.702659606933594\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 172/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.96360748291016\n",
            "Validation:\n",
            "\tLoss: 66.20977783203125\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.462585067749023\n",
            "Validation:\n",
            "\tLoss: 12.12231159210205\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 15.014966468811036\n",
            "Validation:\n",
            "\tLoss: 11.889718055725098\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 173/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.99186920166015\n",
            "Validation:\n",
            "\tLoss: 66.27809143066406\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 17.687398529052736\n",
            "Validation:\n",
            "\tLoss: 11.491596221923828\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.338500442504884\n",
            "Validation:\n",
            "\tLoss: 11.444646835327148\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 174/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.35233917236329\n",
            "Validation:\n",
            "\tLoss: 67.93484741210938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.860113410949706\n",
            "Validation:\n",
            "\tLoss: 11.390652694702148\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.336268768310546\n",
            "Validation:\n",
            "\tLoss: 10.672869415283204\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 175/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.85184356689453\n",
            "Validation:\n",
            "\tLoss: 66.9680404663086\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 176/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 49.29759063720703\n",
            "Validation:\n",
            "\tLoss: 11.311445217132569\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.513948860168457\n",
            "Validation:\n",
            "\tLoss: 11.536008338928223\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.528158187866211\n",
            "Validation:\n",
            "\tLoss: 10.612852973937988\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 177/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 65.86596130371093\n",
            "Validation:\n",
            "\tLoss: 53.62586624145508\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 13.626513481140137\n",
            "Validation:\n",
            "\tLoss: 10.302928848266601\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.5532368850708\n",
            "Validation:\n",
            "\tLoss: 9.7216579246521\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 178/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.82842315673828\n",
            "Validation:\n",
            "\tLoss: 66.8920669555664\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 36.18032745361328\n",
            "Validation:\n",
            "\tLoss: 34.2900276184082\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 19.872857131958007\n",
            "Validation:\n",
            "\tLoss: 15.177451133728027\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 179/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.35046646118164\n",
            "Validation:\n",
            "\tLoss: 61.04706436157227\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 17.51331874847412\n",
            "Validation:\n",
            "\tLoss: 11.53855239868164\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.245415840148926\n",
            "Validation:\n",
            "\tLoss: 10.874437370300292\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 180/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 68.26741485595703\n",
            "Validation:\n",
            "\tLoss: 66.86029815673828\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.533403625488281\n",
            "Validation:\n",
            "\tLoss: 11.635367393493652\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.846351928710938\n",
            "Validation:\n",
            "\tLoss: 11.519063949584961\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 181/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 62.22961036682129\n",
            "Validation:\n",
            "\tLoss: 50.89094436645508\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.420250396728516\n",
            "Validation:\n",
            "\tLoss: 10.306369934082031\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.146215972900391\n",
            "Validation:\n",
            "\tLoss: 10.138547325134278\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 182/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.52720581054687\n",
            "Validation:\n",
            "\tLoss: 68.71763610839844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 14.323516578674317\n",
            "Validation:\n",
            "\tLoss: 11.555440902709961\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.464443283081055\n",
            "Validation:\n",
            "\tLoss: 11.411995887756348\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 183/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.76777130126953\n",
            "Validation:\n",
            "\tLoss: 67.35163116455078\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 66.76084747314454\n",
            "Validation:\n",
            "\tLoss: 66.3448486328125\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 64.55243194580078\n",
            "Validation:\n",
            "\tLoss: 64.09416198730469\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 184/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.37671234130859\n",
            "Validation:\n",
            "\tLoss: 68.02502899169922\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.905643196105958\n",
            "Validation:\n",
            "\tLoss: 11.677662353515625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.305926055908204\n",
            "Validation:\n",
            "\tLoss: 11.05568920135498\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 185/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.91509796142579\n",
            "Validation:\n",
            "\tLoss: 66.60962463378907\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 18.02237171173096\n",
            "Validation:\n",
            "\tLoss: 11.698789176940918\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.484044723510742\n",
            "Validation:\n",
            "\tLoss: 10.995111961364746\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 186/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.93599822998047\n",
            "Validation:\n",
            "\tLoss: 66.54150390625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.488478775024413\n",
            "Validation:\n",
            "\tLoss: 10.993821144104004\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.591554260253906\n",
            "Validation:\n",
            "\tLoss: 11.3309907913208\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 187/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.51422271728515\n",
            "Validation:\n",
            "\tLoss: 68.38609313964844\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 16.639393272399904\n",
            "Validation:\n",
            "\tLoss: 14.629055976867676\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.28882209777832\n",
            "Validation:\n",
            "\tLoss: 12.204005241394043\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 188/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.73606048583984\n",
            "Validation:\n",
            "\tLoss: 67.24406433105469\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 189/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.76351135253907\n",
            "Validation:\n",
            "\tLoss: 67.107666015625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 21.570491790771484\n",
            "Validation:\n",
            "\tLoss: 15.411075592041016\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 16.42102222442627\n",
            "Validation:\n",
            "\tLoss: 11.975687026977539\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 190/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.61702941894531\n",
            "Validation:\n",
            "\tLoss: 66.92902374267578\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 22.099512023925783\n",
            "Validation:\n",
            "\tLoss: 14.797856330871582\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 19.55515197753906\n",
            "Validation:\n",
            "\tLoss: 11.721162796020508\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 191/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.62104370117187\n",
            "Validation:\n",
            "\tLoss: 67.73191009521484\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.336250228881836\n",
            "Validation:\n",
            "\tLoss: 14.945830001831055\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.404646224975586\n",
            "Validation:\n",
            "\tLoss: 11.526445007324218\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 192/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.47518615722656\n",
            "Validation:\n",
            "\tLoss: 64.94881439208984\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.204432678222656\n",
            "Validation:\n",
            "\tLoss: 11.278663635253906\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 14.062043647766114\n",
            "Validation:\n",
            "\tLoss: 11.002958297729492\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 193/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.47899475097657\n",
            "Validation:\n",
            "\tLoss: 69.24677276611328\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 20.196768798828124\n",
            "Validation:\n",
            "\tLoss: 14.037270545959473\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 17.899326934814454\n",
            "Validation:\n",
            "\tLoss: 11.195279121398926\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 194/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.20133331298828\n",
            "Validation:\n",
            "\tLoss: 68.81737091064453\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 15.79349853515625\n",
            "Validation:\n",
            "\tLoss: 12.446331748962402\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 13.329952430725097\n",
            "Validation:\n",
            "\tLoss: 11.522636756896972\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 195/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.65675048828125\n",
            "Validation:\n",
            "\tLoss: 68.03500366210938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.63612777709961\n",
            "Validation:\n",
            "\tLoss: 10.72701644897461\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.292986602783204\n",
            "Validation:\n",
            "\tLoss: 10.821742057800293\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 196/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.15985534667969\n",
            "Validation:\n",
            "\tLoss: 63.76442504882812\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 11.66554214477539\n",
            "Validation:\n",
            "\tLoss: 10.918338050842285\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 11.834782180786133\n",
            "Validation:\n",
            "\tLoss: 10.029751777648926\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 197/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 66.40566665649413\n",
            "Validation:\n",
            "\tLoss: 105.28826446533203\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: nan\n",
            "Validation:\n",
            "\tLoss: nan\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 198/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.27506591796875\n",
            "Validation:\n",
            "\tLoss: 68.031962890625\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 10.882266807556153\n",
            "Validation:\n",
            "\tLoss: 12.093585968017578\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 10.159557456970214\n",
            "Validation:\n",
            "\tLoss: 12.513187294006348\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 199/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.35371856689453\n",
            "Validation:\n",
            "\tLoss: 69.41683959960938\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.595978050231933\n",
            "Validation:\n",
            "\tLoss: 10.843062400817871\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.525081634521484\n",
            "Validation:\n",
            "\tLoss: 10.31994915008545\n",
            "\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 200/200\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 1/100:\n",
            "Train:\n",
            "\tLoss: 67.11661499023438\n",
            "Validation:\n",
            "\tLoss: 64.92350830078125\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 51/100:\n",
            "Train:\n",
            "\tLoss: 12.599579582214355\n",
            "Validation:\n",
            "\tLoss: 11.987100982666016\n",
            "\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch 100/100:\n",
            "Train:\n",
            "\tLoss: 12.26883457183838\n",
            "Validation:\n",
            "\tLoss: 11.713008079528809\n",
            "\n",
            "---------------------------------------------------\n",
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
            "\n",
            "Best Sample:\n",
            "\tLoss: 9.213712348937989\n",
            "\t\tUnits: 32\n",
            "\t\tHidden Layers: 1\n",
            "\t\tActivation Function: leaky\n",
            "\t\tLearning Rate: 0.043822707037253474\n",
            "\t\tMomentum: 0.40165118469844885\n",
            "\t\tBatch Size: 32\n",
            "\t\tDropout Probability: 0.06738041099465714\n",
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter Tuning\n",
        "\n",
        "def main_task1(num_samples=20, num_epochs=100):\n",
        "  best_epoch_loss = 1e9\n",
        "  best_units, best_layers, best_active, best_lr, best_momentum, best_batch_size, best_dropout = None, None, None, None, None, None, None\n",
        "  for i in range(num_samples):\n",
        "    print('____________________________________________________________________\\n')\n",
        "    print(f'Sample {i+1}/{num_samples}')\n",
        "    print('____________________________________________________________________\\n')\n",
        "      \n",
        "    units = 2 ** np.random.randint(3, 7)\n",
        "    layers = np.random.randint(1, 5)\n",
        "    active = np.random.choice([\"relu\", \"leaky\", \"elu\", \"hardswish\", \"selu\", \"silu\"])\n",
        "    lr = np.random.uniform(0.1, 0.00001)\n",
        "    momentum = np.random.uniform(0.0, 1.0)\n",
        "    batch_size = 2 ** np.random.randint(5, 10)\n",
        "    dropout = np.random.uniform(0.0, 0.5)\n",
        "    \n",
        "    epoch_loss = process(units, layers, active, lr, momentum, batch_size, dropout, num_epochs)\n",
        "\n",
        "    if epoch_loss < best_epoch_loss:\n",
        "      best_epoch_loss = epoch_loss\n",
        "      best_units, best_layers, best_active, best_lr, best_momentum, best_batch_size, best_dropout = units, layers, active, lr, momentum, batch_size, dropout\n",
        "\n",
        "  print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n')\n",
        "  print(\"Best Sample:\")\n",
        "  print(f'\\tLoss: {best_epoch_loss}')\n",
        "  print(f'\\t\\tUnits: {best_units}')\n",
        "  print(f'\\t\\tHidden Layers: {best_layers}')\n",
        "  print(f'\\t\\tActivation Function: {best_active}')\n",
        "  print(f'\\t\\tLearning Rate: {best_lr}')\n",
        "  print(f'\\t\\tMomentum: {best_momentum}')\n",
        "  print(f'\\t\\tBatch Size: {best_batch_size}')\n",
        "  print(f'\\t\\tDropout Probability: {best_dropout}')\n",
        "  print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n')\n",
        "  \n",
        "    \n",
        "main_task1(200, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Some samples produce L1Loss equal to NaN.\n",
        "- After investigating the issue for a long time I came to the conclusion that some samples extremly diverge and python just can't keep up.\n",
        "- Since we're only looking for the best model and the majority of the samples run fine, I decided to not focus on this issue because it doesn't really affect our end goal.\n"
      ],
      "metadata": {
        "id": "BNzv0zcnXJ97"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-6l0VCZfLXhE"
      },
      "source": [
        "### Questions\n",
        "1. What preprocessing techniques did you use? Why?\n",
        "    - Encoding:\n",
        "      - OneHotEncoding\n",
        "        - Features: \n",
        "          - gender \n",
        "          - race/ethnicity \n",
        "        - Reasoning: \n",
        "          - Because gender and race do not have a natural ordered relationship in themselves. So, one hot encoding is the appropriate here.\n",
        "      - OrdinalEncoding:\n",
        "        - Features: \n",
        "          - parental level of education  \n",
        "          - test preparation course \n",
        "          - lunch \n",
        "        - Reasoning: \n",
        "          - parental level of education: there's a natural order from uneducated to educated.\n",
        "          - Order:\n",
        "            - some high school -> 0  \n",
        "            - high school -> 1 \n",
        "            - some college -> 2 \n",
        "            - associate's degree -> 3 \n",
        "            - bachelor's degree -> 4 \n",
        "            - master's degree -> 5 \n",
        "          - lunch: there's a natural order in terms of what is better, free/reduced or full priced. \n",
        "          - Order:\n",
        "            - standard -> 0 \n",
        "            - free/reduced -> 1 \n",
        "          - test preparation course: there's a natural order in terms of who is prepared and not.\n",
        "          - Order:\n",
        "            - none -> 0 \n",
        "            - completed -> 1 \n",
        "      - Note: For the lunch and test preparation course features, both OneHotEncoding and OrdinalEncoding are valid due to the fact that there's only 2 possible values for each feature.\n",
        "    - Scaling\n",
        "      - Used standard scaler to scale the dataset\n",
        "      - Reasoning: to make all features contribute equally instead of having ordinally encoded features(parental level of education) have more weight than other features.\n",
        "2. Describe the fine-tuning process and how you reached your model architecture.\n",
        "   \n",
        "    - Fine-tuning: \n",
        "      - Number of Layers:\n",
        "        - Possible values: \\[1, 2, 3, 4, 5]\n",
        "        - Reason: in most of my test runs the best model had 1 or 2 layers, and having more than 5 will make the code slower\n",
        "      - Number of Neurons: \n",
        "        - Possible values: \\[8, 16, 32, 64, 128]  \n",
        "        - Reason: in most of my test runs the best model had 32 or 64 Neurons, and having more than 128 will make the code slower \n",
        "      - Activation Functions:\n",
        "        - Possible functions: \n",
        "            - ReLU\n",
        "            - LeakyReLU\n",
        "            - Hardswish\n",
        "            - ELU\n",
        "            - SELU\n",
        "            - SiLU\n",
        "        - Reason: We were told in labs that ReLU is the most common one and we should use it in most cases. And, I did not want to include all available functions, because it will need me to run the code for a much larger number of samples to have a good variaty of tests. \n",
        "      - Learning Rate:\n",
        "        - Possible values: a random float between 10^-1 and 10^-5\n",
        "        - Reason: A good margin and it will give various results\n",
        "      - Momentum: \n",
        "        - Possible values: a random float between 0.0 and 1.0\n",
        "      - Regularization: \n",
        "        - Dropout Probability: \n",
        "          - Possible values: a random float between 0.0 and 0.5\n",
        "          - Reason: based on lecture 10 best dropout probability is between 0.2 and 0.5 but it was mentioned that sometimes lower than that might be better. So, I decided to give it from 0.0 to 0.5 with the trade off that I will run the code for a larger number of samples.\n",
        "      - Note: I went with the assumption that you wanted us to use SGD as an optimizer based on the following facts:\n",
        "        - You asked us to tune Momentum\n",
        "        - We only used Adam and SGD optimizers in the course\n",
        "      - Batch Size: \n",
        "        - Possible values: \\[32, 64, 128, 256, 512]\n",
        "        - Reason: Although it wasn't mentioned in the problem statement, I wanted to test it out since the most harm it could do is make the code a little slower. \n",
        "    - After running for 200 samples where each sample ran for 100 epochs, the best samples was the following:\n",
        "      - L1Loss: 9.213712348937989\n",
        "      - Number of Layers: 1 \n",
        "      - Number of Neurons: 32\n",
        "      - Learning Rate: 0.043822707037253474\n",
        "      - Momuntem: 0.40165118469844885\n",
        "      - Activiation Function: LeakyReLU\n",
        "      - Batch Size: 32\n",
        "      - Dropout Probability: 0.06738041099465714"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cJtzI-pfLXhE"
      },
      "source": [
        "# Task 2: CNN (40%)\n",
        "For this task, you will be doing image classification:\n",
        "- First, adapt your best model from Task 1 to work on this task, and\n",
        "fit it on the new data. Then, evaluate its performance.\n",
        "- After that, build a CNN model for image classification.\n",
        "- Compare both models in terms of accuracy, number of parameters and speed of\n",
        "inference (the time the model takes to predict 50 samples).\n",
        "\n",
        "For the given data, you need to do proper data preprocessing and augmentation,\n",
        "data loaders.\n",
        "Then fine-tune your model architecture (number of layers, number of filters,\n",
        "activation function, learning rate, momentum, regularization).\n",
        "\n",
        "### Data\n",
        "You will be working with the data in `triple_mnist.zip` for predicting 3-digit\n",
        "numbers writen in the image. Each image contains 3 digits similar to the\n",
        "following example (whose label is `039`):\n",
        "\n",
        "![example](https://github.com/shaohua0116/MultiDigitMNIST/blob/master/asset/examples/039/0_039.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "\n",
        "#Pytorch: Used for CNN\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray"
      ],
      "metadata": {
        "id": "YDE48vZanaoT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the data file and extracting to task2 directory\n",
        "#Reference: https://stackoverflow.com/questions/3451111/unzipping-files-in-python\n",
        "\n",
        "with zipfile.ZipFile('triple_mnist.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/task2/')"
      ],
      "metadata": {
        "id": "IkshCdP1ncuK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parsing a directory of images into greyscale and transforming it to a tensor \n",
        "#Reference: Lab 9 \n",
        "#           https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
        "#           https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor\n",
        "\n",
        "def parse_data(dir):\n",
        "  X = []\n",
        "  y = []\n",
        "  tr = transforms.ToTensor()\n",
        "  for d in os.listdir(dir):\n",
        "    for img in os.listdir(f'{dir}/{d}'):\n",
        "      datum = plt.imread(f'{dir}/{d}/{img}')\n",
        "      datum = rgb2gray(datum)\n",
        "      datum = tr(datum)  \n",
        "      X.append(datum)\n",
        "      y.append(d)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "6phrkAs9BPq-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Custom Dataset in pytorch\n",
        "#Reference: Self Practice 7\n",
        "#           Lab 10\n",
        "\n",
        "class CustumData(Dataset):\n",
        "  def __init__(self, X, y, augmentation = None):\n",
        "    super().__init__()\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.augmentation = augmentation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.X[idx]\n",
        "    if self.augmentation:\n",
        "      img = self.augmentation(self.X[idx])\n",
        "    return img, self.y[idx]"
      ],
      "metadata": {
        "id": "1Bnly9bFaW8t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the split data from the unzipped directories\n",
        "#Reference: Lab 10\n",
        "#           https://pytorch.org/vision/stable/transforms.html\n",
        "#           https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose\n",
        "\n",
        "X_train, y_train = parse_data('/task2/triple_mnist/train')\n",
        "X_val, y_val = parse_data('/task2/triple_mnist/val')\n",
        "X_test, y_test = parse_data('/task2/triple_mnist/test')\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(15), # Only logical thing since other types of transformations will either not be useful or will change the numbers\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "train_data = CustumData(X_train, y_train, train_transforms)\n",
        "val_data = CustumData(X_val, y_val, test_transforms)\n",
        "test_data = CustumData(X_test, y_test, test_transforms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzg2ne-lv3oZ",
        "outputId": "8fbf2e83-6d61-4189-b54d-c606e5e46c22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NN Model\n",
        "#Reference: Lab 7, \n",
        "#           https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html, \n",
        "#           https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential\n",
        "#           Lab 9, \n",
        "\n",
        "#Same as before just change input and output and return a list of 3 values in forward\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, units = 64, layers = 2, activation = nn.ReLU(), dropout = 0.25):\n",
        "    super(Net, self).__init__()\n",
        "    self.input = nn.Sequential(\n",
        "      nn.Linear(84*84 ,units),\n",
        "      activation\n",
        "    )\n",
        "    linear = nn.Sequential(\n",
        "      nn.Linear(units, units),\n",
        "      activation\n",
        "    )\n",
        "    self.linears = nn.ModuleList([linear for i in range(layers)])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.output = nn.Linear(units, 30)\n",
        "\n",
        "  def forward(self, x):  \n",
        "    x = x.view(-1, 84*84)\n",
        "    x = self.input(x)\n",
        "    for layer in self.linears:\n",
        "      x = layer(x)\n",
        "      x = self.dropout(x)\n",
        "    x = self.output(x)\n",
        "    n1 = x[:, :10]\n",
        "    n2 = x[:, 10:20]\n",
        "    n3 = x[:, 20:30]\n",
        "    return [n1,n2,n3]\n"
      ],
      "metadata": {
        "id": "NuF8ZnM22_Ve"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training, Testing/Validation\n",
        "#Reference: Lab 9 \n",
        "\n",
        "\n",
        "def training(net, device, trainloader, criterion, optimizer):\n",
        "  #Training\n",
        "  net.train()\n",
        "  train_loss = 0.0\n",
        "  train_corrects = 0\n",
        "  for data, targets in trainloader:\n",
        "    data = data.to(device).float()\n",
        "    targets = torch.tensor([[int(target[0]), int(target[1]), int(target[2])] for target in targets])\n",
        "    targets = targets.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    outputs = net(data)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(3):\n",
        "      loss += criterion(outputs[i], targets[:, i])\n",
        "      preds = torch.max(outputs[i], 1)[1]\n",
        "      train_corrects += torch.sum(preds == targets[:, i])\n",
        "    loss /= 10\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item() * data.size(0)\n",
        "\n",
        "  epoch_loss = train_loss / len(trainloader.dataset)\n",
        "  epoch_acc = train_corrects.double() / (len(train_data)*3)\n",
        "  return epoch_loss, epoch_acc\n",
        "  \n",
        "\n",
        "def testing(net, device, testloader, criterion):\n",
        "  #Validation/Testing\n",
        "  net.eval()\n",
        "  test_loss = 0.0\n",
        "  test_corrects = 0\n",
        "  for data, targets in testloader:\n",
        "    with torch.no_grad():\n",
        "      data = data.to(device).float()\n",
        "      targets = torch.tensor([[int(target[0]), int(target[1]), int(target[2])] for target in targets])\n",
        "      targets = targets.to(device)\n",
        "      \n",
        "      outputs = net(data)\n",
        "      \n",
        "      loss = 0\n",
        "      for i in range(3):\n",
        "        loss = criterion(outputs[i], targets[:, i])\n",
        "        preds = torch.max(outputs[i], 1)[1]\n",
        "        test_corrects += torch.sum(preds == targets[:, i])\n",
        "      loss /= 10\n",
        "      test_loss += loss.item() * data.size(0)\n",
        "      \n",
        "  epoch_loss = test_loss / len(testloader.dataset)\n",
        "  epoch_acc = test_corrects.double() / (len(test_data)*3)\n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "def process(units, layers, activation, momentum, lr, batch_size, dropout):\n",
        "  net = Net(units, layers, activation, dropout)\n",
        "  \n",
        "  optimizer = optim.SGD(net.parameters(), momentum=momentum,lr=lr) \n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss() #Change the loss to adapt for the classification problem\n",
        "  \n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  \n",
        "  net.to(device)\n",
        "\n",
        "\n",
        "  trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  validloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "  testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "  \n",
        "  for epoch in range(100):\n",
        "    train_loss, train_acc = training(net, device, trainloader, criterion, optimizer)\n",
        "    val_loss, val_acc = testing(net, device, validloader, criterion)\n",
        "    print('---------------------------------------------------\\n')\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "    print(f'Train:')\n",
        "    print(f'\\tLoss: {train_loss}')\n",
        "    print(f'\\tAccuracy: {train_acc}')\n",
        "    print(f'Validation:')\n",
        "    print(f'\\tLoss: {val_loss}')\n",
        "    print(f'\\tAccuracy: {val_acc}')\n",
        "    print('---------------------------------------------------')\n",
        "  test_loss, test_acc = testing(net, device, testloader, criterion)\n",
        "  print(f'Test:')\n",
        "  print(f'\\tLoss: {test_loss}')\n",
        "  print(f'\\tAccuracy: {test_acc}')\n",
        "  return net\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "Lqx3VQsT3lkn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Main\n",
        "def main_task2_1():\n",
        "# L1Loss: 9.213712348937989\n",
        "#       - Number of Layers: 1 \n",
        "#       - Number of Neurons: 32\n",
        "#       - Learning Rate: 0.043822707037253474\n",
        "#       - Momuntem: 0.40165118469844885\n",
        "#       - Activiation Function: LeakyReLU\n",
        "#       - Batch Size: 32\n",
        "#       - Dropout Probability: 0.06738041099465714\n",
        "  units = 32\n",
        "  layers = 1\n",
        "  activation = nn.LeakyReLU()\n",
        "  lr = 0.043822707037253474\n",
        "  momentum = 0.40165118469844885\n",
        "  batch_size = 32\n",
        "  dropout = 0.06738041099465714\n",
        "  model = process(units, layers, activation, momentum, lr, batch_size, dropout)\n",
        "  return model\n",
        "\n",
        "best_task2_1 = main_task2_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfh3Jh23oRL",
        "outputId": "d38a1f14-9a60-4616-a46a-1d856be60a9e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 1\n",
            "Train:\n",
            "\tLoss: 0.6906634705364704\n",
            "\tAccuracy: 0.10835416666666667\n",
            "Validation:\n",
            "\tLoss: 0.2314030497968197\n",
            "\tAccuracy: 0.05666666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 2\n",
            "Train:\n",
            "\tLoss: 0.6891287945508957\n",
            "\tAccuracy: 0.11859895833333332\n",
            "Validation:\n",
            "\tLoss: 0.2307731391489506\n",
            "\tAccuracy: 0.08466666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 3\n",
            "Train:\n",
            "\tLoss: 0.6827908050119876\n",
            "\tAccuracy: 0.14086458333333332\n",
            "Validation:\n",
            "\tLoss: 0.22751371133327483\n",
            "\tAccuracy: 0.1101\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 4\n",
            "Train:\n",
            "\tLoss: 0.6758543344140053\n",
            "\tAccuracy: 0.15140104166666665\n",
            "Validation:\n",
            "\tLoss: 0.22602736920118333\n",
            "\tAccuracy: 0.12983333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 5\n",
            "Train:\n",
            "\tLoss: 0.6598348411917686\n",
            "\tAccuracy: 0.18059375\n",
            "Validation:\n",
            "\tLoss: 0.22809993812441826\n",
            "\tAccuracy: 0.14055\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 6\n",
            "Train:\n",
            "\tLoss: 0.6421397706568241\n",
            "\tAccuracy: 0.20499479166666665\n",
            "Validation:\n",
            "\tLoss: 0.20959022471308708\n",
            "\tAccuracy: 0.17451666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 7\n",
            "Train:\n",
            "\tLoss: 0.6340771206617355\n",
            "\tAccuracy: 0.21515104166666665\n",
            "Validation:\n",
            "\tLoss: 0.20644851690530777\n",
            "\tAccuracy: 0.18271666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 8\n",
            "Train:\n",
            "\tLoss: 0.6292628494203091\n",
            "\tAccuracy: 0.22056770833333333\n",
            "Validation:\n",
            "\tLoss: 0.20639800807833672\n",
            "\tAccuracy: 0.17775000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 9\n",
            "Train:\n",
            "\tLoss: 0.6261121745705605\n",
            "\tAccuracy: 0.225203125\n",
            "Validation:\n",
            "\tLoss: 0.20533430123329163\n",
            "\tAccuracy: 0.18263333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 10\n",
            "Train:\n",
            "\tLoss: 0.6240836564302444\n",
            "\tAccuracy: 0.22755729166666666\n",
            "Validation:\n",
            "\tLoss: 0.2127565748691559\n",
            "\tAccuracy: 0.17585\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 11\n",
            "Train:\n",
            "\tLoss: 0.6225021733641625\n",
            "\tAccuracy: 0.230171875\n",
            "Validation:\n",
            "\tLoss: 0.2125841261446476\n",
            "\tAccuracy: 0.18395\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 12\n",
            "Train:\n",
            "\tLoss: 0.6210957407653331\n",
            "\tAccuracy: 0.23244791666666667\n",
            "Validation:\n",
            "\tLoss: 0.20577637922763825\n",
            "\tAccuracy: 0.189\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 13\n",
            "Train:\n",
            "\tLoss: 0.6198081946074963\n",
            "\tAccuracy: 0.23379166666666665\n",
            "Validation:\n",
            "\tLoss: 0.2050338274538517\n",
            "\tAccuracy: 0.18623333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 14\n",
            "Train:\n",
            "\tLoss: 0.6187599969208241\n",
            "\tAccuracy: 0.23673958333333334\n",
            "Validation:\n",
            "\tLoss: 0.206581161826849\n",
            "\tAccuracy: 0.18798333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 15\n",
            "Train:\n",
            "\tLoss: 0.6175479969382286\n",
            "\tAccuracy: 0.23746874999999998\n",
            "Validation:\n",
            "\tLoss: 0.20798490154743193\n",
            "\tAccuracy: 0.18805000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 16\n",
            "Train:\n",
            "\tLoss: 0.6160902470946312\n",
            "\tAccuracy: 0.23947395833333332\n",
            "Validation:\n",
            "\tLoss: 0.20331168976426126\n",
            "\tAccuracy: 0.20113333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 17\n",
            "Train:\n",
            "\tLoss: 0.6148365199565887\n",
            "\tAccuracy: 0.24133333333333332\n",
            "Validation:\n",
            "\tLoss: 0.20639271518588065\n",
            "\tAccuracy: 0.1957\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 18\n",
            "Train:\n",
            "\tLoss: 0.6141843537688255\n",
            "\tAccuracy: 0.2448958333333333\n",
            "Validation:\n",
            "\tLoss: 0.2064202226102352\n",
            "\tAccuracy: 0.19465000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 19\n",
            "Train:\n",
            "\tLoss: 0.6119775324761868\n",
            "\tAccuracy: 0.24617187499999998\n",
            "Validation:\n",
            "\tLoss: 0.20405057799816131\n",
            "\tAccuracy: 0.20566666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 20\n",
            "Train:\n",
            "\tLoss: 0.6097587478756905\n",
            "\tAccuracy: 0.25109895833333334\n",
            "Validation:\n",
            "\tLoss: 0.20115552258491515\n",
            "\tAccuracy: 0.20703333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 21\n",
            "Train:\n",
            "\tLoss: 0.6068679526746273\n",
            "\tAccuracy: 0.2560104166666667\n",
            "Validation:\n",
            "\tLoss: 0.20513102596998214\n",
            "\tAccuracy: 0.20563333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 22\n",
            "Train:\n",
            "\tLoss: 0.6045971621572971\n",
            "\tAccuracy: 0.2588020833333333\n",
            "Validation:\n",
            "\tLoss: 0.20221989318728448\n",
            "\tAccuracy: 0.21385\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 23\n",
            "Train:\n",
            "\tLoss: 0.6033521719574928\n",
            "\tAccuracy: 0.2623802083333333\n",
            "Validation:\n",
            "\tLoss: 0.2022821239233017\n",
            "\tAccuracy: 0.20558333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 24\n",
            "Train:\n",
            "\tLoss: 0.6009287302494049\n",
            "\tAccuracy: 0.26409375\n",
            "Validation:\n",
            "\tLoss: 0.198787264585495\n",
            "\tAccuracy: 0.21730000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 25\n",
            "Train:\n",
            "\tLoss: 0.6000258513391018\n",
            "\tAccuracy: 0.2674583333333333\n",
            "Validation:\n",
            "\tLoss: 0.2097522799372673\n",
            "\tAccuracy: 0.20788333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 26\n",
            "Train:\n",
            "\tLoss: 0.5980942659974098\n",
            "\tAccuracy: 0.26831770833333335\n",
            "Validation:\n",
            "\tLoss: 0.20065537631511687\n",
            "\tAccuracy: 0.21645\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 27\n",
            "Train:\n",
            "\tLoss: 0.5967450607120991\n",
            "\tAccuracy: 0.26948958333333334\n",
            "Validation:\n",
            "\tLoss: 0.20124421548843383\n",
            "\tAccuracy: 0.21230000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 28\n",
            "Train:\n",
            "\tLoss: 0.5958521399199963\n",
            "\tAccuracy: 0.2705\n",
            "Validation:\n",
            "\tLoss: 0.20076619294285775\n",
            "\tAccuracy: 0.2132\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 29\n",
            "Train:\n",
            "\tLoss: 0.5945024600923061\n",
            "\tAccuracy: 0.27269791666666665\n",
            "Validation:\n",
            "\tLoss: 0.20117928266525267\n",
            "\tAccuracy: 0.22095\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 30\n",
            "Train:\n",
            "\tLoss: 0.594121632128954\n",
            "\tAccuracy: 0.27302604166666666\n",
            "Validation:\n",
            "\tLoss: 0.19897275123000144\n",
            "\tAccuracy: 0.21530000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 31\n",
            "Train:\n",
            "\tLoss: 0.59329335552454\n",
            "\tAccuracy: 0.27248958333333334\n",
            "Validation:\n",
            "\tLoss: 0.19910337963700295\n",
            "\tAccuracy: 0.2237\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 32\n",
            "Train:\n",
            "\tLoss: 0.5917297005951404\n",
            "\tAccuracy: 0.27571875\n",
            "Validation:\n",
            "\tLoss: 0.20135981151461602\n",
            "\tAccuracy: 0.21730000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 33\n",
            "Train:\n",
            "\tLoss: 0.5911336739957332\n",
            "\tAccuracy: 0.2757395833333333\n",
            "Validation:\n",
            "\tLoss: 0.19934467524290084\n",
            "\tAccuracy: 0.22441666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 34\n",
            "Train:\n",
            "\tLoss: 0.5896186325252056\n",
            "\tAccuracy: 0.27770833333333333\n",
            "Validation:\n",
            "\tLoss: 0.20172550642490386\n",
            "\tAccuracy: 0.22385000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 35\n",
            "Train:\n",
            "\tLoss: 0.5880900501906872\n",
            "\tAccuracy: 0.27877604166666664\n",
            "Validation:\n",
            "\tLoss: 0.19852392023801804\n",
            "\tAccuracy: 0.22460000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 36\n",
            "Train:\n",
            "\tLoss: 0.5875315490365028\n",
            "\tAccuracy: 0.2802708333333333\n",
            "Validation:\n",
            "\tLoss: 0.1991669473350048\n",
            "\tAccuracy: 0.22548333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 37\n",
            "Train:\n",
            "\tLoss: 0.5862361772358418\n",
            "\tAccuracy: 0.283234375\n",
            "Validation:\n",
            "\tLoss: 0.19857261449098587\n",
            "\tAccuracy: 0.22826666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 38\n",
            "Train:\n",
            "\tLoss: 0.585234003931284\n",
            "\tAccuracy: 0.28265104166666666\n",
            "Validation:\n",
            "\tLoss: 0.19727890300750733\n",
            "\tAccuracy: 0.2271166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 39\n",
            "Train:\n",
            "\tLoss: 0.5849228983521462\n",
            "\tAccuracy: 0.28397395833333333\n",
            "Validation:\n",
            "\tLoss: 0.20114151445031167\n",
            "\tAccuracy: 0.22656666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 40\n",
            "Train:\n",
            "\tLoss: 0.5838875208944082\n",
            "\tAccuracy: 0.2844114583333333\n",
            "Validation:\n",
            "\tLoss: 0.19722527185082436\n",
            "\tAccuracy: 0.22771666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 41\n",
            "Train:\n",
            "\tLoss: 0.5830467960834503\n",
            "\tAccuracy: 0.28706770833333334\n",
            "Validation:\n",
            "\tLoss: 0.19826309943199158\n",
            "\tAccuracy: 0.23468333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 42\n",
            "Train:\n",
            "\tLoss: 0.5821295988559723\n",
            "\tAccuracy: 0.286578125\n",
            "Validation:\n",
            "\tLoss: 0.1993013007938862\n",
            "\tAccuracy: 0.23203333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 43\n",
            "Train:\n",
            "\tLoss: 0.5808568848520518\n",
            "\tAccuracy: 0.2887239583333333\n",
            "Validation:\n",
            "\tLoss: 0.19797260877490044\n",
            "\tAccuracy: 0.21928333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 44\n",
            "Train:\n",
            "\tLoss: 0.5797325435727835\n",
            "\tAccuracy: 0.29178125\n",
            "Validation:\n",
            "\tLoss: 0.19809414553642274\n",
            "\tAccuracy: 0.23243333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 45\n",
            "Train:\n",
            "\tLoss: 0.5787412591725588\n",
            "\tAccuracy: 0.29299479166666664\n",
            "Validation:\n",
            "\tLoss: 0.19641888231039048\n",
            "\tAccuracy: 0.23405\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 46\n",
            "Train:\n",
            "\tLoss: 0.5777835890501738\n",
            "\tAccuracy: 0.2921302083333333\n",
            "Validation:\n",
            "\tLoss: 0.19612859123945237\n",
            "\tAccuracy: 0.23703333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 47\n",
            "Train:\n",
            "\tLoss: 0.575769778251648\n",
            "\tAccuracy: 0.29405729166666666\n",
            "Validation:\n",
            "\tLoss: 0.19639608809351922\n",
            "\tAccuracy: 0.22995000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 48\n",
            "Train:\n",
            "\tLoss: 0.5745370347350836\n",
            "\tAccuracy: 0.2963854166666667\n",
            "Validation:\n",
            "\tLoss: 0.1966385135948658\n",
            "\tAccuracy: 0.23578333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 49\n",
            "Train:\n",
            "\tLoss: 0.5725798640996218\n",
            "\tAccuracy: 0.29907291666666663\n",
            "Validation:\n",
            "\tLoss: 0.19643836095929146\n",
            "\tAccuracy: 0.2376\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 50\n",
            "Train:\n",
            "\tLoss: 0.5706429770737886\n",
            "\tAccuracy: 0.30021354166666664\n",
            "Validation:\n",
            "\tLoss: 0.1934620675444603\n",
            "\tAccuracy: 0.23825000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 51\n",
            "Train:\n",
            "\tLoss: 0.568790450528264\n",
            "\tAccuracy: 0.30239062499999997\n",
            "Validation:\n",
            "\tLoss: 0.19817891997098921\n",
            "\tAccuracy: 0.2396\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 52\n",
            "Train:\n",
            "\tLoss: 0.5671204174011946\n",
            "\tAccuracy: 0.3049427083333333\n",
            "Validation:\n",
            "\tLoss: 0.19369170382618905\n",
            "\tAccuracy: 0.22336666666666669\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 53\n",
            "Train:\n",
            "\tLoss: 0.565526826351881\n",
            "\tAccuracy: 0.30583333333333335\n",
            "Validation:\n",
            "\tLoss: 0.19325405251979827\n",
            "\tAccuracy: 0.24808333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 54\n",
            "Train:\n",
            "\tLoss: 0.5634335669577122\n",
            "\tAccuracy: 0.30915624999999997\n",
            "Validation:\n",
            "\tLoss: 0.19711234310269357\n",
            "\tAccuracy: 0.23895000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 55\n",
            "Train:\n",
            "\tLoss: 0.5620497453510761\n",
            "\tAccuracy: 0.309328125\n",
            "Validation:\n",
            "\tLoss: 0.19799083498120307\n",
            "\tAccuracy: 0.24215\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 56\n",
            "Train:\n",
            "\tLoss: 0.5607701053917408\n",
            "\tAccuracy: 0.3102552083333333\n",
            "Validation:\n",
            "\tLoss: 0.196778972864151\n",
            "\tAccuracy: 0.23726666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 57\n",
            "Train:\n",
            "\tLoss: 0.5594238994419575\n",
            "\tAccuracy: 0.31219270833333335\n",
            "Validation:\n",
            "\tLoss: 0.1938018672168255\n",
            "\tAccuracy: 0.2457\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 58\n",
            "Train:\n",
            "\tLoss: 0.5580292464196682\n",
            "\tAccuracy: 0.3134635416666667\n",
            "Validation:\n",
            "\tLoss: 0.19214293336868285\n",
            "\tAccuracy: 0.24338333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 59\n",
            "Train:\n",
            "\tLoss: 0.5559973885416984\n",
            "\tAccuracy: 0.3178020833333333\n",
            "Validation:\n",
            "\tLoss: 0.19614378696680068\n",
            "\tAccuracy: 0.24176666666666669\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 60\n",
            "Train:\n",
            "\tLoss: 0.5546946782916784\n",
            "\tAccuracy: 0.31817708333333333\n",
            "Validation:\n",
            "\tLoss: 0.1963650361895561\n",
            "\tAccuracy: 0.25020000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 61\n",
            "Train:\n",
            "\tLoss: 0.5540154546648264\n",
            "\tAccuracy: 0.32003645833333333\n",
            "Validation:\n",
            "\tLoss: 0.1951656832396984\n",
            "\tAccuracy: 0.24100000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 62\n",
            "Train:\n",
            "\tLoss: 0.5524210705608129\n",
            "\tAccuracy: 0.32032812499999996\n",
            "Validation:\n",
            "\tLoss: 0.20339364585280417\n",
            "\tAccuracy: 0.2404666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 63\n",
            "Train:\n",
            "\tLoss: 0.5515443121343852\n",
            "\tAccuracy: 0.32190104166666667\n",
            "Validation:\n",
            "\tLoss: 0.19868296852707862\n",
            "\tAccuracy: 0.24571666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 64\n",
            "Train:\n",
            "\tLoss: 0.5502573641389609\n",
            "\tAccuracy: 0.32317708333333334\n",
            "Validation:\n",
            "\tLoss: 0.1990124851167202\n",
            "\tAccuracy: 0.24173333333333336\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 65\n",
            "Train:\n",
            "\tLoss: 0.5492673358768225\n",
            "\tAccuracy: 0.32458333333333333\n",
            "Validation:\n",
            "\tLoss: 0.20749202266335487\n",
            "\tAccuracy: 0.23695000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 66\n",
            "Train:\n",
            "\tLoss: 0.5487853829413653\n",
            "\tAccuracy: 0.3240677083333333\n",
            "Validation:\n",
            "\tLoss: 0.19203164899349212\n",
            "\tAccuracy: 0.2559666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 67\n",
            "Train:\n",
            "\tLoss: 0.5471756757497788\n",
            "\tAccuracy: 0.3263020833333333\n",
            "Validation:\n",
            "\tLoss: 0.19324712431430816\n",
            "\tAccuracy: 0.24705000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 68\n",
            "Train:\n",
            "\tLoss: 0.5470076122134924\n",
            "\tAccuracy: 0.325984375\n",
            "Validation:\n",
            "\tLoss: 0.19237590250372888\n",
            "\tAccuracy: 0.25261666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 69\n",
            "Train:\n",
            "\tLoss: 0.5456852422952652\n",
            "\tAccuracy: 0.32671354166666666\n",
            "Validation:\n",
            "\tLoss: 0.18935898154973985\n",
            "\tAccuracy: 0.2616833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 70\n",
            "Train:\n",
            "\tLoss: 0.5454458084404469\n",
            "\tAccuracy: 0.327109375\n",
            "Validation:\n",
            "\tLoss: 0.18836581856012344\n",
            "\tAccuracy: 0.255\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 71\n",
            "Train:\n",
            "\tLoss: 0.5443315242081881\n",
            "\tAccuracy: 0.3301145833333333\n",
            "Validation:\n",
            "\tLoss: 0.18918663322925566\n",
            "\tAccuracy: 0.26\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 72\n",
            "Train:\n",
            "\tLoss: 0.5435665324032307\n",
            "\tAccuracy: 0.330421875\n",
            "Validation:\n",
            "\tLoss: 0.18935289204120637\n",
            "\tAccuracy: 0.2583166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 73\n",
            "Train:\n",
            "\tLoss: 0.5429899145960808\n",
            "\tAccuracy: 0.33179166666666665\n",
            "Validation:\n",
            "\tLoss: 0.189725427120924\n",
            "\tAccuracy: 0.26025000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 74\n",
            "Train:\n",
            "\tLoss: 0.541337430536747\n",
            "\tAccuracy: 0.3329375\n",
            "Validation:\n",
            "\tLoss: 0.19363647839426995\n",
            "\tAccuracy: 0.259\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 75\n",
            "Train:\n",
            "\tLoss: 0.5406793092042208\n",
            "\tAccuracy: 0.335671875\n",
            "Validation:\n",
            "\tLoss: 0.19494883036613464\n",
            "\tAccuracy: 0.25643333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 76\n",
            "Train:\n",
            "\tLoss: 0.5402513900995255\n",
            "\tAccuracy: 0.33508854166666663\n",
            "Validation:\n",
            "\tLoss: 0.18929803529381753\n",
            "\tAccuracy: 0.26215\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 77\n",
            "Train:\n",
            "\tLoss: 0.5397540954649448\n",
            "\tAccuracy: 0.33508854166666663\n",
            "Validation:\n",
            "\tLoss: 0.19596438604593278\n",
            "\tAccuracy: 0.26175000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 78\n",
            "Train:\n",
            "\tLoss: 0.5392284331321716\n",
            "\tAccuracy: 0.33539583333333334\n",
            "Validation:\n",
            "\tLoss: 0.1900533223450184\n",
            "\tAccuracy: 0.27080000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 79\n",
            "Train:\n",
            "\tLoss: 0.5383245304375887\n",
            "\tAccuracy: 0.33744270833333334\n",
            "Validation:\n",
            "\tLoss: 0.18953694334626198\n",
            "\tAccuracy: 0.25956666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 80\n",
            "Train:\n",
            "\tLoss: 0.5378577108681202\n",
            "\tAccuracy: 0.33752604166666667\n",
            "Validation:\n",
            "\tLoss: 0.19020678547024727\n",
            "\tAccuracy: 0.26685000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 81\n",
            "Train:\n",
            "\tLoss: 0.537232565626502\n",
            "\tAccuracy: 0.33948958333333334\n",
            "Validation:\n",
            "\tLoss: 0.18703571465611457\n",
            "\tAccuracy: 0.26703333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 82\n",
            "Train:\n",
            "\tLoss: 0.5368247970938682\n",
            "\tAccuracy: 0.34122916666666664\n",
            "Validation:\n",
            "\tLoss: 0.1956005674302578\n",
            "\tAccuracy: 0.26416666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 83\n",
            "Train:\n",
            "\tLoss: 0.5367691002041102\n",
            "\tAccuracy: 0.3400208333333333\n",
            "Validation:\n",
            "\tLoss: 0.18665109154582024\n",
            "\tAccuracy: 0.2697\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 84\n",
            "Train:\n",
            "\tLoss: 0.5360758852511645\n",
            "\tAccuracy: 0.33963541666666663\n",
            "Validation:\n",
            "\tLoss: 0.19071851539611817\n",
            "\tAccuracy: 0.26785000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 85\n",
            "Train:\n",
            "\tLoss: 0.5352519200444221\n",
            "\tAccuracy: 0.34241666666666665\n",
            "Validation:\n",
            "\tLoss: 0.1864565490782261\n",
            "\tAccuracy: 0.27581666666666665\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 86\n",
            "Train:\n",
            "\tLoss: 0.5353953781276941\n",
            "\tAccuracy: 0.343046875\n",
            "Validation:\n",
            "\tLoss: 0.18971023577451707\n",
            "\tAccuracy: 0.26511666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 87\n",
            "Train:\n",
            "\tLoss: 0.5352577492594719\n",
            "\tAccuracy: 0.34231249999999996\n",
            "Validation:\n",
            "\tLoss: 0.19415434753894806\n",
            "\tAccuracy: 0.25351666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 88\n",
            "Train:\n",
            "\tLoss: 0.5345404872596264\n",
            "\tAccuracy: 0.34225520833333334\n",
            "Validation:\n",
            "\tLoss: 0.1913247183263302\n",
            "\tAccuracy: 0.2707333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 89\n",
            "Train:\n",
            "\tLoss: 0.5344061585962773\n",
            "\tAccuracy: 0.3426666666666667\n",
            "Validation:\n",
            "\tLoss: 0.1865642074048519\n",
            "\tAccuracy: 0.28058333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 90\n",
            "Train:\n",
            "\tLoss: 0.5346320853382349\n",
            "\tAccuracy: 0.34202083333333333\n",
            "Validation:\n",
            "\tLoss: 0.18859283983707428\n",
            "\tAccuracy: 0.27283333333333337\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 91\n",
            "Train:\n",
            "\tLoss: 0.5337178090810776\n",
            "\tAccuracy: 0.3427864583333333\n",
            "Validation:\n",
            "\tLoss: 0.18710112097859383\n",
            "\tAccuracy: 0.27838333333333337\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 92\n",
            "Train:\n",
            "\tLoss: 0.5326942945271731\n",
            "\tAccuracy: 0.3447708333333333\n",
            "Validation:\n",
            "\tLoss: 0.18813145032525064\n",
            "\tAccuracy: 0.27740000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 93\n",
            "Train:\n",
            "\tLoss: 0.532639405310154\n",
            "\tAccuracy: 0.345140625\n",
            "Validation:\n",
            "\tLoss: 0.19006903010606765\n",
            "\tAccuracy: 0.27516666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 94\n",
            "Train:\n",
            "\tLoss: 0.5312718009054661\n",
            "\tAccuracy: 0.346234375\n",
            "Validation:\n",
            "\tLoss: 0.189168280929327\n",
            "\tAccuracy: 0.27715\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 95\n",
            "Train:\n",
            "\tLoss: 0.5314209695458412\n",
            "\tAccuracy: 0.348203125\n",
            "Validation:\n",
            "\tLoss: 0.190068837672472\n",
            "\tAccuracy: 0.28140000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 96\n",
            "Train:\n",
            "\tLoss: 0.5300501057207584\n",
            "\tAccuracy: 0.349140625\n",
            "Validation:\n",
            "\tLoss: 0.18746691992878914\n",
            "\tAccuracy: 0.27775\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 97\n",
            "Train:\n",
            "\tLoss: 0.5297311730235815\n",
            "\tAccuracy: 0.348734375\n",
            "Validation:\n",
            "\tLoss: 0.18780067932605743\n",
            "\tAccuracy: 0.28578333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 98\n",
            "Train:\n",
            "\tLoss: 0.5292085719704628\n",
            "\tAccuracy: 0.3504322916666667\n",
            "Validation:\n",
            "\tLoss: 0.19397631499171258\n",
            "\tAccuracy: 0.27293333333333336\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 99\n",
            "Train:\n",
            "\tLoss: 0.5281457473933697\n",
            "\tAccuracy: 0.35078645833333333\n",
            "Validation:\n",
            "\tLoss: 0.18797438788414\n",
            "\tAccuracy: 0.28085\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "Epoch: 100\n",
            "Train:\n",
            "\tLoss: 0.5277699050456286\n",
            "\tAccuracy: 0.35205729166666666\n",
            "Validation:\n",
            "\tLoss: 0.18934866073727608\n",
            "\tAccuracy: 0.28225\n",
            "---------------------------------------------------\n",
            "Test:\n",
            "\tLoss: 0.19420661520957946\n",
            "\tAccuracy: 0.35486666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN \n",
        "#Reference: Lab 9\n",
        "#           Lab 10 \n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, first_out_channel, hidden_out_channel, first_filter, hidden_filter, layers, activation, dropout):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, first_out_channel, first_filter), \n",
        "            activation,\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.BatchNorm2d(first_out_channel),\n",
        "        )\n",
        "        self.first_layer = nn.Sequential(\n",
        "            nn.Conv2d(first_out_channel, hidden_out_channel, hidden_filter),\n",
        "            activation,\n",
        "            nn.BatchNorm2d(hidden_out_channel),\n",
        "        )\n",
        "        conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(hidden_out_channel, hidden_out_channel, hidden_filter),\n",
        "            activation,\n",
        "            nn.BatchNorm2d(hidden_out_channel),\n",
        "        )\n",
        "        self.conv_layers = nn.ModuleList([conv_layer for i in range(layers)])\n",
        "\n",
        "        self.fully_connected1 = nn.Sequential(\n",
        "            nn.LazyLinear(128),\n",
        "            activation,\n",
        "        )\n",
        "        self.fully_connected2 = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            activation,\n",
        "        )\n",
        "        self.out = nn.Linear(64, 30)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.first_layer(x)\n",
        "        for conv_layer in self.conv_layers:\n",
        "          x = conv_layer(x)\n",
        "          x = self.dropout(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fully_connected1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fully_connected2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out(x)\n",
        "        n1 = x[:, :10]\n",
        "        n2 = x[:, 10:20]\n",
        "        n3 = x[:, 20:30]\n",
        "        return [n1, n2, n3]\n",
        "\n"
      ],
      "metadata": {
        "id": "194HVgHr8Xfu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process(input_units, output_units, input_filter, hidden_filter, layers, active, momentum, lr, batch_size, dropout, epochs, final=False):\n",
        "  activation = activation_function(active)\n",
        "  \n",
        "  net = CNN(input_units, output_units, input_filter, hidden_filter, layers, activation, dropout)\n",
        "  \n",
        "  optimizer = optim.SGD(net.parameters(), lr, momentum)\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  \n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  \n",
        "  net.to(device)\n",
        "\n",
        "  trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  validloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "  testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  best_acc = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print('---------------------------------------------------')\n",
        "    print(f'Epoch: {epoch+1}/{epochs}')\n",
        "    train_loss, train_acc = training(net, device, trainloader, criterion, optimizer)\n",
        "    print(f'Train:')\n",
        "    print(f'\\tLoss: {train_loss}')\n",
        "    print(f'\\tAccuracy: {train_acc}')\n",
        "    val_loss, val_acc = testing(net, device, validloader, criterion)\n",
        "    print(f'Validation:')\n",
        "    print(f'\\tLoss: {val_loss}')\n",
        "    print(f'\\tAccuracy: {val_acc}')\n",
        "    print('---------------------------------------------------')\n",
        "    if val_acc >= best_acc:\n",
        "      best_acc = val_acc\n",
        "  if final:\n",
        "    test_loss, test_acc = testing(net, device, testloader, criterion)\n",
        "    print('===================================================')\n",
        "    print('Test:')\n",
        "    print(f'\\tLoss: {test_loss}')\n",
        "    print(f'\\tAccuracy: {test_acc}')\n",
        "    print('===================================================')\n",
        "    best_acc = test_acc\n",
        "  return best_acc, net\n",
        "  "
      ],
      "metadata": {
        "id": "KV06UUgqS8ek"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Main\n",
        "\n",
        "def main_task2_2(num_samples=20, num_epochs=10):\n",
        "  best_acc = 0\n",
        "  best_net = None\n",
        "  best_input_units, best_output_units, best_input_filter, best_hidden_filter, best_layers, best_active, best_lr, best_momentum, best_batch_size, best_dropout = None, None, None, None, None, None, None, None, None, None\n",
        "  for i in range(num_samples):\n",
        "    print('____________________________________________________________________\\n')\n",
        "    print(f'Sample {i+1}/{num_samples}')\n",
        "    print('____________________________________________________________________\\n')\n",
        "      \n",
        "    input_units = 2 ** np.random.randint(1, 6)\n",
        "    output_units = 2 ** np.random.randint(1, 6)\n",
        "    input_filter = np.random.choice([3,5])\n",
        "    hidden_filter = np.random.choice([3,5])\n",
        "    layers = np.random.randint(1, 5)\n",
        "    active = np.random.choice([\"relu\", \"leaky\", \"elu\", \"hardswish\", \"selu\", \"silu\"])\n",
        "    lr = np.random.uniform(0.1, 0.00001)\n",
        "    momentum = np.random.uniform(0, 1.0)\n",
        "    batch_size = 4 ** np.random.randint(3, 6)\n",
        "    dropout = np.random.uniform(0, 0.5)\n",
        "    \n",
        "    sample_acc, sample_net = process(input_units, output_units, input_filter, hidden_filter, layers, active, momentum, lr, batch_size, dropout, num_epochs)\n",
        "\n",
        "    if sample_acc > best_acc:\n",
        "      best_acc = sample_acc\n",
        "      best_net = sample_net\n",
        "      best_input_units, best_output_units, best_input_filter, best_hidden_filter, best_layers, best_active, best_lr, best_momentum, best_batch_size, best_dropout = input_units, output_units, input_filter, hidden_filter, layers, active, lr, momentum, batch_size, dropout\n",
        "\n",
        "  print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n')\n",
        "  print(\"Best Sample:\")\n",
        "  print(f'\\tAccuracy: {best_acc}')\n",
        "  print(f'\\tInput Output Channels: {best_input_units}')\n",
        "  print(f'\\tHidden Output Channels: {best_output_units}')\n",
        "  print(f'\\tInput Kernel: {best_input_filter}')\n",
        "  print(f'\\tHidden Kernel: {best_hidden_filter}')\n",
        "  print(f'\\t\\tHidden Layers: {best_layers}')\n",
        "  print(f'\\t\\tLearning Rate: {best_lr}')\n",
        "  print(f'\\t\\tMomentum: {best_momentum}')\n",
        "  print(f'\\t\\tBatch Size: {best_batch_size}')\n",
        "  print(f'\\t\\tDropout Probability: {best_dropout}')\n",
        "  print(f'\\t\\tActivation Function: {best_active}')\n",
        "  print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n')\n",
        "  \n",
        "  return best_net\n",
        "\n",
        "best_hypertune_cnn = main_task2_2(5, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYV1PFcxS_01",
        "outputId": "121fa8f3-9748-4c7a-efe5-a3f02940217a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "____________________________________________________________________\n",
            "\n",
            "Sample 1/5\n",
            "____________________________________________________________________\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "Epoch: 1/25\n",
            "Train:\n",
            "\tLoss: 0.7007718977928161\n",
            "\tAccuracy: 0.12698437499999998\n",
            "Validation:\n",
            "\tLoss: 0.21745612728595734\n",
            "\tAccuracy: 0.20563333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/25\n",
            "Train:\n",
            "\tLoss: 0.6479294838905334\n",
            "\tAccuracy: 0.20060416666666667\n",
            "Validation:\n",
            "\tLoss: 0.19720813894271852\n",
            "\tAccuracy: 0.2813833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/25\n",
            "Train:\n",
            "\tLoss: 0.6053323397636413\n",
            "\tAccuracy: 0.25271354166666665\n",
            "Validation:\n",
            "\tLoss: 0.19856909573078155\n",
            "\tAccuracy: 0.27575\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/25\n",
            "Train:\n",
            "\tLoss: 0.5683043313026428\n",
            "\tAccuracy: 0.296703125\n",
            "Validation:\n",
            "\tLoss: 0.20344017302989958\n",
            "\tAccuracy: 0.305\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/25\n",
            "Train:\n",
            "\tLoss: 0.5356298360824585\n",
            "\tAccuracy: 0.33625\n",
            "Validation:\n",
            "\tLoss: 0.28155294799804687\n",
            "\tAccuracy: 0.12035000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/25\n",
            "Train:\n",
            "\tLoss: 0.5134390773773193\n",
            "\tAccuracy: 0.362515625\n",
            "Validation:\n",
            "\tLoss: 0.24079234325885773\n",
            "\tAccuracy: 0.13441666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/25\n",
            "Train:\n",
            "\tLoss: 0.4967374699115753\n",
            "\tAccuracy: 0.3828958333333333\n",
            "Validation:\n",
            "\tLoss: 0.16823897850513458\n",
            "\tAccuracy: 0.4262\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/25\n",
            "Train:\n",
            "\tLoss: 0.4828776867389679\n",
            "\tAccuracy: 0.39953125\n",
            "Validation:\n",
            "\tLoss: 0.17283458054065703\n",
            "\tAccuracy: 0.29615\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/25\n",
            "Train:\n",
            "\tLoss: 0.47019590735435485\n",
            "\tAccuracy: 0.413375\n",
            "Validation:\n",
            "\tLoss: 0.24416636002063752\n",
            "\tAccuracy: 0.08856666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/25\n",
            "Train:\n",
            "\tLoss: 0.4614658896923065\n",
            "\tAccuracy: 0.4225\n",
            "Validation:\n",
            "\tLoss: 0.19145074105262758\n",
            "\tAccuracy: 0.14606666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/25\n",
            "Train:\n",
            "\tLoss: 0.4536597964763641\n",
            "\tAccuracy: 0.4283645833333333\n",
            "Validation:\n",
            "\tLoss: 0.17239544916152955\n",
            "\tAccuracy: 0.31625000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/25\n",
            "Train:\n",
            "\tLoss: 0.4471595435142517\n",
            "\tAccuracy: 0.43423958333333335\n",
            "Validation:\n",
            "\tLoss: 0.2599837348461151\n",
            "\tAccuracy: 0.10583333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/25\n",
            "Train:\n",
            "\tLoss: 0.4442189629077911\n",
            "\tAccuracy: 0.43563541666666666\n",
            "Validation:\n",
            "\tLoss: 0.22475713860988616\n",
            "\tAccuracy: 0.11218333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/25\n",
            "Train:\n",
            "\tLoss: 0.4358399088382721\n",
            "\tAccuracy: 0.4448333333333333\n",
            "Validation:\n",
            "\tLoss: 0.27408416390419005\n",
            "\tAccuracy: 0.08850000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/25\n",
            "Train:\n",
            "\tLoss: 0.4290979051589966\n",
            "\tAccuracy: 0.45135416666666667\n",
            "Validation:\n",
            "\tLoss: 0.20456650924682618\n",
            "\tAccuracy: 0.13\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/25\n",
            "Train:\n",
            "\tLoss: 0.4258994507789612\n",
            "\tAccuracy: 0.454484375\n",
            "Validation:\n",
            "\tLoss: 0.17277187538146974\n",
            "\tAccuracy: 0.36075\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/25\n",
            "Train:\n",
            "\tLoss: 0.42011150431632993\n",
            "\tAccuracy: 0.4632135416666667\n",
            "Validation:\n",
            "\tLoss: 0.2540483849048614\n",
            "\tAccuracy: 0.12268333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/25\n",
            "Train:\n",
            "\tLoss: 0.4156257755756378\n",
            "\tAccuracy: 0.467828125\n",
            "Validation:\n",
            "\tLoss: 0.16753955352306366\n",
            "\tAccuracy: 0.4054666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/25\n",
            "Train:\n",
            "\tLoss: 0.41505832719802854\n",
            "\tAccuracy: 0.46899479166666663\n",
            "Validation:\n",
            "\tLoss: 0.18608913934230806\n",
            "\tAccuracy: 0.21386666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/25\n",
            "Train:\n",
            "\tLoss: 0.4086667063236237\n",
            "\tAccuracy: 0.476640625\n",
            "Validation:\n",
            "\tLoss: 0.22250377857685089\n",
            "\tAccuracy: 0.2015\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/25\n",
            "Train:\n",
            "\tLoss: 0.4083191459178925\n",
            "\tAccuracy: 0.47715625\n",
            "Validation:\n",
            "\tLoss: 0.17318482542037963\n",
            "\tAccuracy: 0.39148333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/25\n",
            "Train:\n",
            "\tLoss: 0.4042413532733917\n",
            "\tAccuracy: 0.4833645833333333\n",
            "Validation:\n",
            "\tLoss: 0.1714037297964096\n",
            "\tAccuracy: 0.3952\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/25\n",
            "Train:\n",
            "\tLoss: 0.40109740376472475\n",
            "\tAccuracy: 0.486375\n",
            "Validation:\n",
            "\tLoss: 0.3821740727424622\n",
            "\tAccuracy: 0.08968333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/25\n",
            "Train:\n",
            "\tLoss: 0.39943569445610044\n",
            "\tAccuracy: 0.49034374999999997\n",
            "Validation:\n",
            "\tLoss: 0.15865958988666534\n",
            "\tAccuracy: 0.39635000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/25\n",
            "Train:\n",
            "\tLoss: 0.39667182755470276\n",
            "\tAccuracy: 0.49141145833333333\n",
            "Validation:\n",
            "\tLoss: 0.18117808651924133\n",
            "\tAccuracy: 0.3191666666666667\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 2/5\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "Epoch: 1/25\n",
            "Train:\n",
            "\tLoss: 0.3410236144065857\n",
            "\tAccuracy: 0.592234375\n",
            "Validation:\n",
            "\tLoss: 0.35013982057571413\n",
            "\tAccuracy: 0.22205\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/25\n",
            "Train:\n",
            "\tLoss: 0.15228667570650578\n",
            "\tAccuracy: 0.8330520833333334\n",
            "Validation:\n",
            "\tLoss: 0.3442258003354073\n",
            "\tAccuracy: 0.22178333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/25\n",
            "Train:\n",
            "\tLoss: 0.11786713265255093\n",
            "\tAccuracy: 0.8739374999999999\n",
            "Validation:\n",
            "\tLoss: 0.36025981414318087\n",
            "\tAccuracy: 0.24211666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/25\n",
            "Train:\n",
            "\tLoss: 0.10181913797929883\n",
            "\tAccuracy: 0.8930885416666666\n",
            "Validation:\n",
            "\tLoss: 0.4630133935213089\n",
            "\tAccuracy: 0.2717333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/25\n",
            "Train:\n",
            "\tLoss: 0.09123354754596949\n",
            "\tAccuracy: 0.9049166666666666\n",
            "Validation:\n",
            "\tLoss: 0.643657617688179\n",
            "\tAccuracy: 0.2876666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/25\n",
            "Train:\n",
            "\tLoss: 0.08465546133741736\n",
            "\tAccuracy: 0.9116770833333333\n",
            "Validation:\n",
            "\tLoss: 0.3116433818340302\n",
            "\tAccuracy: 0.3363166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/25\n",
            "Train:\n",
            "\tLoss: 0.07913991521671414\n",
            "\tAccuracy: 0.9183072916666666\n",
            "Validation:\n",
            "\tLoss: 0.4877314630746841\n",
            "\tAccuracy: 0.33965\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/25\n",
            "Train:\n",
            "\tLoss: 0.07430150187760591\n",
            "\tAccuracy: 0.9228541666666666\n",
            "Validation:\n",
            "\tLoss: 0.3010342608690262\n",
            "\tAccuracy: 0.32663333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/25\n",
            "Train:\n",
            "\tLoss: 0.07130457095243037\n",
            "\tAccuracy: 0.9263802083333333\n",
            "Validation:\n",
            "\tLoss: 0.5125135184526444\n",
            "\tAccuracy: 0.33468333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/25\n",
            "Train:\n",
            "\tLoss: 0.06811275747232139\n",
            "\tAccuracy: 0.9293541666666666\n",
            "Validation:\n",
            "\tLoss: 0.2825103988647461\n",
            "\tAccuracy: 0.40976666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/25\n",
            "Train:\n",
            "\tLoss: 0.06555644494667649\n",
            "\tAccuracy: 0.9319375\n",
            "Validation:\n",
            "\tLoss: 0.57690620803833\n",
            "\tAccuracy: 0.31598333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/25\n",
            "Train:\n",
            "\tLoss: 0.06302038524486124\n",
            "\tAccuracy: 0.9350677083333333\n",
            "Validation:\n",
            "\tLoss: 0.30115935558080675\n",
            "\tAccuracy: 0.3550666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/25\n",
            "Train:\n",
            "\tLoss: 0.06095824764110148\n",
            "\tAccuracy: 0.9363020833333333\n",
            "Validation:\n",
            "\tLoss: 0.2740526644587517\n",
            "\tAccuracy: 0.3621166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/25\n",
            "Train:\n",
            "\tLoss: 0.05932671178877354\n",
            "\tAccuracy: 0.9387239583333333\n",
            "Validation:\n",
            "\tLoss: 0.2677555658817291\n",
            "\tAccuracy: 0.41681666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/25\n",
            "Train:\n",
            "\tLoss: 0.05713510250858962\n",
            "\tAccuracy: 0.9411666666666666\n",
            "Validation:\n",
            "\tLoss: 0.2593313550949097\n",
            "\tAccuracy: 0.43063333333333337\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/25\n",
            "Train:\n",
            "\tLoss: 0.056177098704501986\n",
            "\tAccuracy: 0.9417916666666666\n",
            "Validation:\n",
            "\tLoss: 0.2733271214962006\n",
            "\tAccuracy: 0.3412\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/25\n",
            "Train:\n",
            "\tLoss: 0.05512754660472274\n",
            "\tAccuracy: 0.9430833333333333\n",
            "Validation:\n",
            "\tLoss: 0.31572092628479004\n",
            "\tAccuracy: 0.40826666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/25\n",
            "Train:\n",
            "\tLoss: 0.05337495724670589\n",
            "\tAccuracy: 0.9448124999999999\n",
            "Validation:\n",
            "\tLoss: 0.25307785606384275\n",
            "\tAccuracy: 0.43085\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/25\n",
            "Train:\n",
            "\tLoss: 0.051588265614584086\n",
            "\tAccuracy: 0.9464374999999999\n",
            "Validation:\n",
            "\tLoss: 0.6726198799610138\n",
            "\tAccuracy: 0.26816666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/25\n",
            "Train:\n",
            "\tLoss: 0.05125233444944024\n",
            "\tAccuracy: 0.9469427083333333\n",
            "Validation:\n",
            "\tLoss: 0.48884348142147066\n",
            "\tAccuracy: 0.28925\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/25\n",
            "Train:\n",
            "\tLoss: 0.050180734928697346\n",
            "\tAccuracy: 0.94778125\n",
            "Validation:\n",
            "\tLoss: 0.2345139425098896\n",
            "\tAccuracy: 0.4171166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/25\n",
            "Train:\n",
            "\tLoss: 0.049571165496483445\n",
            "\tAccuracy: 0.9485104166666667\n",
            "Validation:\n",
            "\tLoss: 0.26623252952098847\n",
            "\tAccuracy: 0.3811333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/25\n",
            "Train:\n",
            "\tLoss: 0.0484634105283767\n",
            "\tAccuracy: 0.9504166666666667\n",
            "Validation:\n",
            "\tLoss: 0.24488242098689078\n",
            "\tAccuracy: 0.42360000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/25\n",
            "Train:\n",
            "\tLoss: 0.04762213606480509\n",
            "\tAccuracy: 0.9509479166666667\n",
            "Validation:\n",
            "\tLoss: 0.32772458732128146\n",
            "\tAccuracy: 0.3045\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/25\n",
            "Train:\n",
            "\tLoss: 0.04700326375477016\n",
            "\tAccuracy: 0.9511562499999999\n",
            "Validation:\n",
            "\tLoss: 0.33100200885534287\n",
            "\tAccuracy: 0.3846333333333333\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 3/5\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "Epoch: 1/25\n",
            "Train:\n",
            "\tLoss: 0.6715833075046539\n",
            "\tAccuracy: 0.16469791666666667\n",
            "Validation:\n",
            "\tLoss: 0.20243251180648802\n",
            "\tAccuracy: 0.2150166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/25\n",
            "Train:\n",
            "\tLoss: 0.44430032968521116\n",
            "\tAccuracy: 0.48451041666666667\n",
            "Validation:\n",
            "\tLoss: 0.09325298744440079\n",
            "\tAccuracy: 0.5624833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/25\n",
            "Train:\n",
            "\tLoss: 0.22274999660253525\n",
            "\tAccuracy: 0.7581510416666667\n",
            "Validation:\n",
            "\tLoss: 0.25407234179973603\n",
            "\tAccuracy: 0.1841\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/25\n",
            "Train:\n",
            "\tLoss: 0.14488242307305335\n",
            "\tAccuracy: 0.850140625\n",
            "Validation:\n",
            "\tLoss: 0.09894951170682907\n",
            "\tAccuracy: 0.5705166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/25\n",
            "Train:\n",
            "\tLoss: 0.10798243752121925\n",
            "\tAccuracy: 0.8909322916666667\n",
            "Validation:\n",
            "\tLoss: 0.12510659229755403\n",
            "\tAccuracy: 0.4555166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/25\n",
            "Train:\n",
            "\tLoss: 0.0904864930510521\n",
            "\tAccuracy: 0.9089270833333333\n",
            "Validation:\n",
            "\tLoss: 0.04213686960935593\n",
            "\tAccuracy: 0.68225\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/25\n",
            "Train:\n",
            "\tLoss: 0.07801898945868015\n",
            "\tAccuracy: 0.9213333333333333\n",
            "Validation:\n",
            "\tLoss: 0.03639111724495888\n",
            "\tAccuracy: 0.7191166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/25\n",
            "Train:\n",
            "\tLoss: 0.06831696797907352\n",
            "\tAccuracy: 0.9311875\n",
            "Validation:\n",
            "\tLoss: 0.05835018682479858\n",
            "\tAccuracy: 0.64695\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/25\n",
            "Train:\n",
            "\tLoss: 0.06206642955541611\n",
            "\tAccuracy: 0.9376822916666666\n",
            "Validation:\n",
            "\tLoss: 0.03849005448818207\n",
            "\tAccuracy: 0.6730833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/25\n",
            "Train:\n",
            "\tLoss: 0.05679710900783539\n",
            "\tAccuracy: 0.942328125\n",
            "Validation:\n",
            "\tLoss: 0.19730895686149597\n",
            "\tAccuracy: 0.40598333333333336\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/25\n",
            "Train:\n",
            "\tLoss: 0.05284223403036594\n",
            "\tAccuracy: 0.94709375\n",
            "Validation:\n",
            "\tLoss: 0.019614768609404563\n",
            "\tAccuracy: 0.75\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/25\n",
            "Train:\n",
            "\tLoss: 0.04988921995460987\n",
            "\tAccuracy: 0.9495\n",
            "Validation:\n",
            "\tLoss: 0.0150613923817873\n",
            "\tAccuracy: 0.7689\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/25\n",
            "Train:\n",
            "\tLoss: 0.047521356120705606\n",
            "\tAccuracy: 0.9516458333333333\n",
            "Validation:\n",
            "\tLoss: 0.016546134874224662\n",
            "\tAccuracy: 0.7562500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/25\n",
            "Train:\n",
            "\tLoss: 0.04471676407754421\n",
            "\tAccuracy: 0.9546822916666666\n",
            "Validation:\n",
            "\tLoss: 0.12977874600887299\n",
            "\tAccuracy: 0.3993333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/25\n",
            "Train:\n",
            "\tLoss: 0.043206586837768554\n",
            "\tAccuracy: 0.9561197916666666\n",
            "Validation:\n",
            "\tLoss: 0.0167948609739542\n",
            "\tAccuracy: 0.7623666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/25\n",
            "Train:\n",
            "\tLoss: 0.04139774199575186\n",
            "\tAccuracy: 0.957578125\n",
            "Validation:\n",
            "\tLoss: 0.10013391155004502\n",
            "\tAccuracy: 0.5334666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/25\n",
            "Train:\n",
            "\tLoss: 0.03930198461562395\n",
            "\tAccuracy: 0.9589791666666666\n",
            "Validation:\n",
            "\tLoss: 0.10761708837747574\n",
            "\tAccuracy: 0.4791\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/25\n",
            "Train:\n",
            "\tLoss: 0.03836653742194176\n",
            "\tAccuracy: 0.9602604166666666\n",
            "Validation:\n",
            "\tLoss: 0.08800930732488632\n",
            "\tAccuracy: 0.5295500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/25\n",
            "Train:\n",
            "\tLoss: 0.037208456180989745\n",
            "\tAccuracy: 0.9617812499999999\n",
            "Validation:\n",
            "\tLoss: 0.036575161427259445\n",
            "\tAccuracy: 0.6620166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/25\n",
            "Train:\n",
            "\tLoss: 0.035668312817811965\n",
            "\tAccuracy: 0.9633020833333333\n",
            "Validation:\n",
            "\tLoss: 0.11426589876413346\n",
            "\tAccuracy: 0.50115\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/25\n",
            "Train:\n",
            "\tLoss: 0.03525849326699972\n",
            "\tAccuracy: 0.9634583333333333\n",
            "Validation:\n",
            "\tLoss: 0.021543229684233667\n",
            "\tAccuracy: 0.7442500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/25\n",
            "Train:\n",
            "\tLoss: 0.03454019083082676\n",
            "\tAccuracy: 0.9640052083333333\n",
            "Validation:\n",
            "\tLoss: 0.019797748804092408\n",
            "\tAccuracy: 0.7623000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/25\n",
            "Train:\n",
            "\tLoss: 0.033062321208417414\n",
            "\tAccuracy: 0.9651927083333333\n",
            "Validation:\n",
            "\tLoss: 0.02116799545288086\n",
            "\tAccuracy: 0.7232666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/25\n",
            "Train:\n",
            "\tLoss: 0.03261041896045208\n",
            "\tAccuracy: 0.9655833333333333\n",
            "Validation:\n",
            "\tLoss: 0.03687002271413803\n",
            "\tAccuracy: 0.6453833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/25\n",
            "Train:\n",
            "\tLoss: 0.03184377650916576\n",
            "\tAccuracy: 0.9663802083333333\n",
            "Validation:\n",
            "\tLoss: 0.5559918332099915\n",
            "\tAccuracy: 0.22870000000000001\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 4/5\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "Epoch: 1/25\n",
            "Train:\n",
            "\tLoss: 0.6901929097175599\n",
            "\tAccuracy: 0.11120833333333333\n",
            "Validation:\n",
            "\tLoss: 0.2292092115879059\n",
            "\tAccuracy: 0.10883333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/25\n",
            "Train:\n",
            "\tLoss: 0.6832421216964721\n",
            "\tAccuracy: 0.15046874999999998\n",
            "Validation:\n",
            "\tLoss: 0.22547958397865295\n",
            "\tAccuracy: 0.14200000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/25\n",
            "Train:\n",
            "\tLoss: 0.664828293800354\n",
            "\tAccuracy: 0.19486979166666665\n",
            "Validation:\n",
            "\tLoss: 0.21437625980377198\n",
            "\tAccuracy: 0.1947\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/25\n",
            "Train:\n",
            "\tLoss: 0.6100157952308655\n",
            "\tAccuracy: 0.2640208333333333\n",
            "Validation:\n",
            "\tLoss: 0.20451443004608155\n",
            "\tAccuracy: 0.18453333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/25\n",
            "Train:\n",
            "\tLoss: 0.5258722205162049\n",
            "\tAccuracy: 0.3611875\n",
            "Validation:\n",
            "\tLoss: 0.15376973187923432\n",
            "\tAccuracy: 0.3937333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/25\n",
            "Train:\n",
            "\tLoss: 0.4460629699230194\n",
            "\tAccuracy: 0.45769791666666665\n",
            "Validation:\n",
            "\tLoss: 0.1166362242102623\n",
            "\tAccuracy: 0.47195000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/25\n",
            "Train:\n",
            "\tLoss: 0.378049535036087\n",
            "\tAccuracy: 0.5491979166666666\n",
            "Validation:\n",
            "\tLoss: 0.1688867621421814\n",
            "\tAccuracy: 0.2911\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/25\n",
            "Train:\n",
            "\tLoss: 0.3228826487064362\n",
            "\tAccuracy: 0.62234375\n",
            "Validation:\n",
            "\tLoss: 0.136572927236557\n",
            "\tAccuracy: 0.42838333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/25\n",
            "Train:\n",
            "\tLoss: 0.2793188467025757\n",
            "\tAccuracy: 0.6767552083333334\n",
            "Validation:\n",
            "\tLoss: 0.1015292610526085\n",
            "\tAccuracy: 0.49723333333333336\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/25\n",
            "Train:\n",
            "\tLoss: 0.2476680933237076\n",
            "\tAccuracy: 0.7192760416666666\n",
            "Validation:\n",
            "\tLoss: 0.08624546402692795\n",
            "\tAccuracy: 0.5681833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/25\n",
            "Train:\n",
            "\tLoss: 0.22198623645305635\n",
            "\tAccuracy: 0.7533489583333333\n",
            "Validation:\n",
            "\tLoss: 0.06921248549222946\n",
            "\tAccuracy: 0.6196833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/25\n",
            "Train:\n",
            "\tLoss: 0.20456199097633362\n",
            "\tAccuracy: 0.7741354166666666\n",
            "Validation:\n",
            "\tLoss: 0.12160265970230102\n",
            "\tAccuracy: 0.43895\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/25\n",
            "Train:\n",
            "\tLoss: 0.19025109601020812\n",
            "\tAccuracy: 0.7926354166666666\n",
            "Validation:\n",
            "\tLoss: 0.1273117368221283\n",
            "\tAccuracy: 0.41490000000000005\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/25\n",
            "Train:\n",
            "\tLoss: 0.17781925594806672\n",
            "\tAccuracy: 0.8063958333333333\n",
            "Validation:\n",
            "\tLoss: 0.12048440766334534\n",
            "\tAccuracy: 0.43560000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/25\n",
            "Train:\n",
            "\tLoss: 0.16735840845108033\n",
            "\tAccuracy: 0.8188541666666667\n",
            "Validation:\n",
            "\tLoss: 0.06423027992248535\n",
            "\tAccuracy: 0.6387666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/25\n",
            "Train:\n",
            "\tLoss: 0.15861013066768645\n",
            "\tAccuracy: 0.8299010416666667\n",
            "Validation:\n",
            "\tLoss: 0.07852802723646164\n",
            "\tAccuracy: 0.5486666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/25\n",
            "Train:\n",
            "\tLoss: 0.15153753471374512\n",
            "\tAccuracy: 0.837609375\n",
            "Validation:\n",
            "\tLoss: 0.12003018862009049\n",
            "\tAccuracy: 0.4531\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/25\n",
            "Train:\n",
            "\tLoss: 0.1460758763551712\n",
            "\tAccuracy: 0.8444114583333333\n",
            "Validation:\n",
            "\tLoss: 0.1334651946425438\n",
            "\tAccuracy: 0.3509333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/25\n",
            "Train:\n",
            "\tLoss: 0.14002089750766755\n",
            "\tAccuracy: 0.8506822916666666\n",
            "Validation:\n",
            "\tLoss: 0.17656178319454194\n",
            "\tAccuracy: 0.28950000000000004\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/25\n",
            "Train:\n",
            "\tLoss: 0.1353226054906845\n",
            "\tAccuracy: 0.857015625\n",
            "Validation:\n",
            "\tLoss: 0.13265432059764862\n",
            "\tAccuracy: 0.3370166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/25\n",
            "Train:\n",
            "\tLoss: 0.13046696120500564\n",
            "\tAccuracy: 0.8623697916666666\n",
            "Validation:\n",
            "\tLoss: 0.19789791810512541\n",
            "\tAccuracy: 0.2782\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/25\n",
            "Train:\n",
            "\tLoss: 0.1268458744287491\n",
            "\tAccuracy: 0.8662656249999999\n",
            "Validation:\n",
            "\tLoss: 0.10830317980051041\n",
            "\tAccuracy: 0.43115000000000003\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/25\n",
            "Train:\n",
            "\tLoss: 0.12271926391124725\n",
            "\tAccuracy: 0.8707916666666666\n",
            "Validation:\n",
            "\tLoss: 0.1242156435251236\n",
            "\tAccuracy: 0.3972333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/25\n",
            "Train:\n",
            "\tLoss: 0.11883628213405609\n",
            "\tAccuracy: 0.8757083333333333\n",
            "Validation:\n",
            "\tLoss: 0.20771930611133577\n",
            "\tAccuracy: 0.25798333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/25\n",
            "Train:\n",
            "\tLoss: 0.11644030660390854\n",
            "\tAccuracy: 0.878921875\n",
            "Validation:\n",
            "\tLoss: 0.15923832547664643\n",
            "\tAccuracy: 0.3292\n",
            "---------------------------------------------------\n",
            "____________________________________________________________________\n",
            "\n",
            "Sample 5/5\n",
            "____________________________________________________________________\n",
            "\n",
            "---------------------------------------------------\n",
            "Epoch: 1/25\n",
            "Train:\n",
            "\tLoss: 0.6931219370365143\n",
            "\tAccuracy: 0.10309895833333332\n",
            "Validation:\n",
            "\tLoss: 0.23033096396923064\n",
            "\tAccuracy: 0.08556666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/25\n",
            "Train:\n",
            "\tLoss: 0.6909701700210571\n",
            "\tAccuracy: 0.10850520833333333\n",
            "Validation:\n",
            "\tLoss: 0.23013721525669098\n",
            "\tAccuracy: 0.09351666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/25\n",
            "Train:\n",
            "\tLoss: 0.6881249601840973\n",
            "\tAccuracy: 0.12155208333333332\n",
            "Validation:\n",
            "\tLoss: 0.2293182748556137\n",
            "\tAccuracy: 0.11273333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/25\n",
            "Train:\n",
            "\tLoss: 0.6819581270217896\n",
            "\tAccuracy: 0.14444791666666665\n",
            "Validation:\n",
            "\tLoss: 0.22491354954242707\n",
            "\tAccuracy: 0.14205\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/25\n",
            "Train:\n",
            "\tLoss: 0.6636614034175873\n",
            "\tAccuracy: 0.17694270833333334\n",
            "Validation:\n",
            "\tLoss: 0.21445716035366058\n",
            "\tAccuracy: 0.17153333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/25\n",
            "Train:\n",
            "\tLoss: 0.6286474249362946\n",
            "\tAccuracy: 0.22328125\n",
            "Validation:\n",
            "\tLoss: 0.20583465671539306\n",
            "\tAccuracy: 0.20406666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/25\n",
            "Train:\n",
            "\tLoss: 0.5861358871459961\n",
            "\tAccuracy: 0.26321354166666666\n",
            "Validation:\n",
            "\tLoss: 0.195243181347847\n",
            "\tAccuracy: 0.23855\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/25\n",
            "Train:\n",
            "\tLoss: 0.5488972742557525\n",
            "\tAccuracy: 0.30126041666666664\n",
            "Validation:\n",
            "\tLoss: 0.20046081006526947\n",
            "\tAccuracy: 0.24745\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/25\n",
            "Train:\n",
            "\tLoss: 0.5154464958906174\n",
            "\tAccuracy: 0.339875\n",
            "Validation:\n",
            "\tLoss: 0.20225954198837282\n",
            "\tAccuracy: 0.24393333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/25\n",
            "Train:\n",
            "\tLoss: 0.4878605778217316\n",
            "\tAccuracy: 0.37370312499999997\n",
            "Validation:\n",
            "\tLoss: 0.21342990159988404\n",
            "\tAccuracy: 0.1952\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/25\n",
            "Train:\n",
            "\tLoss: 0.4643775932788849\n",
            "\tAccuracy: 0.40103125\n",
            "Validation:\n",
            "\tLoss: 0.21134520351886749\n",
            "\tAccuracy: 0.18848333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/25\n",
            "Train:\n",
            "\tLoss: 0.4447981019020081\n",
            "\tAccuracy: 0.4279114583333333\n",
            "Validation:\n",
            "\tLoss: 0.21352367627620697\n",
            "\tAccuracy: 0.16558333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/25\n",
            "Train:\n",
            "\tLoss: 0.4294927587509155\n",
            "\tAccuracy: 0.4478958333333333\n",
            "Validation:\n",
            "\tLoss: 0.21262581944465636\n",
            "\tAccuracy: 0.16806666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/25\n",
            "Train:\n",
            "\tLoss: 0.41661331152915954\n",
            "\tAccuracy: 0.4665052083333333\n",
            "Validation:\n",
            "\tLoss: 0.2137222660779953\n",
            "\tAccuracy: 0.16411666666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/25\n",
            "Train:\n",
            "\tLoss: 0.4056162074804306\n",
            "\tAccuracy: 0.48333333333333334\n",
            "Validation:\n",
            "\tLoss: 0.21931988787651063\n",
            "\tAccuracy: 0.13915\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/25\n",
            "Train:\n",
            "\tLoss: 0.3962494683265686\n",
            "\tAccuracy: 0.4975104166666667\n",
            "Validation:\n",
            "\tLoss: 0.22352527010440826\n",
            "\tAccuracy: 0.13118333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/25\n",
            "Train:\n",
            "\tLoss: 0.3864328594207764\n",
            "\tAccuracy: 0.5114427083333333\n",
            "Validation:\n",
            "\tLoss: 0.21889148604869843\n",
            "\tAccuracy: 0.13168333333333335\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/25\n",
            "Train:\n",
            "\tLoss: 0.3799746739864349\n",
            "\tAccuracy: 0.52015625\n",
            "Validation:\n",
            "\tLoss: 0.234410612821579\n",
            "\tAccuracy: 0.13721666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/25\n",
            "Train:\n",
            "\tLoss: 0.3704301302433014\n",
            "\tAccuracy: 0.5358645833333333\n",
            "Validation:\n",
            "\tLoss: 0.23818591046333312\n",
            "\tAccuracy: 0.1071\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/25\n",
            "Train:\n",
            "\tLoss: 0.3635219415426254\n",
            "\tAccuracy: 0.5470885416666667\n",
            "Validation:\n",
            "\tLoss: 0.23923928856849672\n",
            "\tAccuracy: 0.10211666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/25\n",
            "Train:\n",
            "\tLoss: 0.3554259949922562\n",
            "\tAccuracy: 0.55853125\n",
            "Validation:\n",
            "\tLoss: 0.2587398766279221\n",
            "\tAccuracy: 0.09961666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/25\n",
            "Train:\n",
            "\tLoss: 0.3491535196304321\n",
            "\tAccuracy: 0.56778125\n",
            "Validation:\n",
            "\tLoss: 0.2642803997993469\n",
            "\tAccuracy: 0.08655\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/25\n",
            "Train:\n",
            "\tLoss: 0.34264721286296845\n",
            "\tAccuracy: 0.5772395833333334\n",
            "Validation:\n",
            "\tLoss: 0.2738252873420715\n",
            "\tAccuracy: 0.08198333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/25\n",
            "Train:\n",
            "\tLoss: 0.3375295970439911\n",
            "\tAccuracy: 0.5820416666666667\n",
            "Validation:\n",
            "\tLoss: 0.2947015027999878\n",
            "\tAccuracy: 0.07730000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/25\n",
            "Train:\n",
            "\tLoss: 0.33125447726249696\n",
            "\tAccuracy: 0.5920052083333334\n",
            "Validation:\n",
            "\tLoss: 0.2993680293560028\n",
            "\tAccuracy: 0.07698333333333333\n",
            "---------------------------------------------------\n",
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
            "\n",
            "Best Sample:\n",
            "\tAccuracy: 0.7689\n",
            "\tInput Output Channels: 4\n",
            "\tHidden Output Channels: 8\n",
            "\tInput Kernel: 3\n",
            "\tHidden Kernel: 5\n",
            "\t\tHidden Layers: 1\n",
            "\t\tLearning Rate: 0.062128695444829546\n",
            "\t\tMomentum: 0.33922085849116246\n",
            "\t\tBatch Size: 256\n",
            "\t\tDropout Probability: 0.005428947811590701\n",
            "\t\tActivation Function: leaky\n",
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main_task2_2_best(num_epochs):\n",
        "  input_units = 4\n",
        "  output_units = 8\n",
        "  input_filter = 3\n",
        "  hidden_filter = 5\n",
        "  layers = 1\n",
        "  active = \"leaky\"\n",
        "  lr = 0.062128695444829546\n",
        "  momentum = 0.33922085849116246\n",
        "  batch_size = 256\n",
        "  dropout = 0.005428947811590701\n",
        "  \n",
        "  sample_acc, sample_net = process(input_units, output_units, input_filter, hidden_filter, layers, active, momentum, lr, batch_size, dropout, num_epochs, final=True)\n",
        "  \n",
        "  return sample_net\n",
        "best_cnn = main_task2_2_best(50)"
      ],
      "metadata": {
        "id": "z74fUkhOClb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377f5a5e-e022-4142-f88a-6ca7c9158e46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "Epoch: 1/50\n",
            "Train:\n",
            "\tLoss: 0.6709928939342499\n",
            "\tAccuracy: 0.18438541666666666\n",
            "Validation:\n",
            "\tLoss: 0.20429083228111267\n",
            "\tAccuracy: 0.26021666666666665\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 2/50\n",
            "Train:\n",
            "\tLoss: 0.42453560316562655\n",
            "\tAccuracy: 0.5168177083333333\n",
            "Validation:\n",
            "\tLoss: 0.2046163569688797\n",
            "\tAccuracy: 0.22353333333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 3/50\n",
            "Train:\n",
            "\tLoss: 0.21105537366867066\n",
            "\tAccuracy: 0.7760833333333333\n",
            "Validation:\n",
            "\tLoss: 0.29511822485923767\n",
            "\tAccuracy: 0.3415\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 4/50\n",
            "Train:\n",
            "\tLoss: 0.1273428860604763\n",
            "\tAccuracy: 0.8733385416666667\n",
            "Validation:\n",
            "\tLoss: 0.47874233865737914\n",
            "\tAccuracy: 0.12190000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 5/50\n",
            "Train:\n",
            "\tLoss: 0.09256773456931114\n",
            "\tAccuracy: 0.9082552083333333\n",
            "Validation:\n",
            "\tLoss: 0.3423723683357239\n",
            "\tAccuracy: 0.41223333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 6/50\n",
            "Train:\n",
            "\tLoss: 0.07799226236343383\n",
            "\tAccuracy: 0.9219999999999999\n",
            "Validation:\n",
            "\tLoss: 0.03716387018561363\n",
            "\tAccuracy: 0.7288833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 7/50\n",
            "Train:\n",
            "\tLoss: 0.06835850951075553\n",
            "\tAccuracy: 0.9317656249999999\n",
            "Validation:\n",
            "\tLoss: 0.037760102599859235\n",
            "\tAccuracy: 0.7236833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 8/50\n",
            "Train:\n",
            "\tLoss: 0.060951757863163945\n",
            "\tAccuracy: 0.939140625\n",
            "Validation:\n",
            "\tLoss: 1.3049789123535156\n",
            "\tAccuracy: 0.10236666666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 9/50\n",
            "Train:\n",
            "\tLoss: 0.05681653840839863\n",
            "\tAccuracy: 0.9429895833333333\n",
            "Validation:\n",
            "\tLoss: 0.03294189530611038\n",
            "\tAccuracy: 0.7227666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 10/50\n",
            "Train:\n",
            "\tLoss: 0.05283016313612461\n",
            "\tAccuracy: 0.9468020833333333\n",
            "Validation:\n",
            "\tLoss: 0.017932272724807262\n",
            "\tAccuracy: 0.7633166666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 11/50\n",
            "Train:\n",
            "\tLoss: 0.0491207854449749\n",
            "\tAccuracy: 0.9503697916666667\n",
            "Validation:\n",
            "\tLoss: 0.03219337384402752\n",
            "\tAccuracy: 0.7351166666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 12/50\n",
            "Train:\n",
            "\tLoss: 0.047173233471810815\n",
            "\tAccuracy: 0.9524010416666666\n",
            "Validation:\n",
            "\tLoss: 0.05588012564182281\n",
            "\tAccuracy: 0.6801833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 13/50\n",
            "Train:\n",
            "\tLoss: 0.04479831335693598\n",
            "\tAccuracy: 0.9541041666666666\n",
            "Validation:\n",
            "\tLoss: 0.024017296850681304\n",
            "\tAccuracy: 0.7539666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 14/50\n",
            "Train:\n",
            "\tLoss: 0.042890282943844796\n",
            "\tAccuracy: 0.956515625\n",
            "Validation:\n",
            "\tLoss: 0.02653928904235363\n",
            "\tAccuracy: 0.7354333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 15/50\n",
            "Train:\n",
            "\tLoss: 0.04134461750090122\n",
            "\tAccuracy: 0.9576822916666666\n",
            "Validation:\n",
            "\tLoss: 0.018266739808022976\n",
            "\tAccuracy: 0.7595000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 16/50\n",
            "Train:\n",
            "\tLoss: 0.039887276701629164\n",
            "\tAccuracy: 0.958328125\n",
            "Validation:\n",
            "\tLoss: 0.03216510659456253\n",
            "\tAccuracy: 0.7388666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 17/50\n",
            "Train:\n",
            "\tLoss: 0.03936959127336741\n",
            "\tAccuracy: 0.9600104166666666\n",
            "Validation:\n",
            "\tLoss: 0.01632618209719658\n",
            "\tAccuracy: 0.7634333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 18/50\n",
            "Train:\n",
            "\tLoss: 0.03708725428581238\n",
            "\tAccuracy: 0.9617864583333333\n",
            "Validation:\n",
            "\tLoss: 0.013339063994586467\n",
            "\tAccuracy: 0.7691166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 19/50\n",
            "Train:\n",
            "\tLoss: 0.03613838377594948\n",
            "\tAccuracy: 0.9624895833333333\n",
            "Validation:\n",
            "\tLoss: 0.0199471610635519\n",
            "\tAccuracy: 0.7638833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 20/50\n",
            "Train:\n",
            "\tLoss: 0.035392792887985705\n",
            "\tAccuracy: 0.963234375\n",
            "Validation:\n",
            "\tLoss: 0.031663240015506744\n",
            "\tAccuracy: 0.7058166666666666\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 21/50\n",
            "Train:\n",
            "\tLoss: 0.0343031696677208\n",
            "\tAccuracy: 0.9641614583333333\n",
            "Validation:\n",
            "\tLoss: 0.03322544154524803\n",
            "\tAccuracy: 0.72095\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 22/50\n",
            "Train:\n",
            "\tLoss: 0.034057239547371866\n",
            "\tAccuracy: 0.9645364583333333\n",
            "Validation:\n",
            "\tLoss: 1.2783269414901732\n",
            "\tAccuracy: 0.14575000000000002\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 23/50\n",
            "Train:\n",
            "\tLoss: 0.033221914201974866\n",
            "\tAccuracy: 0.9651822916666666\n",
            "Validation:\n",
            "\tLoss: 0.01586983585357666\n",
            "\tAccuracy: 0.7688166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 24/50\n",
            "Train:\n",
            "\tLoss: 0.03237853964418173\n",
            "\tAccuracy: 0.9661093749999999\n",
            "Validation:\n",
            "\tLoss: 0.02149464537203312\n",
            "\tAccuracy: 0.7468833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 25/50\n",
            "Train:\n",
            "\tLoss: 0.03133523805439472\n",
            "\tAccuracy: 0.9674739583333333\n",
            "Validation:\n",
            "\tLoss: 0.022415569782257082\n",
            "\tAccuracy: 0.7607666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 26/50\n",
            "Train:\n",
            "\tLoss: 0.0309662616699934\n",
            "\tAccuracy: 0.9677604166666667\n",
            "Validation:\n",
            "\tLoss: 0.020587467938661574\n",
            "\tAccuracy: 0.7449666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 27/50\n",
            "Train:\n",
            "\tLoss: 0.03074622405320406\n",
            "\tAccuracy: 0.9671927083333333\n",
            "Validation:\n",
            "\tLoss: 0.016309730634093286\n",
            "\tAccuracy: 0.7617166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 28/50\n",
            "Train:\n",
            "\tLoss: 0.02989887922257185\n",
            "\tAccuracy: 0.968671875\n",
            "Validation:\n",
            "\tLoss: 0.026059772431850432\n",
            "\tAccuracy: 0.7339666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 29/50\n",
            "Train:\n",
            "\tLoss: 0.02981290139257908\n",
            "\tAccuracy: 0.9686666666666667\n",
            "Validation:\n",
            "\tLoss: 0.015090716890990735\n",
            "\tAccuracy: 0.7673500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 30/50\n",
            "Train:\n",
            "\tLoss: 0.028260848373174666\n",
            "\tAccuracy: 0.9700208333333333\n",
            "Validation:\n",
            "\tLoss: 0.04403730908036232\n",
            "\tAccuracy: 0.7250500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 31/50\n",
            "Train:\n",
            "\tLoss: 0.028305370021611452\n",
            "\tAccuracy: 0.9702291666666666\n",
            "Validation:\n",
            "\tLoss: 0.013545891460031271\n",
            "\tAccuracy: 0.7679833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 32/50\n",
            "Train:\n",
            "\tLoss: 0.027502527229487896\n",
            "\tAccuracy: 0.9709479166666667\n",
            "Validation:\n",
            "\tLoss: 0.024355809956789015\n",
            "\tAccuracy: 0.7336666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 33/50\n",
            "Train:\n",
            "\tLoss: 0.02705874892324209\n",
            "\tAccuracy: 0.97165625\n",
            "Validation:\n",
            "\tLoss: 0.03206499683856964\n",
            "\tAccuracy: 0.7146\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 34/50\n",
            "Train:\n",
            "\tLoss: 0.027070436172187327\n",
            "\tAccuracy: 0.9711927083333333\n",
            "Validation:\n",
            "\tLoss: 0.026107141360640525\n",
            "\tAccuracy: 0.7370833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 35/50\n",
            "Train:\n",
            "\tLoss: 0.026348601531237362\n",
            "\tAccuracy: 0.971765625\n",
            "Validation:\n",
            "\tLoss: 0.016770870827138424\n",
            "\tAccuracy: 0.7666000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 36/50\n",
            "Train:\n",
            "\tLoss: 0.025879931062459945\n",
            "\tAccuracy: 0.9728958333333333\n",
            "Validation:\n",
            "\tLoss: 0.01192063308134675\n",
            "\tAccuracy: 0.7730166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 37/50\n",
            "Train:\n",
            "\tLoss: 0.026071945760399104\n",
            "\tAccuracy: 0.9719427083333333\n",
            "Validation:\n",
            "\tLoss: 0.012885841593146324\n",
            "\tAccuracy: 0.7736166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 38/50\n",
            "Train:\n",
            "\tLoss: 0.025188919890671967\n",
            "\tAccuracy: 0.9731197916666666\n",
            "Validation:\n",
            "\tLoss: 0.033965874575078485\n",
            "\tAccuracy: 0.7303833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 39/50\n",
            "Train:\n",
            "\tLoss: 0.02451016503944993\n",
            "\tAccuracy: 0.9738020833333333\n",
            "Validation:\n",
            "\tLoss: 0.014375817500054837\n",
            "\tAccuracy: 0.7677666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 40/50\n",
            "Train:\n",
            "\tLoss: 0.02447808485850692\n",
            "\tAccuracy: 0.973796875\n",
            "Validation:\n",
            "\tLoss: 0.07374753335118293\n",
            "\tAccuracy: 0.6849166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 41/50\n",
            "Train:\n",
            "\tLoss: 0.023932871252298354\n",
            "\tAccuracy: 0.9744375\n",
            "Validation:\n",
            "\tLoss: 0.017086533628404142\n",
            "\tAccuracy: 0.7599666666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 42/50\n",
            "Train:\n",
            "\tLoss: 0.023667370975017546\n",
            "\tAccuracy: 0.9742916666666667\n",
            "Validation:\n",
            "\tLoss: 0.018329315714538098\n",
            "\tAccuracy: 0.7552166666666668\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 43/50\n",
            "Train:\n",
            "\tLoss: 0.023857791170477868\n",
            "\tAccuracy: 0.9745520833333333\n",
            "Validation:\n",
            "\tLoss: 0.016458990089595317\n",
            "\tAccuracy: 0.7688166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 44/50\n",
            "Train:\n",
            "\tLoss: 0.023170224152505397\n",
            "\tAccuracy: 0.975078125\n",
            "Validation:\n",
            "\tLoss: 0.029507421433925627\n",
            "\tAccuracy: 0.7525333333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 45/50\n",
            "Train:\n",
            "\tLoss: 0.022844481009989977\n",
            "\tAccuracy: 0.9752916666666667\n",
            "Validation:\n",
            "\tLoss: 0.018158461578190326\n",
            "\tAccuracy: 0.7668833333333334\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 46/50\n",
            "Train:\n",
            "\tLoss: 0.022711175840348007\n",
            "\tAccuracy: 0.9755416666666666\n",
            "Validation:\n",
            "\tLoss: 0.015466125279664993\n",
            "\tAccuracy: 0.7665500000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 47/50\n",
            "Train:\n",
            "\tLoss: 0.02219560606405139\n",
            "\tAccuracy: 0.9754375\n",
            "Validation:\n",
            "\tLoss: 0.0328862482458353\n",
            "\tAccuracy: 0.7333000000000001\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 48/50\n",
            "Train:\n",
            "\tLoss: 0.02260284994542599\n",
            "\tAccuracy: 0.9754166666666666\n",
            "Validation:\n",
            "\tLoss: 0.012290600709617138\n",
            "\tAccuracy: 0.7733166666666667\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 49/50\n",
            "Train:\n",
            "\tLoss: 0.02181700214743614\n",
            "\tAccuracy: 0.9765468749999999\n",
            "Validation:\n",
            "\tLoss: 0.013099238596856595\n",
            "\tAccuracy: 0.7731833333333333\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "Epoch: 50/50\n",
            "Train:\n",
            "\tLoss: 0.021258352380245923\n",
            "\tAccuracy: 0.9771197916666666\n",
            "Validation:\n",
            "\tLoss: 0.01749486444145441\n",
            "\tAccuracy: 0.7626166666666667\n",
            "---------------------------------------------------\n",
            "===================================================\n",
            "Test:\n",
            "\tLoss: 0.01775339352041483\n",
            "\tAccuracy: 0.9516666666666667\n",
            "===================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measuring speed for a model\n",
        "import time\n",
        "\n",
        "def testing_speed(net, device, testloader, criterion):\n",
        "  #Validation/Testing\n",
        "  net.eval()\n",
        "  test_loss = 0.0\n",
        "  test_corrects = 0\n",
        "  all_time = 0\n",
        "  for data, targets in testloader:\n",
        "    ann_time = time.monotonic()\n",
        "    with torch.no_grad():\n",
        "      data = data.to(device).float()\n",
        "      targets = torch.tensor([[int(target[0]), int(target[1]), int(target[2])] for target in targets])\n",
        "      targets = targets.to(device)\n",
        "      \n",
        "      outputs = net(data)\n",
        "      \n",
        "      loss = 0\n",
        "      for i in range(3):\n",
        "        loss = criterion(outputs[i], targets[:, i])\n",
        "        preds = torch.max(outputs[i], 1)[1]\n",
        "        test_corrects += torch.sum(preds == targets[:, i])\n",
        "      loss /= 10\n",
        "      test_loss += loss.item() * data.size(0)\n",
        "    all_time += (time.monotonic() - ann_time)\n",
        "    #print(all_time)\n",
        "  epoch_loss = test_loss / len(testloader.dataset)\n",
        "  epoch_acc = test_corrects.double() / (len(test_data)*3)\n",
        "  all_time = all_time/(len(testloader.dataset)/50)\n",
        "  return epoch_loss, epoch_acc, all_time\n",
        "\n",
        "def get_speed(net):\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  \n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  \n",
        "  net.to(device)\n",
        "\n",
        "  testloader = DataLoader(test_data, batch_size=50, shuffle=True)\n",
        "\n",
        "  test_loss, test_acc, test_time = testing_speed(net, device, testloader, criterion)\n",
        "  print(f'\\tLoss: {test_loss}')\n",
        "  print(f'\\tAccuracy: {test_acc}')\n",
        "  return test_acc, test_time\n",
        "  "
      ],
      "metadata": {
        "id": "dmXxJrV47t56"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count parameters\n",
        "#Reference: https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325\n",
        "\n",
        "def count_parameters(model): \n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "JMHqjWfMhe__"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Measuring speed for ANN model\n",
        "ANN_parameters = count_parameters(best_task2_1)\n",
        "ANN_acc, ANN_speed = get_speed(best_task2_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Md9XE8NapZ",
        "outputId": "3b0ac167-b962-402a-e4a8-8b9fdbb4e92a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLoss: 0.19420661445707083\n",
            "\tAccuracy: 0.35486666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measuring speed for CNN model\n",
        "\n",
        "CNN_parameters = count_parameters(best_cnn)\n",
        "CNN_acc, CNN_speed = get_speed(best_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fGACmEU7xsA",
        "outputId": "06218176-7177-44ec-8bc4-7c3e39fd7546"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLoss: 0.017753391618898603\n",
            "\tAccuracy: 0.9516666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing speeds and parameters \n",
        "\n",
        "print(f'ANN Accuracy {ANN_acc}')\n",
        "print(f'ANN Speed: {ANN_speed}')\n",
        "print(f'ANN Number of Parameters: {ANN_parameters}\\n')\n",
        "print(f'CNN Accuracy {CNN_acc}')\n",
        "print(f'CNN Speed: {CNN_speed}')\n",
        "print(f'CNN Number of Parameters: {CNN_parameters}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehFsiuIB70jO",
        "outputId": "4f2225f1-b95e-4e62-cff4-1107d956d35d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Accuracy 0.35486666666666666\n",
            "ANN Speed: 0.0014094984275516253\n",
            "ANN Number of Parameters: 227870\n",
            "\n",
            "CNN Accuracy 0.9516666666666667\n",
            "CNN Speed: 0.0021250320449826177\n",
            "CNN Number of Parameters: 1127966\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison\n",
        "\n",
        "- ANN: \n",
        "  - Accuracy: 35.48666%\n",
        "  - Number of Parameters: 227870\n",
        "  - Speed of inference: 0.0014094984275516253 seconds\n",
        "- CNN: \n",
        "  - Accuracy: 95.16666%\n",
        "  - Parameters: 1127966\n",
        "  - Speed of inference: 0.0021250320449826177 seconds\n",
        "\n",
        "  \n",
        "\n",
        "- Other remarks:\n",
        "  - Please keep in mind that I trained the ANN model for 100 epochs and the CNN model for 50 epochs\n",
        "  - The ANN model showes a small improvement the more epochs it trains in\n",
        "  - the CNN model showed significant improvement for the first 10 to 15 epochs then the improvment  stagnated.\n",
        "\n",
        "-------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rOpGEssf2FMJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wv-v1oymLXhF"
      },
      "source": [
        "### Questions\n",
        "1. What preprocessing techniques did you use? Why?\n",
        "    - First: I unzipped the data and put it in a specific folder called \"task2\", where it will have a folder called \"triple_mnist\" consisting of 3 folders for train, validation and test.\n",
        "    - Second: I iterate through the files and retrieve the images and labels(from the folder name)\n",
        "\n",
        "    - Preporcessing: \n",
        "      - Read the image using imread\n",
        "      - gray scale the image using rgbtogray\n",
        "        - Reason: to easily make a model that works with one channel instead of 3\n",
        "      - turn it to a tensor using transforms.ToTensor\n",
        "        - Reason: to be able to process it in my model with pytorch\n",
        "2. What data augmentation techniques did you use?\n",
        "    - In training I used a random rotation of 15 degrees \n",
        "    - Reason: To get a model that is robust and can predict the answers from a adjusted data\n",
        "3. Describe the fine-tuning process and how you reached your final CNN model.\n",
        "    - Fine-tuning: \n",
        "      - Number of Layers:\n",
        "        - Possible values: \\[1, 2, 3, 4, 5]\n",
        "        - Reason: in most of my test runs the best model had 1 or 2 layers, and having more than 5 will make the code slower\n",
        "      - Number of Input Layer Out Channels: \n",
        "        - Possible values: \\[2, 4, 8, 16, 32, 64]\n",
        "        - Reason: It will give a good variaty, without slowing the code.\n",
        "      - Number of Hidden Layers In and Out Channels:\n",
        "        - Possible values: \\[2, 4, 8, 16, 32, 64]\n",
        "        - Reason: It will give a good variaty, without slowing the code.\n",
        "      - Size of Input Layer Kernel\n",
        "        - Possible values: \\[3, 5]\n",
        "        - Reason Because it is best practice to have an odd valued kernel so we would have a point of focus.\n",
        "      - Size of Hidden Layer Kernels\n",
        "        - Possible values: \\[3, 5]\n",
        "        - Reason: Because it is best practice to have an odd valued kernel so we would have a point of focus.\n",
        "      - Activation Functions:\n",
        "        - Possible functions: \n",
        "            - ReLU\n",
        "            - LeakyReLU\n",
        "            - Hardswish\n",
        "            - ELU\n",
        "            - SELU\n",
        "            - SiLU\n",
        "        - Reason: We were told in labs that ReLU is the most common one and we should use it in most cases. And, I did not want to include all available functions, because it will need me to run the code for a much larger number of samples to have a good variaty of tests. \n",
        "      - Learning Rate:\n",
        "        - Possible values: a random float between 10^-1 and 10^-5\n",
        "        - Reason: A good margin and it will give various results\n",
        "      - Momentum: \n",
        "        - Possible values: a random float between 0.0 and 1.0\n",
        "      - Regularization: \n",
        "        - Dropout Probability: \n",
        "          - Possible values: a random float between 0.0 and 0.5\n",
        "          - Reason: based on lecture 10 best dropout probability is between 0.2 and 0.5 but it was mentioned that sometimes lower than that might be better. So, I decided to give it from 0.0 to 0.5 with the trade off that I will run the code for a larger number of samples.\n",
        "      - Note: I went with the assumption that you wanted us to use SGD as an optimizer based on the following facts:\n",
        "        - You asked us to tune Momentum\n",
        "        - We only used Adam and SGD optimizers in the course\n",
        "      - Batch Size: \n",
        "        - Possible values: \\[64, 256, 1024, 4096]\n",
        "        - Reason: Although it wasn't mentioned in the problem statement, I wanted to test it out since the most harm it could do is make the code a little slower. \n",
        "    - After running for 5 samples where each sample ran for 25 epochs, the best samples was the following:\n",
        "      - Accuracy on validation: 0.7689\n",
        "      - Number of Layers: 1 \n",
        "      - Number of Input Layer Out Channels: 4\n",
        "      - Number of Hidden Layers In and Out Channels: 8\n",
        "      - Size of Input Layer Kernel: 3\n",
        "      - Size of Hidden Layer Kernels: 5\n",
        "      - Learning Rate: 0.062128695444829546\n",
        "      - Momuntem: 0.33922085849116246\n",
        "      - Activiation Function: LeakyReLU\n",
        "      - Batch Size: 256\n",
        "      - Dropout Probability: 0.005428947811590701\n",
        "    - After running the best model on its own for 50 epochs:\n",
        "      - Accuracy on Test: 0.9516666666666667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kDjy3Y9FLXhF"
      },
      "source": [
        "# Task 3: Decision Trees and Ensemble Learning (15%)\n",
        "\n",
        "For the `loan_data.csv` data, predict if the bank should give a loan or not.\n",
        "You need to do the following:\n",
        "- Fine-tune a decision tree on the data\n",
        "- Fine-tune a random forest on the data\n",
        "- Compare their performance\n",
        "- Visualize your DT and one of the trees from the RF\n",
        "\n",
        "For evaluating your models, do $80/20$ train test split.\n",
        "\n",
        "### Data\n",
        "- `credit.policy`: Whether the customer meets the credit underwriting criteria.\n",
        "- `purpose`: The purpose of the loan.\n",
        "- `int.rate`: The interest rate of the loan.\n",
        "- `installment`: The monthly installments owed by the borrower if the loan is funded.\n",
        "- `log.annual.inc`: The natural logarithm of the self-reported annual income of the borrower.\n",
        "- `dti`: The debt-to-income ratio of the borrower.\n",
        "- `fico`: The FICO credit score of the borrower.\n",
        "- `days.with.cr.line`: The number of days the borrower has had a credit line.\n",
        "- `revol.bal`: The borrower's revolving balance.\n",
        "- `revol.util`: The borrower's revolving line utilization rate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "jsHYkN47ZzhB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the dataset\n",
        "\n",
        "df = pd.read_csv(\"loan_data.csv\")\n",
        "print(df['purpose'].unique())\n",
        "print(f'number of entries: {len(df)}')\n",
        "print(f'columns: {[column for column in df.columns]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj3T568VZ3HI",
        "outputId": "b1eaa8ce-b518-46e2-9bef-61e1e7a3d490"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['debt_consolidation' 'credit_card' 'all_other' 'home_improvement'\n",
            " 'small_business' 'major_purchase' 'educational']\n",
            "number of entries: 9578\n",
            "columns: ['credit.policy', 'purpose', 'int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util', 'inq.last.6mths', 'delinq.2yrs', 'pub.rec', 'not.fully.paid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "\n",
        "onehot_features = {\n",
        "    'purpose': ['debt_consolidation', 'credit_card', 'all_other', 'home_improvement', 'small_business', 'major_purchase', 'educational']\n",
        "}\n",
        "ordinal_features = {}\n",
        "\n",
        "df = categorical_encoder(df=df, ordinal_features=ordinal_features, onehot_features=onehot_features)\n",
        "\n",
        "print(f'columns: {[column for column in df.columns]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERv3mtb7Z3ct",
        "outputId": "22ace44a-bb2b-4de5-f508-e94e02b26231"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns: ['credit.policy', 'int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util', 'inq.last.6mths', 'delinq.2yrs', 'pub.rec', 'not.fully.paid', 'purpose_credit_card', 'purpose_debt_consolidation', 'purpose_educational', 'purpose_home_improvement', 'purpose_major_purchase', 'purpose_small_business']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting features and target\n",
        "\n",
        "X = df.iloc[:, 1:]\n",
        "y = df['credit.policy']"
      ],
      "metadata": {
        "id": "CWfk4Rg3Z33O"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting and scaling\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "X_train, X_test = scaling(X_train, X_test, StandardScaler())"
      ],
      "metadata": {
        "id": "uP-24mRLbhdf"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "#Reference: Lab 4\n",
        "\n",
        "def train(model, param_grid, scoring='accuracy', cv=5):\n",
        "  clf = GridSearchCV(\n",
        "    estimator=model,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    param_grid=param_grid\n",
        "  )\n",
        "  clf.fit(X_train, y_train)\n",
        "  best_params = clf.best_params_\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  return acc, best_params\n"
      ],
      "metadata": {
        "id": "S67gqNdkbpFk"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "#Reference: https://www.projectpro.io/recipes/optimize-hyper-parameters-of-decisiontree-model-using-grid-search-in-python\n",
        "\n",
        "DT_param_grid = {\n",
        "  \"criterion\": [\"gini\", \"entropy\"],\n",
        "  \"splitter\": [\"best\", \"random\"],\n",
        "  \"max_depth\": [2*i for i in range(1, 10)],\n",
        "  \"min_samples_leaf\": [4**i for i in range(4)],\n",
        "  \"max_features\": [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "DT_acc, DT_params = train(DecisionTreeClassifier(), DT_param_grid)"
      ],
      "metadata": {
        "id": "1OE58GNXbsPA"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jGyTT-6yLXhG"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "#Reference: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "\n",
        "RF_param_grid = {\n",
        "  \"criterion\": [\"gini\", \"entropy\"],\n",
        "  \"max_depth\": [2*i for i in range(1, 10)],\n",
        "  \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "  'n_estimators': [50*i for i in range(1,4)]\n",
        "}\n",
        "\n",
        "RF_acc, RF_params = train(RandomForestClassifier(), RF_param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare\n",
        "\n",
        "print(f'Best:')\n",
        "print(f'\\tDecision Tree:')\n",
        "print(f'\\t\\taccuracy: {DT_acc}\\n\\t\\tParameters: {DT_params}')\n",
        "print(f'\\tRandom Forest:')\n",
        "print(f'\\t\\tRF accuracy: {RF_acc}\\n\\t\\tParameters: {RF_params}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr9_XDG6b4I3",
        "outputId": "c1e044a7-2b51-42f4-8504-0cc93c27a839"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best:\n",
            "\tDecision Tree:\n",
            "\t\taccuracy: 0.9890396659707724\n",
            "\t\tParameters: {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
            "\tRandom Forest:\n",
            "\t\tRF accuracy: 0.9895615866388309\n",
            "\t\tParameters: {'criterion': 'entropy', 'max_depth': 16, 'max_features': None, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "#Reference: Lab 11\n",
        "\n",
        "task4_features = ['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util', 'inq.last.6mths', 'delinq.2yrs', 'pub.rec', 'not.fully.paid', 'purpose_credit_card', 'purpose_debt_consolidation', 'purpose_educational', 'purpose_home_improvement', 'purpose_major_purchase', 'purpose_small_business']\n",
        "task4_classes = ['0', '1'] \n",
        "\n",
        "def plot_tree(clf, features=task4_features, classes=task4_classes):\n",
        "    dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                       feature_names=features,\n",
        "                       class_names=classes,\n",
        "                       filled=True, rounded=True,\n",
        "                       special_characters=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "cfmpJ8EFvysj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retraining models with best params\n",
        "\n",
        "def train(model):\n",
        "  clf = model\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_pred, y_test)\n",
        "  return clf, acc\n",
        "\n",
        "DT = DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features=None, min_samples_leaf=1, splitter='best')\n",
        "RF = RandomForestClassifier(criterion='entropy', max_depth=16, max_features=None, n_estimators=100)\n",
        "\n",
        "DT_clf, DT_acc = train(DT)\n",
        "RF_clf, RF_acc = train(RF)\n",
        "\n",
        "print(f'Decision Tree Accuracy: {DT_acc}')\n",
        "print(f'Random Forest Accuracy: {RF_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HCPCca9gV3D",
        "outputId": "8216b3b2-6cfe-4ab7-d525-439e5f35904d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9921711899791231\n",
            "Random Forest Accuracy: 0.9947807933194155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Visualization\n",
        "\n",
        "graph = plot_tree(DT_clf)\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5o9Xnz8bHtCT",
        "outputId": "4e877628-6bd7-4ded-f82c-d6ccdaa2aa9d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f4e44e24490>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2816pt\" height=\"1266pt\"\n viewBox=\"0.00 0.00 2815.50 1266.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1262)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1262 2811.5,-1262 2811.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#69b5eb\" stroke=\"#000000\" d=\"M2108,-1258C2108,-1258 1974,-1258 1974,-1258 1968,-1258 1962,-1252 1962,-1246 1962,-1246 1962,-1187 1962,-1187 1962,-1181 1968,-1175 1974,-1175 1974,-1175 2108,-1175 2108,-1175 2114,-1175 2120,-1181 2120,-1187 2120,-1187 2120,-1246 2120,-1246 2120,-1252 2114,-1258 2108,-1258\"/>\n<text text-anchor=\"start\" x=\"1970\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">inq.last.6mths ≤ 0.864</text>\n<text text-anchor=\"start\" x=\"1990\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.711</text>\n<text text-anchor=\"start\" x=\"1989\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7662</text>\n<text text-anchor=\"start\" x=\"1974.5\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1490, 6172]</text>\n<text text-anchor=\"start\" x=\"2012\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#4da7e8\" stroke=\"#000000\" d=\"M1927,-1139C1927,-1139 1811,-1139 1811,-1139 1805,-1139 1799,-1133 1799,-1127 1799,-1127 1799,-1068 1799,-1068 1799,-1062 1805,-1056 1811,-1056 1811,-1056 1927,-1056 1927,-1056 1933,-1056 1939,-1062 1939,-1068 1939,-1068 1939,-1127 1939,-1127 1939,-1133 1933,-1139 1927,-1139\"/>\n<text text-anchor=\"start\" x=\"1829.5\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ &#45;1.348</text>\n<text text-anchor=\"start\" x=\"1818\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.448</text>\n<text text-anchor=\"start\" x=\"1817\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6669</text>\n<text text-anchor=\"start\" x=\"1807\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [624, 6045]</text>\n<text text-anchor=\"start\" x=\"1840\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1980.8427,-1174.8796C1966.833,-1165.1868 1951.8146,-1154.7961 1937.475,-1144.8752\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1939.3383,-1141.9083 1929.1233,-1139.0969 1935.3556,-1147.6649 1939.3383,-1141.9083\"/>\n<text text-anchor=\"middle\" x=\"1933.6029\" y=\"-1159.9923\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<path fill=\"#e99356\" stroke=\"#000000\" d=\"M2244,-1139C2244,-1139 2136,-1139 2136,-1139 2130,-1139 2124,-1133 2124,-1127 2124,-1127 2124,-1068 2124,-1068 2124,-1062 2130,-1056 2136,-1056 2136,-1056 2244,-1056 2244,-1056 2250,-1056 2256,-1062 2256,-1068 2256,-1068 2256,-1127 2256,-1127 2256,-1133 2250,-1139 2244,-1139\"/>\n<text text-anchor=\"start\" x=\"2152.5\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 0.763</text>\n<text text-anchor=\"start\" x=\"2139\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.552</text>\n<text text-anchor=\"start\" x=\"2142\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 993</text>\n<text text-anchor=\"start\" x=\"2132\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [866, 127]</text>\n<text text-anchor=\"start\" x=\"2161\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>0&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2093.113,-1174.8796C2105.0225,-1165.368 2117.7734,-1155.1843 2129.9844,-1145.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2132.2868,-1148.0724 2137.9165,-1139.0969 2127.9184,-1142.6027 2132.2868,-1148.0724\"/>\n<text text-anchor=\"middle\" x=\"2135.1353\" y=\"-1160.2417\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e5823a\" stroke=\"#000000\" d=\"M1693,-1020C1693,-1020 1599,-1020 1599,-1020 1593,-1020 1587,-1014 1587,-1008 1587,-1008 1587,-949 1587,-949 1587,-943 1593,-937 1599,-937 1599,-937 1693,-937 1693,-937 1699,-937 1705,-943 1705,-949 1705,-949 1705,-1008 1705,-1008 1705,-1014 1699,-1020 1693,-1020\"/>\n<text text-anchor=\"start\" x=\"1606.5\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ &#45;2.007</text>\n<text text-anchor=\"start\" x=\"1595\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.062</text>\n<text text-anchor=\"start\" x=\"1598\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 274</text>\n<text text-anchor=\"start\" x=\"1596\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [272, 2]</text>\n<text text-anchor=\"start\" x=\"1617\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1798.7475,-1060.011C1771.678,-1045.5658 1740.8328,-1029.1059 1713.9815,-1014.7771\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1715.51,-1011.6256 1705.0397,-1010.0055 1712.2144,-1017.8014 1715.51,-1011.6256\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#45a3e7\" stroke=\"#000000\" d=\"M1944.5,-1020C1944.5,-1020 1793.5,-1020 1793.5,-1020 1787.5,-1020 1781.5,-1014 1781.5,-1008 1781.5,-1008 1781.5,-949 1781.5,-949 1781.5,-943 1787.5,-937 1793.5,-937 1793.5,-937 1944.5,-937 1944.5,-937 1950.5,-937 1956.5,-943 1956.5,-949 1956.5,-949 1956.5,-1008 1956.5,-1008 1956.5,-1014 1950.5,-1020 1944.5,-1020\"/>\n<text text-anchor=\"start\" x=\"1789.5\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">days.with.cr.line ≤ &#45;1.386</text>\n<text text-anchor=\"start\" x=\"1818\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.307</text>\n<text text-anchor=\"start\" x=\"1817\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6395</text>\n<text text-anchor=\"start\" x=\"1807\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [352, 6043]</text>\n<text text-anchor=\"start\" x=\"1840\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1869,-1055.8796C1869,-1047.6838 1869,-1038.9891 1869,-1030.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1872.5001,-1030.298 1869,-1020.2981 1865.5001,-1030.2981 1872.5001,-1030.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#f6d5bd\" stroke=\"#000000\" d=\"M1557.5,-901C1557.5,-901 1406.5,-901 1406.5,-901 1400.5,-901 1394.5,-895 1394.5,-889 1394.5,-889 1394.5,-830 1394.5,-830 1394.5,-824 1400.5,-818 1406.5,-818 1406.5,-818 1557.5,-818 1557.5,-818 1563.5,-818 1569.5,-824 1569.5,-830 1569.5,-830 1569.5,-889 1569.5,-889 1569.5,-895 1563.5,-901 1557.5,-901\"/>\n<text text-anchor=\"start\" x=\"1402.5\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">days.with.cr.line ≤ &#45;1.416</text>\n<text text-anchor=\"start\" x=\"1431\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.971</text>\n<text text-anchor=\"start\" x=\"1442.5\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1440.5\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 2]</text>\n<text text-anchor=\"start\" x=\"1453\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1588.6408,-936.8796C1575.4075,-927.2774 1561.2303,-916.9903 1547.6736,-907.1534\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1549.4762,-904.1371 1539.3269,-901.0969 1545.3651,-909.8027 1549.4762,-904.1371\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1692,-893.5C1692,-893.5 1600,-893.5 1600,-893.5 1594,-893.5 1588,-887.5 1588,-881.5 1588,-881.5 1588,-837.5 1588,-837.5 1588,-831.5 1594,-825.5 1600,-825.5 1600,-825.5 1692,-825.5 1692,-825.5 1698,-825.5 1704,-831.5 1704,-837.5 1704,-837.5 1704,-881.5 1704,-881.5 1704,-887.5 1698,-893.5 1692,-893.5\"/>\n<text text-anchor=\"start\" x=\"1603.5\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1598\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 269</text>\n<text text-anchor=\"start\" x=\"1596\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [269, 0]</text>\n<text text-anchor=\"start\" x=\"1617\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1646,-936.8796C1646,-926.2134 1646,-914.7021 1646,-903.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1649.5001,-903.8149 1646,-893.8149 1642.5001,-903.815 1649.5001,-903.8149\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1407.5,-774.5C1407.5,-774.5 1330.5,-774.5 1330.5,-774.5 1324.5,-774.5 1318.5,-768.5 1318.5,-762.5 1318.5,-762.5 1318.5,-718.5 1318.5,-718.5 1318.5,-712.5 1324.5,-706.5 1330.5,-706.5 1330.5,-706.5 1407.5,-706.5 1407.5,-706.5 1413.5,-706.5 1419.5,-712.5 1419.5,-718.5 1419.5,-718.5 1419.5,-762.5 1419.5,-762.5 1419.5,-768.5 1413.5,-774.5 1407.5,-774.5\"/>\n<text text-anchor=\"start\" x=\"1326.5\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1329.5\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1327.5\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n<text text-anchor=\"start\" x=\"1340\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1442.4781,-817.8796C1431.5143,-806.3337 1419.6103,-793.7976 1408.6399,-782.2446\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1411.0087,-779.6564 1401.5848,-774.8149 1405.9327,-784.4766 1411.0087,-779.6564\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1526.5,-774.5C1526.5,-774.5 1449.5,-774.5 1449.5,-774.5 1443.5,-774.5 1437.5,-768.5 1437.5,-762.5 1437.5,-762.5 1437.5,-718.5 1437.5,-718.5 1437.5,-712.5 1443.5,-706.5 1449.5,-706.5 1449.5,-706.5 1526.5,-706.5 1526.5,-706.5 1532.5,-706.5 1538.5,-712.5 1538.5,-718.5 1538.5,-718.5 1538.5,-762.5 1538.5,-762.5 1538.5,-768.5 1532.5,-774.5 1526.5,-774.5\"/>\n<text text-anchor=\"start\" x=\"1445.5\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1448.5\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1446.5\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n<text text-anchor=\"start\" x=\"1459\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1484.0985,-817.8796C1484.6363,-807.2134 1485.2167,-795.7021 1485.7613,-784.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1489.2617,-784.9785 1486.2698,-774.8149 1482.2706,-784.626 1489.2617,-784.9785\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1826,-893.5C1826,-893.5 1734,-893.5 1734,-893.5 1728,-893.5 1722,-887.5 1722,-881.5 1722,-881.5 1722,-837.5 1722,-837.5 1722,-831.5 1728,-825.5 1734,-825.5 1734,-825.5 1826,-825.5 1826,-825.5 1832,-825.5 1838,-831.5 1838,-837.5 1838,-837.5 1838,-881.5 1838,-881.5 1838,-887.5 1832,-893.5 1826,-893.5\"/>\n<text text-anchor=\"start\" x=\"1737.5\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1732\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 127</text>\n<text text-anchor=\"start\" x=\"1730\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [127, 0]</text>\n<text text-anchor=\"start\" x=\"1751\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1837.8721,-936.8796C1829.4014,-925.5536 1820.2181,-913.2748 1811.7153,-901.9058\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1814.4562,-899.7268 1805.6641,-893.8149 1808.8505,-903.9193 1814.4562,-899.7268\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#40a1e6\" stroke=\"#000000\" d=\"M1984,-901C1984,-901 1868,-901 1868,-901 1862,-901 1856,-895 1856,-889 1856,-889 1856,-830 1856,-830 1856,-824 1862,-818 1868,-818 1868,-818 1984,-818 1984,-818 1990,-818 1996,-824 1996,-830 1996,-830 1996,-889 1996,-889 1996,-895 1990,-901 1984,-901\"/>\n<text text-anchor=\"start\" x=\"1872.5\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 1.649</text>\n<text text-anchor=\"start\" x=\"1875\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.223</text>\n<text text-anchor=\"start\" x=\"1874\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6268</text>\n<text text-anchor=\"start\" x=\"1864\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [225, 6043]</text>\n<text text-anchor=\"start\" x=\"1897\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1888.9358,-936.8796C1893.0341,-928.3236 1897.3928,-919.2238 1901.6273,-910.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1904.8157,-911.8288 1905.9791,-901.2981 1898.5025,-908.8049 1904.8157,-911.8288\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#3d9fe6\" stroke=\"#000000\" d=\"M1686,-782C1686,-782 1570,-782 1570,-782 1564,-782 1558,-776 1558,-770 1558,-770 1558,-711 1558,-711 1558,-705 1564,-699 1570,-699 1570,-699 1686,-699 1686,-699 1692,-699 1698,-705 1698,-711 1698,-711 1698,-770 1698,-770 1698,-776 1692,-782 1686,-782\"/>\n<text text-anchor=\"start\" x=\"1598.5\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.78</text>\n<text text-anchor=\"start\" x=\"1577\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.136</text>\n<text text-anchor=\"start\" x=\"1576\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6071</text>\n<text text-anchor=\"start\" x=\"1566\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [116, 5955]</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1855.6103,-821.8831C1852.7172,-820.5405 1849.8393,-819.2405 1847,-818 1801.741,-798.2261 1749.6684,-779.636 1707.6577,-765.622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1708.6249,-762.2554 1698.0316,-762.432 1706.4229,-768.9 1708.6249,-762.2554\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<path fill=\"#fae7d9\" stroke=\"#000000\" d=\"M1976,-782C1976,-782 1876,-782 1876,-782 1870,-782 1864,-776 1864,-770 1864,-770 1864,-711 1864,-711 1864,-705 1870,-699 1876,-699 1876,-699 1976,-699 1976,-699 1982,-699 1988,-705 1988,-711 1988,-711 1988,-770 1988,-770 1988,-776 1982,-782 1976,-782\"/>\n<text text-anchor=\"start\" x=\"1872.5\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 3.847</text>\n<text text-anchor=\"start\" x=\"1875\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.992</text>\n<text text-anchor=\"start\" x=\"1878\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 197</text>\n<text text-anchor=\"start\" x=\"1872\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [109, 88]</text>\n<text text-anchor=\"start\" x=\"1897\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>9&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1926,-817.8796C1926,-809.6838 1926,-800.9891 1926,-792.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1929.5001,-792.298 1926,-782.2981 1922.5001,-792.2981 1929.5001,-792.298\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M1291,-663C1291,-663 1183,-663 1183,-663 1177,-663 1171,-657 1171,-651 1171,-651 1171,-592 1171,-592 1171,-586 1177,-580 1183,-580 1183,-580 1291,-580 1291,-580 1297,-580 1303,-586 1303,-592 1303,-592 1303,-651 1303,-651 1303,-657 1297,-663 1291,-663\"/>\n<text text-anchor=\"start\" x=\"1184\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ 1.812</text>\n<text text-anchor=\"start\" x=\"1186\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.075</text>\n<text text-anchor=\"start\" x=\"1185\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6006</text>\n<text text-anchor=\"start\" x=\"1179\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [55, 5951]</text>\n<text text-anchor=\"start\" x=\"1208\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1557.7493,-703.3105C1554.1465,-701.7811 1550.5501,-700.3331 1547,-699 1469.3566,-669.8433 1376.675,-648.31 1312.9996,-635.44\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1313.5278,-631.9764 1303.0358,-633.4489 1312.1561,-638.8407 1313.5278,-631.9764\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<path fill=\"#e78946\" stroke=\"#000000\" d=\"M1679,-663C1679,-663 1577,-663 1577,-663 1571,-663 1565,-657 1565,-651 1565,-651 1565,-592 1565,-592 1565,-586 1571,-580 1577,-580 1577,-580 1679,-580 1679,-580 1685,-580 1691,-586 1691,-592 1691,-592 1691,-651 1691,-651 1691,-657 1685,-663 1679,-663\"/>\n<text text-anchor=\"start\" x=\"1573\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.282</text>\n<text text-anchor=\"start\" x=\"1577\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.334</text>\n<text text-anchor=\"start\" x=\"1584\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 65</text>\n<text text-anchor=\"start\" x=\"1582.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [61, 4]</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 10&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>10&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1628,-698.8796C1628,-690.6838 1628,-681.9891 1628,-673.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1631.5001,-673.298 1628,-663.2981 1624.5001,-673.2981 1631.5001,-673.298\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#3a9ee5\" stroke=\"#000000\" d=\"M1055,-544C1055,-544 947,-544 947,-544 941,-544 935,-538 935,-532 935,-532 935,-473 935,-473 935,-467 941,-461 947,-461 947,-461 1055,-461 1055,-461 1061,-461 1067,-467 1067,-473 1067,-473 1067,-532 1067,-532 1067,-538 1061,-544 1055,-544\"/>\n<text text-anchor=\"start\" x=\"947.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.533</text>\n<text text-anchor=\"start\" x=\"954\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.06</text>\n<text text-anchor=\"start\" x=\"949\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5992</text>\n<text text-anchor=\"start\" x=\"943\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [42, 5950]</text>\n<text text-anchor=\"start\" x=\"972\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1170.947,-588.1936C1141.5355,-573.3633 1106.7446,-555.8204 1076.3261,-540.4822\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1077.542,-537.1756 1067.037,-535.7983 1074.3903,-543.4259 1077.542,-537.1756\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<path fill=\"#e78b48\" stroke=\"#000000\" d=\"M1284,-544C1284,-544 1190,-544 1190,-544 1184,-544 1178,-538 1178,-532 1178,-532 1178,-473 1178,-473 1178,-467 1184,-461 1190,-461 1190,-461 1284,-461 1284,-461 1290,-461 1296,-467 1296,-473 1296,-473 1296,-532 1296,-532 1296,-538 1290,-544 1284,-544\"/>\n<text text-anchor=\"start\" x=\"1189\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ 2.132</text>\n<text text-anchor=\"start\" x=\"1186\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.371</text>\n<text text-anchor=\"start\" x=\"1193\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"1191.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [13, 1]</text>\n<text text-anchor=\"start\" x=\"1208\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 11&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>11&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1237,-579.8796C1237,-571.6838 1237,-562.9891 1237,-554.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1240.5001,-554.298 1237,-544.2981 1233.5001,-554.2981 1240.5001,-554.298\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#3a9de5\" stroke=\"#000000\" d=\"M584,-425C584,-425 476,-425 476,-425 470,-425 464,-419 464,-413 464,-413 464,-354 464,-354 464,-348 470,-342 476,-342 476,-342 584,-342 584,-342 590,-342 596,-348 596,-354 596,-354 596,-413 596,-413 596,-419 590,-425 584,-425\"/>\n<text text-anchor=\"start\" x=\"474\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ &#45;0.493</text>\n<text text-anchor=\"start\" x=\"479\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.031</text>\n<text text-anchor=\"start\" x=\"478\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5586</text>\n<text text-anchor=\"start\" x=\"472\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [18, 5568]</text>\n<text text-anchor=\"start\" x=\"501\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M934.5162,-485.7026C847.9057,-463.8201 696.8326,-425.6509 605.8462,-402.6628\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"606.6983,-399.2682 596.1456,-400.212 604.9836,-406.055 606.6983,-399.2682\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#45a3e7\" stroke=\"#000000\" d=\"M1070.5,-425C1070.5,-425 931.5,-425 931.5,-425 925.5,-425 919.5,-419 919.5,-413 919.5,-413 919.5,-354 919.5,-354 919.5,-348 925.5,-342 931.5,-342 931.5,-342 1070.5,-342 1070.5,-342 1076.5,-342 1082.5,-348 1082.5,-354 1082.5,-354 1082.5,-413 1082.5,-413 1082.5,-419 1076.5,-425 1070.5,-425\"/>\n<text text-anchor=\"start\" x=\"927.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;0.033</text>\n<text text-anchor=\"start\" x=\"950\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.324</text>\n<text text-anchor=\"start\" x=\"953\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 406</text>\n<text text-anchor=\"start\" x=\"947\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [24, 382]</text>\n<text text-anchor=\"start\" x=\"972\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 12&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>12&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1001,-460.8796C1001,-452.6838 1001,-443.9891 1001,-435.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1004.5001,-435.298 1001,-425.2981 997.5001,-435.2981 1004.5001,-435.298\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#44a3e7\" stroke=\"#000000\" d=\"M359,-306C359,-306 259,-306 259,-306 253,-306 247,-300 247,-294 247,-294 247,-235 247,-235 247,-229 253,-223 259,-223 259,-223 359,-223 359,-223 365,-223 371,-229 371,-235 371,-235 371,-294 371,-294 371,-300 365,-306 359,-306\"/>\n<text text-anchor=\"start\" x=\"259\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ &#45;0.718</text>\n<text text-anchor=\"start\" x=\"258\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.306</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 201</text>\n<text text-anchor=\"start\" x=\"255\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 190]</text>\n<text text-anchor=\"start\" x=\"280\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M463.9921,-347.9573C437.5952,-333.7436 407.1317,-317.3402 380.2357,-302.8577\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"381.7264,-299.6852 371.2623,-298.0258 378.4076,-305.8485 381.7264,-299.6852\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M599.5,-306C599.5,-306 460.5,-306 460.5,-306 454.5,-306 448.5,-300 448.5,-294 448.5,-294 448.5,-235 448.5,-235 448.5,-229 454.5,-223 460.5,-223 460.5,-223 599.5,-223 599.5,-223 605.5,-223 611.5,-229 611.5,-235 611.5,-235 611.5,-294 611.5,-294 611.5,-300 605.5,-306 599.5,-306\"/>\n<text text-anchor=\"start\" x=\"456.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;1.252</text>\n<text text-anchor=\"start\" x=\"479\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.014</text>\n<text text-anchor=\"start\" x=\"478\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5385</text>\n<text text-anchor=\"start\" x=\"476\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 5378]</text>\n<text text-anchor=\"start\" x=\"501\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 13&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>13&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M530,-341.8796C530,-333.6838 530,-324.9891 530,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"533.5001,-316.298 530,-306.2981 526.5001,-316.2981 533.5001,-316.298\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#5eafea\" stroke=\"#000000\" d=\"M221,-187C221,-187 119,-187 119,-187 113,-187 107,-181 107,-175 107,-175 107,-116 107,-116 107,-110 113,-104 119,-104 119,-104 221,-104 221,-104 227,-104 233,-110 233,-116 233,-116 233,-175 233,-175 233,-181 227,-187 221,-187\"/>\n<text text-anchor=\"start\" x=\"115\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.599</text>\n<text text-anchor=\"start\" x=\"119\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.627</text>\n<text text-anchor=\"start\" x=\"126\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 70</text>\n<text text-anchor=\"start\" x=\"120\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 59]</text>\n<text text-anchor=\"start\" x=\"141\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M260.3845,-222.8796C249.4438,-213.513 237.7418,-203.4948 226.5092,-193.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.6956,-191.1428 218.823,-187.2981 224.1432,-196.4603 228.6956,-191.1428\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M355,-179.5C355,-179.5 263,-179.5 263,-179.5 257,-179.5 251,-173.5 251,-167.5 251,-167.5 251,-123.5 251,-123.5 251,-117.5 257,-111.5 263,-111.5 263,-111.5 355,-111.5 355,-111.5 361,-111.5 367,-117.5 367,-123.5 367,-123.5 367,-167.5 367,-167.5 367,-173.5 361,-179.5 355,-179.5\"/>\n<text text-anchor=\"start\" x=\"266.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 131</text>\n<text text-anchor=\"start\" x=\"259\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 131]</text>\n<text text-anchor=\"start\" x=\"280\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 14&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>14&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M309,-222.8796C309,-212.2134 309,-200.7021 309,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.5001,-189.8149 309,-179.8149 305.5001,-189.815 312.5001,-189.8149\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#43a2e6\" stroke=\"#000000\" d=\"M98,-68C98,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 98,0 98,0 104,0 110,-6 110,-12 110,-12 110,-56 110,-56 110,-62 104,-68 98,-68\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.28</text>\n<text text-anchor=\"start\" x=\"11\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 62</text>\n<text text-anchor=\"start\" x=\"9.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 59]</text>\n<text text-anchor=\"start\" x=\"26\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M127.1782,-103.9815C117.5095,-94.607 107.2473,-84.6572 97.5882,-75.2921\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.9551,-72.7118 90.3392,-68.2637 95.0824,-77.7375 99.9551,-72.7118\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M217.5,-68C217.5,-68 140.5,-68 140.5,-68 134.5,-68 128.5,-62 128.5,-56 128.5,-56 128.5,-12 128.5,-12 128.5,-6 134.5,0 140.5,0 140.5,0 217.5,0 217.5,0 223.5,0 229.5,-6 229.5,-12 229.5,-12 229.5,-56 229.5,-56 229.5,-62 223.5,-68 217.5,-68\"/>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"139.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 0]</text>\n<text text-anchor=\"start\" x=\"150\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M173.3513,-103.9815C174.0263,-95.618 174.7384,-86.7965 175.4209,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.9183,-78.5129 176.2343,-68.2637 171.941,-77.9496 178.9183,-78.5129\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#3c9ee5\" stroke=\"#000000\" d=\"M496.5,-187C496.5,-187 397.5,-187 397.5,-187 391.5,-187 385.5,-181 385.5,-175 385.5,-175 385.5,-116 385.5,-116 385.5,-110 391.5,-104 397.5,-104 397.5,-104 496.5,-104 496.5,-104 502.5,-104 508.5,-110 508.5,-116 508.5,-116 508.5,-175 508.5,-175 508.5,-181 502.5,-187 496.5,-187\"/>\n<text text-anchor=\"start\" x=\"393.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.035</text>\n<text text-anchor=\"start\" x=\"396\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.099</text>\n<text text-anchor=\"start\" x=\"399\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 470</text>\n<text text-anchor=\"start\" x=\"397\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 464]</text>\n<text text-anchor=\"start\" x=\"418\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M500.9706,-222.8796C494.8145,-214.0534 488.2549,-204.6485 481.9064,-195.5466\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"484.7448,-193.4978 476.1533,-187.2981 479.0033,-197.5024 484.7448,-193.4978\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M639,-187C639,-187 539,-187 539,-187 533,-187 527,-181 527,-175 527,-175 527,-116 527,-116 527,-110 533,-104 539,-104 539,-104 639,-104 639,-104 645,-104 651,-110 651,-116 651,-116 651,-175 651,-175 651,-181 645,-187 639,-187\"/>\n<text text-anchor=\"start\" x=\"536\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ 1.678</text>\n<text text-anchor=\"start\" x=\"538\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.003</text>\n<text text-anchor=\"start\" x=\"537\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4915</text>\n<text text-anchor=\"start\" x=\"535\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 4914]</text>\n<text text-anchor=\"start\" x=\"560\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 19&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>19&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M550.6353,-222.8796C554.8774,-214.3236 559.389,-205.2238 563.7721,-196.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"566.9703,-197.8121 568.2766,-187.2981 560.6988,-194.7026 566.9703,-197.8121\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M362,-68C362,-68 268,-68 268,-68 262,-68 256,-62 256,-56 256,-56 256,-12 256,-12 256,-6 262,0 268,0 268,0 362,0 362,0 368,0 374,-6 374,-12 374,-12 374,-56 374,-56 374,-62 368,-68 362,-68\"/>\n<text text-anchor=\"start\" x=\"264\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.022</text>\n<text text-anchor=\"start\" x=\"267\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 458</text>\n<text text-anchor=\"start\" x=\"265\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 457]</text>\n<text text-anchor=\"start\" x=\"286\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M397.8481,-103.9815C386.5324,-94.4232 374.5087,-84.2668 363.2325,-74.7419\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.4612,-72.0429 355.5633,-68.2637 360.9441,-77.3904 365.4612,-72.0429\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#c6e3f8\" stroke=\"#000000\" d=\"M490,-68C490,-68 404,-68 404,-68 398,-68 392,-62 392,-56 392,-56 392,-12 392,-12 392,-6 398,0 404,0 404,0 490,0 490,0 496,0 502,-6 502,-12 502,-12 502,-56 502,-56 502,-62 496,-68 490,-68\"/>\n<text text-anchor=\"start\" x=\"400\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.98</text>\n<text text-anchor=\"start\" x=\"403\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12</text>\n<text text-anchor=\"start\" x=\"405.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 7]</text>\n<text text-anchor=\"start\" x=\"418\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 20&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>20&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M447,-103.9815C447,-95.618 447,-86.7965 447,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.5001,-78.2636 447,-68.2637 443.5001,-78.2637 450.5001,-78.2636\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M632,-68C632,-68 532,-68 532,-68 526,-68 520,-62 520,-56 520,-56 520,-12 520,-12 520,-6 526,0 532,0 532,0 632,0 632,0 638,0 644,-6 644,-12 644,-12 644,-56 644,-56 644,-62 638,-68 632,-68\"/>\n<text text-anchor=\"start\" x=\"539.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"530\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4784</text>\n<text text-anchor=\"start\" x=\"528\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4784]</text>\n<text text-anchor=\"start\" x=\"553\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M586.3935,-103.9815C585.8684,-95.618 585.3146,-86.7965 584.7837,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"588.2709,-78.0247 584.1511,-68.2637 581.2846,-78.4634 588.2709,-78.0247\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M768,-68C768,-68 674,-68 674,-68 668,-68 662,-62 662,-56 662,-56 662,-12 662,-12 662,-6 668,0 674,0 674,0 768,0 768,0 774,0 780,-6 780,-12 780,-12 780,-56 780,-56 780,-62 774,-68 768,-68\"/>\n<text text-anchor=\"start\" x=\"670\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.065</text>\n<text text-anchor=\"start\" x=\"673\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 131</text>\n<text text-anchor=\"start\" x=\"671\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 130]</text>\n<text text-anchor=\"start\" x=\"692\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M638.1519,-103.9815C649.4676,-94.4232 661.4913,-84.2668 672.7675,-74.7419\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"675.0559,-77.3904 680.4367,-68.2637 670.5388,-72.0429 675.0559,-77.3904\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#f7d7c0\" stroke=\"#000000\" d=\"M1021,-306C1021,-306 927,-306 927,-306 921,-306 915,-300 915,-294 915,-294 915,-235 915,-235 915,-229 921,-223 927,-223 927,-223 1021,-223 1021,-223 1027,-223 1033,-229 1033,-235 1033,-235 1033,-294 1033,-294 1033,-300 1027,-306 1021,-306\"/>\n<text text-anchor=\"start\" x=\"936.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 0.763</text>\n<text text-anchor=\"start\" x=\"923\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.974</text>\n<text text-anchor=\"start\" x=\"930\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 37</text>\n<text text-anchor=\"start\" x=\"924\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 15]</text>\n<text text-anchor=\"start\" x=\"945\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 26&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>26&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M991.5567,-341.8796C989.6767,-333.5938 987.6811,-324.798 985.7351,-316.2216\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"989.1096,-315.2757 983.4836,-306.2981 982.2831,-316.8247 989.1096,-315.2757\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<path fill=\"#3a9ee5\" stroke=\"#000000\" d=\"M1162.5,-306C1162.5,-306 1063.5,-306 1063.5,-306 1057.5,-306 1051.5,-300 1051.5,-294 1051.5,-294 1051.5,-235 1051.5,-235 1051.5,-229 1057.5,-223 1063.5,-223 1063.5,-223 1162.5,-223 1162.5,-223 1168.5,-223 1174.5,-229 1174.5,-235 1174.5,-235 1174.5,-294 1174.5,-294 1174.5,-300 1168.5,-306 1162.5,-306\"/>\n<text text-anchor=\"start\" x=\"1059.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 1.556</text>\n<text text-anchor=\"start\" x=\"1062\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.049</text>\n<text text-anchor=\"start\" x=\"1065\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 369</text>\n<text text-anchor=\"start\" x=\"1063\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 367]</text>\n<text text-anchor=\"start\" x=\"1084\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 26&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>26&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1040.1722,-341.8796C1048.7335,-332.7832 1057.8732,-323.0722 1066.6832,-313.7116\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.3557,-315.9789 1073.6606,-306.2981 1064.2583,-311.1813 1069.3557,-315.9789\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#eeaf81\" stroke=\"#000000\" d=\"M899.5,-187C899.5,-187 800.5,-187 800.5,-187 794.5,-187 788.5,-181 788.5,-175 788.5,-175 788.5,-116 788.5,-116 788.5,-110 794.5,-104 800.5,-104 800.5,-104 899.5,-104 899.5,-104 905.5,-104 911.5,-110 911.5,-116 911.5,-116 911.5,-175 911.5,-175 911.5,-181 905.5,-187 899.5,-187\"/>\n<text text-anchor=\"start\" x=\"796.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.893</text>\n<text text-anchor=\"start\" x=\"799\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.837</text>\n<text text-anchor=\"start\" x=\"806\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30</text>\n<text text-anchor=\"start\" x=\"804.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 8]</text>\n<text text-anchor=\"start\" x=\"821\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 27&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>27&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M930.6308,-222.8796C921.0584,-213.6931 910.8328,-203.8798 900.9897,-194.4336\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"903.1928,-191.6969 893.5543,-187.2981 898.3459,-196.7475 903.1928,-191.6969\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1018.5,-179.5C1018.5,-179.5 941.5,-179.5 941.5,-179.5 935.5,-179.5 929.5,-173.5 929.5,-167.5 929.5,-167.5 929.5,-123.5 929.5,-123.5 929.5,-117.5 935.5,-111.5 941.5,-111.5 941.5,-111.5 1018.5,-111.5 1018.5,-111.5 1024.5,-111.5 1030.5,-117.5 1030.5,-123.5 1030.5,-123.5 1030.5,-167.5 1030.5,-167.5 1030.5,-173.5 1024.5,-179.5 1018.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"937.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"940.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7</text>\n<text text-anchor=\"start\" x=\"938.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 7]</text>\n<text text-anchor=\"start\" x=\"951\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 27&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>27&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M976.0985,-222.8796C976.6363,-212.2134 977.2167,-200.7021 977.7613,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"981.2617,-189.9785 978.2698,-179.8149 974.2706,-189.626 981.2617,-189.9785\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M890,-68C890,-68 810,-68 810,-68 804,-68 798,-62 798,-56 798,-56 798,-12 798,-12 798,-6 804,0 810,0 810,0 890,0 890,0 896,0 902,-6 902,-12 902,-12 902,-56 902,-56 902,-62 896,-68 890,-68\"/>\n<text text-anchor=\"start\" x=\"807.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"806\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16</text>\n<text text-anchor=\"start\" x=\"808.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 8]</text>\n<text text-anchor=\"start\" x=\"821\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M850,-103.9815C850,-95.618 850,-86.7965 850,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"853.5001,-78.2636 850,-68.2637 846.5001,-78.2637 853.5001,-78.2636\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1015.5,-68C1015.5,-68 932.5,-68 932.5,-68 926.5,-68 920.5,-62 920.5,-56 920.5,-56 920.5,-12 920.5,-12 920.5,-6 926.5,0 932.5,0 932.5,0 1015.5,0 1015.5,0 1021.5,0 1027.5,-6 1027.5,-12 1027.5,-12 1027.5,-56 1027.5,-56 1027.5,-62 1021.5,-68 1015.5,-68\"/>\n<text text-anchor=\"start\" x=\"931.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"930\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"928.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 0]</text>\n<text text-anchor=\"start\" x=\"945\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>28&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M896.173,-103.9815C906.7007,-94.5151 917.8808,-84.462 928.3849,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"930.7994,-77.5526 935.8951,-68.2637 926.1189,-72.3475 930.7994,-77.5526\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1153,-179.5C1153,-179.5 1061,-179.5 1061,-179.5 1055,-179.5 1049,-173.5 1049,-167.5 1049,-167.5 1049,-123.5 1049,-123.5 1049,-117.5 1055,-111.5 1061,-111.5 1061,-111.5 1153,-111.5 1153,-111.5 1159,-111.5 1165,-117.5 1165,-123.5 1165,-123.5 1165,-167.5 1165,-167.5 1165,-173.5 1159,-179.5 1153,-179.5\"/>\n<text text-anchor=\"start\" x=\"1064.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1059\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 348</text>\n<text text-anchor=\"start\" x=\"1057\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 348]</text>\n<text text-anchor=\"start\" x=\"1078\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 32&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>32&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1110.9015,-222.8796C1110.3637,-212.2134 1109.7833,-200.7021 1109.2387,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1112.7294,-189.626 1108.7302,-179.8149 1105.7383,-189.9785 1112.7294,-189.626\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<path fill=\"#4ea7e8\" stroke=\"#000000\" d=\"M1329,-187C1329,-187 1195,-187 1195,-187 1189,-187 1183,-181 1183,-175 1183,-175 1183,-116 1183,-116 1183,-110 1189,-104 1195,-104 1195,-104 1329,-104 1329,-104 1335,-104 1341,-110 1341,-116 1341,-116 1341,-175 1341,-175 1341,-181 1335,-187 1329,-187\"/>\n<text text-anchor=\"start\" x=\"1191\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 0.369</text>\n<text text-anchor=\"start\" x=\"1211\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.454</text>\n<text text-anchor=\"start\" x=\"1218\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 21</text>\n<text text-anchor=\"start\" x=\"1216.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 19]</text>\n<text text-anchor=\"start\" x=\"1233\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 32&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>32&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1165.113,-222.8796C1177.0225,-213.368 1189.7734,-203.1843 1201.9844,-193.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1204.2868,-196.0724 1209.9165,-187.0969 1199.9184,-190.6027 1204.2868,-196.0724\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1239.5,-68C1239.5,-68 1162.5,-68 1162.5,-68 1156.5,-68 1150.5,-62 1150.5,-56 1150.5,-56 1150.5,-12 1150.5,-12 1150.5,-6 1156.5,0 1162.5,0 1162.5,0 1239.5,0 1239.5,0 1245.5,0 1251.5,-6 1251.5,-12 1251.5,-12 1251.5,-56 1251.5,-56 1251.5,-62 1245.5,-68 1239.5,-68\"/>\n<text text-anchor=\"start\" x=\"1158.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1161.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1159.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"1172\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1239.2859,-103.9815C1234.5092,-95.2504 1229.4595,-86.0202 1224.6494,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1227.6153,-75.3568 1219.7451,-68.2637 1221.4742,-78.7165 1227.6153,-75.3568\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1364.5,-68C1364.5,-68 1281.5,-68 1281.5,-68 1275.5,-68 1269.5,-62 1269.5,-56 1269.5,-56 1269.5,-12 1269.5,-12 1269.5,-6 1275.5,0 1281.5,0 1281.5,0 1364.5,0 1364.5,0 1370.5,0 1376.5,-6 1376.5,-12 1376.5,-12 1376.5,-56 1376.5,-56 1376.5,-62 1370.5,-68 1364.5,-68\"/>\n<text text-anchor=\"start\" x=\"1280.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1279\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n<text text-anchor=\"start\" x=\"1277.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 19]</text>\n<text text-anchor=\"start\" x=\"1294\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 34&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>34&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1284.7141,-103.9815C1289.4908,-95.2504 1294.5405,-86.0202 1299.3506,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1302.5258,-78.7165 1304.2549,-68.2637 1296.3847,-75.3568 1302.5258,-78.7165\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1217.5,-417.5C1217.5,-417.5 1134.5,-417.5 1134.5,-417.5 1128.5,-417.5 1122.5,-411.5 1122.5,-405.5 1122.5,-405.5 1122.5,-361.5 1122.5,-361.5 1122.5,-355.5 1128.5,-349.5 1134.5,-349.5 1134.5,-349.5 1217.5,-349.5 1217.5,-349.5 1223.5,-349.5 1229.5,-355.5 1229.5,-361.5 1229.5,-361.5 1229.5,-405.5 1229.5,-405.5 1229.5,-411.5 1223.5,-417.5 1217.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"1133.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1132\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13</text>\n<text text-anchor=\"start\" x=\"1130.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [13, 0]</text>\n<text text-anchor=\"start\" x=\"1147\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 37&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>37&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1215.6652,-460.8796C1210.0285,-449.8835 1203.9315,-437.9893 1198.2478,-426.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1201.2663,-425.1173 1193.59,-417.8149 1195.0371,-428.3105 1201.2663,-425.1173\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1336.5,-417.5C1336.5,-417.5 1259.5,-417.5 1259.5,-417.5 1253.5,-417.5 1247.5,-411.5 1247.5,-405.5 1247.5,-405.5 1247.5,-361.5 1247.5,-361.5 1247.5,-355.5 1253.5,-349.5 1259.5,-349.5 1259.5,-349.5 1336.5,-349.5 1336.5,-349.5 1342.5,-349.5 1348.5,-355.5 1348.5,-361.5 1348.5,-361.5 1348.5,-405.5 1348.5,-405.5 1348.5,-411.5 1342.5,-417.5 1336.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"1255.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1258.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1256.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"1269\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 37&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>37&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1258.3348,-460.8796C1263.9715,-449.8835 1270.0685,-437.9893 1275.7522,-426.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1278.9629,-428.3105 1280.41,-417.8149 1272.7337,-425.1173 1278.9629,-428.3105\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1529.5,-536.5C1529.5,-536.5 1452.5,-536.5 1452.5,-536.5 1446.5,-536.5 1440.5,-530.5 1440.5,-524.5 1440.5,-524.5 1440.5,-480.5 1440.5,-480.5 1440.5,-474.5 1446.5,-468.5 1452.5,-468.5 1452.5,-468.5 1529.5,-468.5 1529.5,-468.5 1535.5,-468.5 1541.5,-474.5 1541.5,-480.5 1541.5,-480.5 1541.5,-524.5 1541.5,-524.5 1541.5,-530.5 1535.5,-536.5 1529.5,-536.5\"/>\n<text text-anchor=\"start\" x=\"1448.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1451.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1449.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n<text text-anchor=\"start\" x=\"1462\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 40&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>40&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1580.084,-579.8796C1566.5385,-568.1138 1551.8092,-555.3197 1538.3002,-543.5855\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1540.3503,-540.7303 1530.5054,-536.8149 1535.7599,-546.015 1540.3503,-540.7303\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<path fill=\"#e6853f\" stroke=\"#000000\" d=\"M1690,-544C1690,-544 1572,-544 1572,-544 1566,-544 1560,-538 1560,-532 1560,-532 1560,-473 1560,-473 1560,-467 1566,-461 1572,-461 1572,-461 1690,-461 1690,-461 1696,-461 1702,-467 1702,-473 1702,-473 1702,-532 1702,-532 1702,-538 1696,-544 1690,-544\"/>\n<text text-anchor=\"start\" x=\"1568\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">installment ≤ &#45;0.708</text>\n<text text-anchor=\"start\" x=\"1580\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.203</text>\n<text text-anchor=\"start\" x=\"1587\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 63</text>\n<text text-anchor=\"start\" x=\"1585.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [61, 2]</text>\n<text text-anchor=\"start\" x=\"1602\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 40&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>40&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1629.0493,-579.8796C1629.2559,-571.6838 1629.4751,-562.9891 1629.689,-554.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1633.193,-554.3831 1629.9463,-544.2981 1626.1953,-554.2067 1633.193,-554.3831\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<path fill=\"#e88e4e\" stroke=\"#000000\" d=\"M1547,-425C1547,-425 1429,-425 1429,-425 1423,-425 1417,-419 1417,-413 1417,-413 1417,-354 1417,-354 1417,-348 1423,-342 1429,-342 1429,-342 1547,-342 1547,-342 1553,-342 1559,-348 1559,-354 1559,-354 1559,-413 1559,-413 1559,-419 1553,-425 1547,-425\"/>\n<text text-anchor=\"start\" x=\"1425\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">installment ≤ &#45;0.718</text>\n<text text-anchor=\"start\" x=\"1437\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.454</text>\n<text text-anchor=\"start\" x=\"1444\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 21</text>\n<text text-anchor=\"start\" x=\"1442.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [19, 2]</text>\n<text text-anchor=\"start\" x=\"1459\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 42&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>42&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1580.9855,-460.8796C1569.7299,-451.513 1557.6912,-441.4948 1546.1354,-431.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1548.1534,-429.0043 1538.2279,-425.2981 1543.6758,-434.385 1548.1534,-429.0043\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1672.5,-417.5C1672.5,-417.5 1589.5,-417.5 1589.5,-417.5 1583.5,-417.5 1577.5,-411.5 1577.5,-405.5 1577.5,-405.5 1577.5,-361.5 1577.5,-361.5 1577.5,-355.5 1583.5,-349.5 1589.5,-349.5 1589.5,-349.5 1672.5,-349.5 1672.5,-349.5 1678.5,-349.5 1684.5,-355.5 1684.5,-361.5 1684.5,-361.5 1684.5,-405.5 1684.5,-405.5 1684.5,-411.5 1678.5,-417.5 1672.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"1588.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1587\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 42</text>\n<text text-anchor=\"start\" x=\"1585.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [42, 0]</text>\n<text text-anchor=\"start\" x=\"1602\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 42&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>42&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1631,-460.8796C1631,-450.2134 1631,-438.7021 1631,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1634.5001,-427.8149 1631,-417.8149 1627.5001,-427.815 1634.5001,-427.8149\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<path fill=\"#e68843\" stroke=\"#000000\" d=\"M1502.5,-306C1502.5,-306 1321.5,-306 1321.5,-306 1315.5,-306 1309.5,-300 1309.5,-294 1309.5,-294 1309.5,-235 1309.5,-235 1309.5,-229 1315.5,-223 1321.5,-223 1321.5,-223 1502.5,-223 1502.5,-223 1508.5,-223 1514.5,-229 1514.5,-235 1514.5,-235 1514.5,-294 1514.5,-294 1514.5,-300 1508.5,-306 1502.5,-306\"/>\n<text text-anchor=\"start\" x=\"1317.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">purpose_educational ≤ 2.526</text>\n<text text-anchor=\"start\" x=\"1361\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.286</text>\n<text text-anchor=\"start\" x=\"1368\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20</text>\n<text text-anchor=\"start\" x=\"1366.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [19, 1]</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 43&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>43&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1461.4189,-341.8796C1455.8395,-333.1434 1449.8981,-323.8404 1444.1405,-314.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1447.0269,-312.8421 1438.6946,-306.2981 1441.1274,-316.6098 1447.0269,-312.8421\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1621.5,-298.5C1621.5,-298.5 1544.5,-298.5 1544.5,-298.5 1538.5,-298.5 1532.5,-292.5 1532.5,-286.5 1532.5,-286.5 1532.5,-242.5 1532.5,-242.5 1532.5,-236.5 1538.5,-230.5 1544.5,-230.5 1544.5,-230.5 1621.5,-230.5 1621.5,-230.5 1627.5,-230.5 1633.5,-236.5 1633.5,-242.5 1633.5,-242.5 1633.5,-286.5 1633.5,-286.5 1633.5,-292.5 1627.5,-298.5 1621.5,-298.5\"/>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1543.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1541.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"1554\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 43&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>43&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1521.2264,-341.8796C1530.2681,-330.5536 1540.0705,-318.2748 1549.1466,-306.9058\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1552.102,-308.8137 1555.6057,-298.8149 1546.6315,-304.4464 1552.102,-308.8137\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1453.5,-179.5C1453.5,-179.5 1370.5,-179.5 1370.5,-179.5 1364.5,-179.5 1358.5,-173.5 1358.5,-167.5 1358.5,-167.5 1358.5,-123.5 1358.5,-123.5 1358.5,-117.5 1364.5,-111.5 1370.5,-111.5 1370.5,-111.5 1453.5,-111.5 1453.5,-111.5 1459.5,-111.5 1465.5,-117.5 1465.5,-123.5 1465.5,-123.5 1465.5,-167.5 1465.5,-167.5 1465.5,-173.5 1459.5,-179.5 1453.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"1369.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1368\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n<text text-anchor=\"start\" x=\"1366.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 0]</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 44&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>44&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1412,-222.8796C1412,-212.2134 1412,-200.7021 1412,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1415.5001,-189.8149 1412,-179.8149 1408.5001,-189.815 1415.5001,-189.8149\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<path fill=\"#f2c09c\" stroke=\"#000000\" d=\"M1642,-187C1642,-187 1496,-187 1496,-187 1490,-187 1484,-181 1484,-175 1484,-175 1484,-116 1484,-116 1484,-110 1490,-104 1496,-104 1496,-104 1642,-104 1642,-104 1648,-104 1654,-110 1654,-116 1654,-116 1654,-175 1654,-175 1654,-181 1648,-187 1642,-187\"/>\n<text text-anchor=\"start\" x=\"1492\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">days.with.cr.line ≤ 0.164</text>\n<text text-anchor=\"start\" x=\"1518\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.918</text>\n<text text-anchor=\"start\" x=\"1529.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1527.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 1]</text>\n<text text-anchor=\"start\" x=\"1540\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 44&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>44&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1466.911,-222.8796C1479.5794,-213.2774 1493.1515,-202.9903 1506.1295,-193.1534\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1508.2648,-195.9268 1514.12,-187.0969 1504.0364,-190.3482 1508.2648,-195.9268\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1576.5,-68C1576.5,-68 1499.5,-68 1499.5,-68 1493.5,-68 1487.5,-62 1487.5,-56 1487.5,-56 1487.5,-12 1487.5,-12 1487.5,-6 1493.5,0 1499.5,0 1499.5,0 1576.5,0 1576.5,0 1582.5,0 1588.5,-6 1588.5,-12 1588.5,-12 1588.5,-56 1588.5,-56 1588.5,-62 1582.5,-68 1576.5,-68\"/>\n<text text-anchor=\"start\" x=\"1495.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1498.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1496.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"1509\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1557.4567,-103.9815C1555.1059,-95.5261 1552.6249,-86.6026 1550.2505,-78.0623\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1553.5771,-76.9607 1547.5262,-68.2637 1546.8329,-78.8358 1553.5771,-76.9607\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1695.5,-68C1695.5,-68 1618.5,-68 1618.5,-68 1612.5,-68 1606.5,-62 1606.5,-56 1606.5,-56 1606.5,-12 1606.5,-12 1606.5,-6 1612.5,0 1618.5,0 1618.5,0 1695.5,0 1695.5,0 1701.5,0 1707.5,-6 1707.5,-12 1707.5,-12 1707.5,-56 1707.5,-56 1707.5,-62 1701.5,-68 1695.5,-68\"/>\n<text text-anchor=\"start\" x=\"1614.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1617.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1615.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"1628\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 46&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>46&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1601.768,-103.9815C1608.949,-94.8828 1616.5579,-85.242 1623.7574,-76.1199\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1626.5099,-78.2818 1629.9578,-68.2637 1621.0151,-73.9451 1626.5099,-78.2818\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<path fill=\"#9ecff2\" stroke=\"#000000\" d=\"M1993,-663C1993,-663 1859,-663 1859,-663 1853,-663 1847,-657 1847,-651 1847,-651 1847,-592 1847,-592 1847,-586 1853,-580 1859,-580 1859,-580 1993,-580 1993,-580 1999,-580 2005,-586 2005,-592 2005,-592 2005,-651 2005,-651 2005,-657 1999,-663 1993,-663\"/>\n<text text-anchor=\"start\" x=\"1855\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 1.165</text>\n<text text-anchor=\"start\" x=\"1875\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.923</text>\n<text text-anchor=\"start\" x=\"1878\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 133</text>\n<text text-anchor=\"start\" x=\"1876\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [45, 88]</text>\n<text text-anchor=\"start\" x=\"1897\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 51&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>51&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1926,-698.8796C1926,-690.6838 1926,-681.9891 1926,-673.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1929.5001,-673.298 1926,-663.2981 1922.5001,-673.2981 1929.5001,-673.298\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2117.5,-655.5C2117.5,-655.5 2034.5,-655.5 2034.5,-655.5 2028.5,-655.5 2022.5,-649.5 2022.5,-643.5 2022.5,-643.5 2022.5,-599.5 2022.5,-599.5 2022.5,-593.5 2028.5,-587.5 2034.5,-587.5 2034.5,-587.5 2117.5,-587.5 2117.5,-587.5 2123.5,-587.5 2129.5,-593.5 2129.5,-599.5 2129.5,-599.5 2129.5,-643.5 2129.5,-643.5 2129.5,-649.5 2123.5,-655.5 2117.5,-655.5\"/>\n<text text-anchor=\"start\" x=\"2033.5\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2032\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 64</text>\n<text text-anchor=\"start\" x=\"2030.5\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [64, 0]</text>\n<text text-anchor=\"start\" x=\"2047\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 51&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>51&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1978.4627,-698.8796C1993.4322,-687.0038 2009.7222,-674.0804 2024.6259,-662.2568\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2027.087,-664.772 2032.7459,-655.8149 2022.7365,-659.2881 2027.087,-664.772\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<path fill=\"#f3c5a4\" stroke=\"#000000\" d=\"M1973,-544C1973,-544 1879,-544 1879,-544 1873,-544 1867,-538 1867,-532 1867,-532 1867,-473 1867,-473 1867,-467 1873,-461 1879,-461 1879,-461 1973,-461 1973,-461 1979,-461 1985,-467 1985,-473 1985,-473 1985,-532 1985,-532 1985,-538 1979,-544 1973,-544\"/>\n<text text-anchor=\"start\" x=\"1888.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 0.763</text>\n<text text-anchor=\"start\" x=\"1875\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.935</text>\n<text text-anchor=\"start\" x=\"1882\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 57</text>\n<text text-anchor=\"start\" x=\"1876\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [37, 20]</text>\n<text text-anchor=\"start\" x=\"1897\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 52&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>52&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1926,-579.8796C1926,-571.6838 1926,-562.9891 1926,-554.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1929.5001,-554.298 1926,-544.2981 1922.5001,-554.2981 1929.5001,-554.298\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<path fill=\"#50a9e8\" stroke=\"#000000\" d=\"M2114.5,-544C2114.5,-544 2015.5,-544 2015.5,-544 2009.5,-544 2003.5,-538 2003.5,-532 2003.5,-532 2003.5,-473 2003.5,-473 2003.5,-467 2009.5,-461 2015.5,-461 2015.5,-461 2114.5,-461 2114.5,-461 2120.5,-461 2126.5,-467 2126.5,-473 2126.5,-473 2126.5,-532 2126.5,-532 2126.5,-538 2120.5,-544 2114.5,-544\"/>\n<text text-anchor=\"start\" x=\"2011.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 3.036</text>\n<text text-anchor=\"start\" x=\"2014\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.485</text>\n<text text-anchor=\"start\" x=\"2021\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 76</text>\n<text text-anchor=\"start\" x=\"2019.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 68]</text>\n<text text-anchor=\"start\" x=\"2036\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 52&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>52&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1974.6155,-579.8796C1985.5562,-570.513 1997.2582,-560.4948 2008.4908,-550.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2010.8568,-553.4603 2016.177,-544.2981 2006.3044,-548.1428 2010.8568,-553.4603\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<path fill=\"#e99254\" stroke=\"#000000\" d=\"M1850,-425C1850,-425 1716,-425 1716,-425 1710,-425 1704,-419 1704,-413 1704,-413 1704,-354 1704,-354 1704,-348 1710,-342 1716,-342 1716,-342 1850,-342 1850,-342 1856,-342 1862,-348 1862,-354 1862,-354 1862,-413 1862,-413 1862,-419 1856,-425 1850,-425\"/>\n<text text-anchor=\"start\" x=\"1712\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 0.644</text>\n<text text-anchor=\"start\" x=\"1732\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.527</text>\n<text text-anchor=\"start\" x=\"1739\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 42</text>\n<text text-anchor=\"start\" x=\"1737.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [37, 5]</text>\n<text text-anchor=\"start\" x=\"1754\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 53&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>53&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1875.9855,-460.8796C1864.7299,-451.513 1852.6912,-441.4948 1841.1354,-431.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1843.1534,-429.0043 1833.2279,-425.2981 1838.6758,-434.385 1843.1534,-429.0043\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1974.5,-417.5C1974.5,-417.5 1891.5,-417.5 1891.5,-417.5 1885.5,-417.5 1879.5,-411.5 1879.5,-405.5 1879.5,-405.5 1879.5,-361.5 1879.5,-361.5 1879.5,-355.5 1885.5,-349.5 1891.5,-349.5 1891.5,-349.5 1974.5,-349.5 1974.5,-349.5 1980.5,-349.5 1986.5,-355.5 1986.5,-361.5 1986.5,-361.5 1986.5,-405.5 1986.5,-405.5 1986.5,-411.5 1980.5,-417.5 1974.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"1890.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1889\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1887.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 15]</text>\n<text text-anchor=\"start\" x=\"1904\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 53&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>53&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1928.4483,-460.8796C1929.0757,-450.2134 1929.7528,-438.7021 1930.3881,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1933.8881,-428.0032 1930.9815,-417.8149 1926.9002,-427.5921 1933.8881,-428.0032\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1746.5,-298.5C1746.5,-298.5 1663.5,-298.5 1663.5,-298.5 1657.5,-298.5 1651.5,-292.5 1651.5,-286.5 1651.5,-286.5 1651.5,-242.5 1651.5,-242.5 1651.5,-236.5 1657.5,-230.5 1663.5,-230.5 1663.5,-230.5 1746.5,-230.5 1746.5,-230.5 1752.5,-230.5 1758.5,-236.5 1758.5,-242.5 1758.5,-242.5 1758.5,-286.5 1758.5,-286.5 1758.5,-292.5 1752.5,-298.5 1746.5,-298.5\"/>\n<text text-anchor=\"start\" x=\"1662.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1661\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 23</text>\n<text text-anchor=\"start\" x=\"1659.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [23, 0]</text>\n<text text-anchor=\"start\" x=\"1676\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1755.7194,-341.8796C1748.3677,-330.6636 1740.4036,-318.5131 1733.0126,-307.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1735.9014,-305.2598 1727.4921,-298.8149 1730.0469,-309.0972 1735.9014,-305.2598\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<path fill=\"#eeae80\" stroke=\"#000000\" d=\"M1887.5,-306C1887.5,-306 1788.5,-306 1788.5,-306 1782.5,-306 1776.5,-300 1776.5,-294 1776.5,-294 1776.5,-235 1776.5,-235 1776.5,-229 1782.5,-223 1788.5,-223 1788.5,-223 1887.5,-223 1887.5,-223 1893.5,-223 1899.5,-229 1899.5,-235 1899.5,-235 1899.5,-294 1899.5,-294 1899.5,-300 1893.5,-306 1887.5,-306\"/>\n<text text-anchor=\"start\" x=\"1784.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 2.208</text>\n<text text-anchor=\"start\" x=\"1787\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.831</text>\n<text text-anchor=\"start\" x=\"1794\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n<text text-anchor=\"start\" x=\"1792.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 5]</text>\n<text text-anchor=\"start\" x=\"1809\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 54&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>54&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1802.2363,-341.8796C1806.1908,-333.3236 1810.3966,-324.2238 1814.4825,-315.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1817.6632,-316.8439 1818.6816,-306.2981 1811.309,-313.907 1817.6632,-316.8439\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<path fill=\"#b0d8f5\" stroke=\"#000000\" d=\"M1854,-187C1854,-187 1760,-187 1760,-187 1754,-187 1748,-181 1748,-175 1748,-175 1748,-116 1748,-116 1748,-110 1754,-104 1760,-104 1760,-104 1854,-104 1854,-104 1860,-104 1866,-110 1866,-116 1866,-116 1866,-175 1866,-175 1866,-181 1860,-187 1854,-187\"/>\n<text text-anchor=\"start\" x=\"1773.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.674</text>\n<text text-anchor=\"start\" x=\"1756\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.954</text>\n<text text-anchor=\"start\" x=\"1767.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1765.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 5]</text>\n<text text-anchor=\"start\" x=\"1778\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 56&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>56&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1827.1577,-222.8796C1824.9992,-214.5938 1822.7079,-205.798 1820.4737,-197.2216\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1823.7965,-196.0928 1817.8886,-187.2981 1817.0226,-197.8575 1823.7965,-196.0928\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1979.5,-179.5C1979.5,-179.5 1896.5,-179.5 1896.5,-179.5 1890.5,-179.5 1884.5,-173.5 1884.5,-167.5 1884.5,-167.5 1884.5,-123.5 1884.5,-123.5 1884.5,-117.5 1890.5,-111.5 1896.5,-111.5 1896.5,-111.5 1979.5,-111.5 1979.5,-111.5 1985.5,-111.5 1991.5,-117.5 1991.5,-123.5 1991.5,-123.5 1991.5,-167.5 1991.5,-167.5 1991.5,-173.5 1985.5,-179.5 1979.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"1895.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1894\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 11</text>\n<text text-anchor=\"start\" x=\"1892.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 0]</text>\n<text text-anchor=\"start\" x=\"1909\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 56&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>56&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1872.9751,-222.8796C1882.5852,-211.4436 1893.0115,-199.0363 1902.6429,-187.575\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1905.41,-189.7225 1909.1639,-179.8149 1900.0509,-185.219 1905.41,-189.7225\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1830.5,-68C1830.5,-68 1753.5,-68 1753.5,-68 1747.5,-68 1741.5,-62 1741.5,-56 1741.5,-56 1741.5,-12 1741.5,-12 1741.5,-6 1747.5,0 1753.5,0 1753.5,0 1830.5,0 1830.5,0 1836.5,0 1842.5,-6 1842.5,-12 1842.5,-12 1842.5,-56 1842.5,-56 1842.5,-62 1836.5,-68 1830.5,-68\"/>\n<text text-anchor=\"start\" x=\"1749.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1752.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1750.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5]</text>\n<text text-anchor=\"start\" x=\"1763\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 57&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>57&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1801.4146,-103.9815C1800.2894,-95.618 1799.1027,-86.7965 1797.9651,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1801.4116,-77.7077 1796.6095,-68.2637 1794.4741,-78.6411 1801.4116,-77.7077\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1949.5,-68C1949.5,-68 1872.5,-68 1872.5,-68 1866.5,-68 1860.5,-62 1860.5,-56 1860.5,-56 1860.5,-12 1860.5,-12 1860.5,-6 1866.5,0 1872.5,0 1872.5,0 1949.5,0 1949.5,0 1955.5,0 1961.5,-6 1961.5,-12 1961.5,-12 1961.5,-56 1961.5,-56 1961.5,-62 1955.5,-68 1949.5,-68\"/>\n<text text-anchor=\"start\" x=\"1868.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1871.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1869.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n<text text-anchor=\"start\" x=\"1882\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 57&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>57&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1845.7258,-103.9815C1854.2982,-94.7908 1863.3865,-85.0472 1871.971,-75.8436\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1874.7796,-77.9637 1879.0411,-68.2637 1869.6607,-73.1891 1874.7796,-77.9637\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<path fill=\"#3c9fe5\" stroke=\"#000000\" d=\"M2112,-425C2112,-425 2018,-425 2018,-425 2012,-425 2006,-419 2006,-413 2006,-413 2006,-354 2006,-354 2006,-348 2012,-342 2018,-342 2018,-342 2112,-342 2112,-342 2118,-342 2124,-348 2124,-354 2124,-354 2124,-413 2124,-413 2124,-419 2118,-425 2112,-425\"/>\n<text text-anchor=\"start\" x=\"2031.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.871</text>\n<text text-anchor=\"start\" x=\"2014\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.126</text>\n<text text-anchor=\"start\" x=\"2021\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 58</text>\n<text text-anchor=\"start\" x=\"2019.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 57]</text>\n<text text-anchor=\"start\" x=\"2036\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 62&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>62&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2065,-460.8796C2065,-452.6838 2065,-443.9891 2065,-435.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2068.5001,-435.298 2065,-425.2981 2061.5001,-435.2981 2068.5001,-435.298\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<path fill=\"#b7dbf6\" stroke=\"#000000\" d=\"M2288,-425C2288,-425 2154,-425 2154,-425 2148,-425 2142,-419 2142,-413 2142,-413 2142,-354 2142,-354 2142,-348 2148,-342 2154,-342 2154,-342 2288,-342 2288,-342 2294,-342 2300,-348 2300,-354 2300,-354 2300,-413 2300,-413 2300,-419 2294,-425 2288,-425\"/>\n<text text-anchor=\"start\" x=\"2150\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 1.732</text>\n<text text-anchor=\"start\" x=\"2170\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.964</text>\n<text text-anchor=\"start\" x=\"2177\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18</text>\n<text text-anchor=\"start\" x=\"2175.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 11]</text>\n<text text-anchor=\"start\" x=\"2192\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 62&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>62&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2119.5612,-460.8796C2132.0302,-451.368 2145.3802,-441.1843 2158.1648,-431.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2160.6415,-433.9448 2166.4696,-425.0969 2156.396,-428.3792 2160.6415,-433.9448\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2012.5,-298.5C2012.5,-298.5 1929.5,-298.5 1929.5,-298.5 1923.5,-298.5 1917.5,-292.5 1917.5,-286.5 1917.5,-286.5 1917.5,-242.5 1917.5,-242.5 1917.5,-236.5 1923.5,-230.5 1929.5,-230.5 1929.5,-230.5 2012.5,-230.5 2012.5,-230.5 2018.5,-230.5 2024.5,-236.5 2024.5,-242.5 2024.5,-242.5 2024.5,-286.5 2024.5,-286.5 2024.5,-292.5 2018.5,-298.5 2012.5,-298.5\"/>\n<text text-anchor=\"start\" x=\"1928.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1927\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 57</text>\n<text text-anchor=\"start\" x=\"1925.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 57]</text>\n<text text-anchor=\"start\" x=\"1942\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 63&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>63&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2032.1234,-341.8796C2023.1768,-330.5536 2013.4776,-318.2748 2004.4971,-306.9058\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2007.051,-304.4926 1998.1059,-298.8149 2001.558,-308.8316 2007.051,-304.4926\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2131.5,-298.5C2131.5,-298.5 2054.5,-298.5 2054.5,-298.5 2048.5,-298.5 2042.5,-292.5 2042.5,-286.5 2042.5,-286.5 2042.5,-242.5 2042.5,-242.5 2042.5,-236.5 2048.5,-230.5 2054.5,-230.5 2054.5,-230.5 2131.5,-230.5 2131.5,-230.5 2137.5,-230.5 2143.5,-236.5 2143.5,-242.5 2143.5,-242.5 2143.5,-286.5 2143.5,-286.5 2143.5,-292.5 2137.5,-298.5 2131.5,-298.5\"/>\n<text text-anchor=\"start\" x=\"2050.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2053.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2051.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n<text text-anchor=\"start\" x=\"2064\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 63&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>63&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2074.793,-341.8796C2077.3286,-331.1034 2080.0671,-319.4647 2082.6311,-308.5677\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2086.0424,-309.3508 2084.9259,-298.8149 2079.2285,-307.7474 2086.0424,-309.3508\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<path fill=\"#f0b78e\" stroke=\"#000000\" d=\"M2268,-306C2268,-306 2174,-306 2174,-306 2168,-306 2162,-300 2162,-294 2162,-294 2162,-235 2162,-235 2162,-229 2168,-223 2174,-223 2174,-223 2268,-223 2268,-223 2274,-223 2280,-229 2280,-235 2280,-235 2280,-294 2280,-294 2280,-300 2274,-306 2268,-306\"/>\n<text text-anchor=\"start\" x=\"2187.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.433</text>\n<text text-anchor=\"start\" x=\"2170\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.881</text>\n<text text-anchor=\"start\" x=\"2177\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2179.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 3]</text>\n<text text-anchor=\"start\" x=\"2192\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 66&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>66&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2221,-341.8796C2221,-333.6838 2221,-324.9891 2221,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2224.5001,-316.298 2221,-306.2981 2217.5001,-316.2981 2224.5001,-316.298\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2387.5,-298.5C2387.5,-298.5 2310.5,-298.5 2310.5,-298.5 2304.5,-298.5 2298.5,-292.5 2298.5,-286.5 2298.5,-286.5 2298.5,-242.5 2298.5,-242.5 2298.5,-236.5 2304.5,-230.5 2310.5,-230.5 2310.5,-230.5 2387.5,-230.5 2387.5,-230.5 2393.5,-230.5 2399.5,-236.5 2399.5,-242.5 2399.5,-242.5 2399.5,-286.5 2399.5,-286.5 2399.5,-292.5 2393.5,-298.5 2387.5,-298.5\"/>\n<text text-anchor=\"start\" x=\"2306.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2309.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2307.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 8]</text>\n<text text-anchor=\"start\" x=\"2320\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 66&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>66&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2265.7682,-341.8796C2278.3056,-330.2237 2291.9284,-317.5587 2304.453,-305.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2307.1491,-308.1872 2312.0898,-298.8149 2302.3828,-303.0605 2307.1491,-308.1872\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M2222,-187C2222,-187 2088,-187 2088,-187 2082,-187 2076,-181 2076,-175 2076,-175 2076,-116 2076,-116 2076,-110 2082,-104 2088,-104 2088,-104 2222,-104 2222,-104 2228,-104 2234,-110 2234,-116 2234,-116 2234,-175 2234,-175 2234,-181 2228,-187 2222,-187\"/>\n<text text-anchor=\"start\" x=\"2084\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 1.416</text>\n<text text-anchor=\"start\" x=\"2112.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"2115.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2113.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 3]</text>\n<text text-anchor=\"start\" x=\"2126\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 67&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>67&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2197.9164,-222.8796C2193.1211,-214.2335 2188.0178,-205.0322 2183.0662,-196.1042\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2186.0931,-194.3455 2178.1821,-187.2981 2179.9716,-197.7407 2186.0931,-194.3455\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2341.5,-179.5C2341.5,-179.5 2264.5,-179.5 2264.5,-179.5 2258.5,-179.5 2252.5,-173.5 2252.5,-167.5 2252.5,-167.5 2252.5,-123.5 2252.5,-123.5 2252.5,-117.5 2258.5,-111.5 2264.5,-111.5 2264.5,-111.5 2341.5,-111.5 2341.5,-111.5 2347.5,-111.5 2353.5,-117.5 2353.5,-123.5 2353.5,-123.5 2353.5,-167.5 2353.5,-167.5 2353.5,-173.5 2347.5,-179.5 2341.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"2260.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2263.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2261.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0]</text>\n<text text-anchor=\"start\" x=\"2274\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 67&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>67&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2249.6796,-222.8796C2257.4083,-211.6636 2265.7809,-199.5131 2273.5508,-188.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2276.5623,-190.0353 2279.3544,-179.8149 2270.7982,-186.0634 2276.5623,-190.0353\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2134.5,-68C2134.5,-68 2057.5,-68 2057.5,-68 2051.5,-68 2045.5,-62 2045.5,-56 2045.5,-56 2045.5,-12 2045.5,-12 2045.5,-6 2051.5,0 2057.5,0 2057.5,0 2134.5,0 2134.5,0 2140.5,0 2146.5,-6 2146.5,-12 2146.5,-12 2146.5,-56 2146.5,-56 2146.5,-62 2140.5,-68 2134.5,-68\"/>\n<text text-anchor=\"start\" x=\"2053.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2056.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2054.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n<text text-anchor=\"start\" x=\"2067\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2133.0306,-103.9815C2128.4105,-95.2504 2123.5264,-86.0202 2118.874,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2121.9013,-75.4655 2114.1306,-68.2637 2115.7141,-78.7395 2121.9013,-75.4655\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2253.5,-68C2253.5,-68 2176.5,-68 2176.5,-68 2170.5,-68 2164.5,-62 2164.5,-56 2164.5,-56 2164.5,-12 2164.5,-12 2164.5,-6 2170.5,0 2176.5,0 2176.5,0 2253.5,0 2253.5,0 2259.5,0 2265.5,-6 2265.5,-12 2265.5,-12 2265.5,-56 2265.5,-56 2265.5,-62 2259.5,-68 2253.5,-68\"/>\n<text text-anchor=\"start\" x=\"2172.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2175.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2173.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n<text text-anchor=\"start\" x=\"2186\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 68&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>68&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2177.3418,-103.9815C2182.0402,-95.2504 2187.0071,-86.0202 2191.7383,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2194.9056,-78.7282 2196.5621,-68.2637 2188.7414,-75.4111 2194.9056,-78.7282\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2236,-1012.5C2236,-1012.5 2144,-1012.5 2144,-1012.5 2138,-1012.5 2132,-1006.5 2132,-1000.5 2132,-1000.5 2132,-956.5 2132,-956.5 2132,-950.5 2138,-944.5 2144,-944.5 2144,-944.5 2236,-944.5 2236,-944.5 2242,-944.5 2248,-950.5 2248,-956.5 2248,-956.5 2248,-1000.5 2248,-1000.5 2248,-1006.5 2242,-1012.5 2236,-1012.5\"/>\n<text text-anchor=\"start\" x=\"2147.5\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2142\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 849</text>\n<text text-anchor=\"start\" x=\"2140\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [849, 0]</text>\n<text text-anchor=\"start\" x=\"2161\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 74&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>74&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2190,-1055.8796C2190,-1045.2134 2190,-1033.7021 2190,-1022.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2193.5001,-1022.8149 2190,-1012.8149 2186.5001,-1022.815 2193.5001,-1022.8149\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<path fill=\"#54aae8\" stroke=\"#000000\" d=\"M2498,-1020C2498,-1020 2364,-1020 2364,-1020 2358,-1020 2352,-1014 2352,-1008 2352,-1008 2352,-949 2352,-949 2352,-943 2358,-937 2364,-937 2364,-937 2498,-937 2498,-937 2504,-937 2510,-943 2510,-949 2510,-949 2510,-1008 2510,-1008 2510,-1014 2504,-1020 2498,-1020\"/>\n<text text-anchor=\"start\" x=\"2360\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">inq.last.6mths ≤ 3.124</text>\n<text text-anchor=\"start\" x=\"2380\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.524</text>\n<text text-anchor=\"start\" x=\"2383\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 144</text>\n<text text-anchor=\"start\" x=\"2377\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 127]</text>\n<text text-anchor=\"start\" x=\"2402\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 74&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>74&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2256.1731,-1064.8253C2282.8297,-1051.6629 2313.9723,-1036.2854 2342.5277,-1022.1855\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2344.2821,-1025.2227 2351.699,-1017.6569 2341.1829,-1018.9461 2344.2821,-1025.2227\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<path fill=\"#4aa5e7\" stroke=\"#000000\" d=\"M2481,-901C2481,-901 2381,-901 2381,-901 2375,-901 2369,-895 2369,-889 2369,-889 2369,-830 2369,-830 2369,-824 2375,-818 2381,-818 2381,-818 2481,-818 2481,-818 2487,-818 2493,-824 2493,-830 2493,-830 2493,-889 2493,-889 2493,-895 2487,-901 2481,-901\"/>\n<text text-anchor=\"start\" x=\"2377.5\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 3.734</text>\n<text text-anchor=\"start\" x=\"2380\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.401</text>\n<text text-anchor=\"start\" x=\"2383\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 138</text>\n<text text-anchor=\"start\" x=\"2377\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 127]</text>\n<text text-anchor=\"start\" x=\"2402\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 76&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>76&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2431,-936.8796C2431,-928.6838 2431,-919.9891 2431,-911.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2434.5001,-911.298 2431,-901.2981 2427.5001,-911.2981 2434.5001,-911.298\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2600.5,-893.5C2600.5,-893.5 2523.5,-893.5 2523.5,-893.5 2517.5,-893.5 2511.5,-887.5 2511.5,-881.5 2511.5,-881.5 2511.5,-837.5 2511.5,-837.5 2511.5,-831.5 2517.5,-825.5 2523.5,-825.5 2523.5,-825.5 2600.5,-825.5 2600.5,-825.5 2606.5,-825.5 2612.5,-831.5 2612.5,-837.5 2612.5,-837.5 2612.5,-881.5 2612.5,-881.5 2612.5,-887.5 2606.5,-893.5 2600.5,-893.5\"/>\n<text text-anchor=\"start\" x=\"2519.5\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2522.5\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2520.5\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 0]</text>\n<text text-anchor=\"start\" x=\"2533\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 76&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>76&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2476.8174,-936.8796C2489.7697,-925.1138 2503.854,-912.3197 2516.7714,-900.5855\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2519.1761,-903.1296 2524.2247,-893.8149 2514.4694,-897.9482 2519.1761,-903.1296\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<path fill=\"#44a2e6\" stroke=\"#000000\" d=\"M2478,-782C2478,-782 2384,-782 2384,-782 2378,-782 2372,-776 2372,-770 2372,-770 2372,-711 2372,-711 2372,-705 2378,-699 2384,-699 2384,-699 2478,-699 2478,-699 2484,-699 2490,-705 2490,-711 2490,-711 2490,-770 2490,-770 2490,-776 2484,-782 2478,-782\"/>\n<text text-anchor=\"start\" x=\"2381\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ &#45;1.513</text>\n<text text-anchor=\"start\" x=\"2380\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.296</text>\n<text text-anchor=\"start\" x=\"2383\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 134</text>\n<text text-anchor=\"start\" x=\"2381\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 127]</text>\n<text text-anchor=\"start\" x=\"2402\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 77&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>77&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2431,-817.8796C2431,-809.6838 2431,-800.9891 2431,-792.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2434.5001,-792.298 2431,-782.2981 2427.5001,-792.2981 2434.5001,-792.298\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2597.5,-774.5C2597.5,-774.5 2520.5,-774.5 2520.5,-774.5 2514.5,-774.5 2508.5,-768.5 2508.5,-762.5 2508.5,-762.5 2508.5,-718.5 2508.5,-718.5 2508.5,-712.5 2514.5,-706.5 2520.5,-706.5 2520.5,-706.5 2597.5,-706.5 2597.5,-706.5 2603.5,-706.5 2609.5,-712.5 2609.5,-718.5 2609.5,-718.5 2609.5,-762.5 2609.5,-762.5 2609.5,-768.5 2603.5,-774.5 2597.5,-774.5\"/>\n<text text-anchor=\"start\" x=\"2516.5\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2519.5\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2517.5\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0]</text>\n<text text-anchor=\"start\" x=\"2530\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 77&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>77&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2475.7682,-817.8796C2488.3056,-806.2237 2501.9284,-793.5587 2514.453,-781.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2517.1491,-784.1872 2522.0898,-774.8149 2512.3828,-779.0605 2517.1491,-784.1872\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<path fill=\"#94caf1\" stroke=\"#000000\" d=\"M2478.5,-663C2478.5,-663 2383.5,-663 2383.5,-663 2377.5,-663 2371.5,-657 2371.5,-651 2371.5,-651 2371.5,-592 2371.5,-592 2371.5,-586 2377.5,-580 2383.5,-580 2383.5,-580 2478.5,-580 2478.5,-580 2484.5,-580 2490.5,-586 2490.5,-592 2490.5,-592 2490.5,-651 2490.5,-651 2490.5,-657 2484.5,-663 2478.5,-663\"/>\n<text text-anchor=\"start\" x=\"2379.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ &#45;0.48</text>\n<text text-anchor=\"start\" x=\"2388.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.9</text>\n<text text-anchor=\"start\" x=\"2387\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n<text text-anchor=\"start\" x=\"2385.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 13]</text>\n<text text-anchor=\"start\" x=\"2402\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 78&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>78&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2431,-698.8796C2431,-690.6838 2431,-681.9891 2431,-673.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2434.5001,-673.298 2431,-663.2981 2427.5001,-673.2981 2434.5001,-673.298\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M2677,-663C2677,-663 2583,-663 2583,-663 2577,-663 2571,-657 2571,-651 2571,-651 2571,-592 2571,-592 2571,-586 2577,-580 2583,-580 2583,-580 2677,-580 2677,-580 2683,-580 2689,-586 2689,-592 2689,-592 2689,-651 2689,-651 2689,-657 2683,-663 2677,-663\"/>\n<text text-anchor=\"start\" x=\"2596.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.924</text>\n<text text-anchor=\"start\" x=\"2579\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.072</text>\n<text text-anchor=\"start\" x=\"2582\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 115</text>\n<text text-anchor=\"start\" x=\"2580\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 114]</text>\n<text text-anchor=\"start\" x=\"2601\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 78&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>78&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2490.309,-704.2383C2493.2455,-702.4635 2496.1549,-700.7097 2499,-699 2519.421,-686.7288 2541.7063,-673.4886 2562.0099,-661.4839\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2564.0517,-664.3428 2570.881,-656.2427 2560.491,-658.3161 2564.0517,-664.3428\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<path fill=\"#eeab7b\" stroke=\"#000000\" d=\"M2416,-544C2416,-544 2322,-544 2322,-544 2316,-544 2310,-538 2310,-532 2310,-532 2310,-473 2310,-473 2310,-467 2316,-461 2322,-461 2322,-461 2416,-461 2416,-461 2422,-461 2428,-467 2428,-473 2428,-473 2428,-532 2428,-532 2428,-538 2422,-544 2416,-544\"/>\n<text text-anchor=\"start\" x=\"2318\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.59</text>\n<text text-anchor=\"start\" x=\"2318\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.811</text>\n<text text-anchor=\"start\" x=\"2329.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2327.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 2]</text>\n<text text-anchor=\"start\" x=\"2340\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 79&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>79&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2409.3154,-579.8796C2404.8577,-571.3236 2400.1166,-562.2238 2395.5106,-553.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2398.5017,-551.5494 2390.7771,-544.2981 2392.2938,-554.7838 2398.5017,-551.5494\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2541.5,-536.5C2541.5,-536.5 2458.5,-536.5 2458.5,-536.5 2452.5,-536.5 2446.5,-530.5 2446.5,-524.5 2446.5,-524.5 2446.5,-480.5 2446.5,-480.5 2446.5,-474.5 2452.5,-468.5 2458.5,-468.5 2458.5,-468.5 2541.5,-468.5 2541.5,-468.5 2547.5,-468.5 2553.5,-474.5 2553.5,-480.5 2553.5,-480.5 2553.5,-524.5 2553.5,-524.5 2553.5,-530.5 2547.5,-536.5 2541.5,-536.5\"/>\n<text text-anchor=\"start\" x=\"2457.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2456\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 11</text>\n<text text-anchor=\"start\" x=\"2454.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 11]</text>\n<text text-anchor=\"start\" x=\"2471\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 79&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>79&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2455.1329,-579.8796C2461.5725,-568.7735 2468.5434,-556.7513 2475.0271,-545.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2478.1148,-547.2215 2480.1031,-536.8149 2472.0591,-543.7102 2478.1148,-547.2215\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2407.5,-417.5C2407.5,-417.5 2330.5,-417.5 2330.5,-417.5 2324.5,-417.5 2318.5,-411.5 2318.5,-405.5 2318.5,-405.5 2318.5,-361.5 2318.5,-361.5 2318.5,-355.5 2324.5,-349.5 2330.5,-349.5 2330.5,-349.5 2407.5,-349.5 2407.5,-349.5 2413.5,-349.5 2419.5,-355.5 2419.5,-361.5 2419.5,-361.5 2419.5,-405.5 2419.5,-405.5 2419.5,-411.5 2413.5,-417.5 2407.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"2326.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2329.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2327.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n<text text-anchor=\"start\" x=\"2340\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 80&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>80&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2369,-460.8796C2369,-450.2134 2369,-438.7021 2369,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2372.5001,-427.8149 2369,-417.8149 2365.5001,-427.815 2372.5001,-427.8149\"/>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2526.5,-417.5C2526.5,-417.5 2449.5,-417.5 2449.5,-417.5 2443.5,-417.5 2437.5,-411.5 2437.5,-405.5 2437.5,-405.5 2437.5,-361.5 2437.5,-361.5 2437.5,-355.5 2443.5,-349.5 2449.5,-349.5 2449.5,-349.5 2526.5,-349.5 2526.5,-349.5 2532.5,-349.5 2538.5,-355.5 2538.5,-361.5 2538.5,-361.5 2538.5,-405.5 2538.5,-405.5 2538.5,-411.5 2532.5,-417.5 2526.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"2445.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2448.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2446.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 0]</text>\n<text text-anchor=\"start\" x=\"2459\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 80&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>80&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2410.6204,-460.8796C2422.2763,-449.2237 2434.9413,-436.5587 2446.5852,-424.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2449.0889,-427.3609 2453.6851,-417.8149 2444.1391,-422.4111 2449.0889,-427.3609\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2676,-536.5C2676,-536.5 2584,-536.5 2584,-536.5 2578,-536.5 2572,-530.5 2572,-524.5 2572,-524.5 2572,-480.5 2572,-480.5 2572,-474.5 2578,-468.5 2584,-468.5 2584,-468.5 2676,-468.5 2676,-468.5 2682,-468.5 2688,-474.5 2688,-480.5 2688,-480.5 2688,-524.5 2688,-524.5 2688,-530.5 2682,-536.5 2676,-536.5\"/>\n<text text-anchor=\"start\" x=\"2587.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2582\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 114</text>\n<text text-anchor=\"start\" x=\"2580\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 114]</text>\n<text text-anchor=\"start\" x=\"2601\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 84&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>84&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2630,-579.8796C2630,-569.2134 2630,-557.7021 2630,-546.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2633.5001,-546.8149 2630,-536.8149 2626.5001,-546.815 2633.5001,-546.8149\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2795.5,-536.5C2795.5,-536.5 2718.5,-536.5 2718.5,-536.5 2712.5,-536.5 2706.5,-530.5 2706.5,-524.5 2706.5,-524.5 2706.5,-480.5 2706.5,-480.5 2706.5,-474.5 2712.5,-468.5 2718.5,-468.5 2718.5,-468.5 2795.5,-468.5 2795.5,-468.5 2801.5,-468.5 2807.5,-474.5 2807.5,-480.5 2807.5,-480.5 2807.5,-524.5 2807.5,-524.5 2807.5,-530.5 2801.5,-536.5 2795.5,-536.5\"/>\n<text text-anchor=\"start\" x=\"2714.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2717.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2715.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n<text text-anchor=\"start\" x=\"2728\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 84&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>84&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2674.4184,-579.8796C2686.8579,-568.2237 2700.3743,-555.5587 2712.801,-543.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2715.4741,-546.2065 2720.3782,-536.8149 2710.6879,-541.0985 2715.4741,-546.2065\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Visualization\n",
        "\n",
        "graph = plot_tree(RF_clf.estimators_[1])\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TXjwRR7PHyyS",
        "outputId": "e018140d-fce2-41cf-f1f8-e0b6be3ea0d7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f4ed8626990>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2676pt\" height=\"1623pt\"\n viewBox=\"0.00 0.00 2676.00 1623.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1619)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1619 2672,-1619 2672,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#68b4eb\" stroke=\"#000000\" d=\"M2012.5,-1615C2012.5,-1615 1878.5,-1615 1878.5,-1615 1872.5,-1615 1866.5,-1609 1866.5,-1603 1866.5,-1603 1866.5,-1544 1866.5,-1544 1866.5,-1538 1872.5,-1532 1878.5,-1532 1878.5,-1532 2012.5,-1532 2012.5,-1532 2018.5,-1532 2024.5,-1538 2024.5,-1544 2024.5,-1544 2024.5,-1603 2024.5,-1603 2024.5,-1609 2018.5,-1615 2012.5,-1615\"/>\n<text text-anchor=\"start\" x=\"1874.5\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">inq.last.6mths ≤ 0.864</text>\n<text text-anchor=\"start\" x=\"1894.5\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.707</text>\n<text text-anchor=\"start\" x=\"1893.5\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4857</text>\n<text text-anchor=\"start\" x=\"1879\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1478, 6184]</text>\n<text text-anchor=\"start\" x=\"1916.5\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#4ea7e8\" stroke=\"#000000\" d=\"M1921.5,-1496C1921.5,-1496 1805.5,-1496 1805.5,-1496 1799.5,-1496 1793.5,-1490 1793.5,-1484 1793.5,-1484 1793.5,-1425 1793.5,-1425 1793.5,-1419 1799.5,-1413 1805.5,-1413 1805.5,-1413 1921.5,-1413 1921.5,-1413 1927.5,-1413 1933.5,-1419 1933.5,-1425 1933.5,-1425 1933.5,-1484 1933.5,-1484 1933.5,-1490 1927.5,-1496 1921.5,-1496\"/>\n<text text-anchor=\"start\" x=\"1824\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ &#45;1.348</text>\n<text text-anchor=\"start\" x=\"1812.5\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.455</text>\n<text text-anchor=\"start\" x=\"1811.5\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4225</text>\n<text text-anchor=\"start\" x=\"1801.5\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [639, 6036]</text>\n<text text-anchor=\"start\" x=\"1834.5\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1916.8204,-1531.8796C1910.7385,-1523.0534 1904.2578,-1513.6485 1897.9859,-1504.5466\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1900.8582,-1502.5465 1892.302,-1496.2981 1895.0941,-1506.5184 1900.8582,-1502.5465\"/>\n<text text-anchor=\"middle\" x=\"1887.7761\" y=\"-1517.185\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<path fill=\"#ea975c\" stroke=\"#000000\" d=\"M2105.5,-1496C2105.5,-1496 1997.5,-1496 1997.5,-1496 1991.5,-1496 1985.5,-1490 1985.5,-1484 1985.5,-1484 1985.5,-1425 1985.5,-1425 1985.5,-1419 1991.5,-1413 1997.5,-1413 1997.5,-1413 2105.5,-1413 2105.5,-1413 2111.5,-1413 2117.5,-1419 2117.5,-1425 2117.5,-1425 2117.5,-1484 2117.5,-1484 2117.5,-1490 2111.5,-1496 2105.5,-1496\"/>\n<text text-anchor=\"start\" x=\"2014\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 0.763</text>\n<text text-anchor=\"start\" x=\"2004.5\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.61</text>\n<text text-anchor=\"start\" x=\"2003.5\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 632</text>\n<text text-anchor=\"start\" x=\"1993.5\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [839, 148]</text>\n<text text-anchor=\"start\" x=\"2022.5\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>0&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1982.5737,-1531.8796C1990.5961,-1522.8733 1999.1552,-1513.2644 2007.4167,-1503.9897\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2010.2302,-1506.0933 2014.2681,-1496.2981 2005.0031,-1501.4373 2010.2302,-1506.0933\"/>\n<text text-anchor=\"middle\" x=\"2015.7101\" y=\"-1517.5564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e5813a\" stroke=\"#000000\" d=\"M1697.5,-1377C1697.5,-1377 1603.5,-1377 1603.5,-1377 1597.5,-1377 1591.5,-1371 1591.5,-1365 1591.5,-1365 1591.5,-1306 1591.5,-1306 1591.5,-1300 1597.5,-1294 1603.5,-1294 1603.5,-1294 1697.5,-1294 1697.5,-1294 1703.5,-1294 1709.5,-1300 1709.5,-1306 1709.5,-1306 1709.5,-1365 1709.5,-1365 1709.5,-1371 1703.5,-1377 1697.5,-1377\"/>\n<text text-anchor=\"start\" x=\"1611\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ &#45;2.007</text>\n<text text-anchor=\"start\" x=\"1599.5\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.036</text>\n<text text-anchor=\"start\" x=\"1602.5\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 170</text>\n<text text-anchor=\"start\" x=\"1600.5\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [266, 1]</text>\n<text text-anchor=\"start\" x=\"1621.5\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1793.4608,-1415.3701C1769.377,-1401.9149 1742.4642,-1386.879 1718.5418,-1373.514\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1719.9689,-1370.3021 1709.5318,-1368.4802 1716.5547,-1376.4131 1719.9689,-1370.3021\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#45a3e7\" stroke=\"#000000\" d=\"M1939,-1377C1939,-1377 1788,-1377 1788,-1377 1782,-1377 1776,-1371 1776,-1365 1776,-1365 1776,-1306 1776,-1306 1776,-1300 1782,-1294 1788,-1294 1788,-1294 1939,-1294 1939,-1294 1945,-1294 1951,-1300 1951,-1306 1951,-1306 1951,-1365 1951,-1365 1951,-1371 1945,-1377 1939,-1377\"/>\n<text text-anchor=\"start\" x=\"1784\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">days.with.cr.line ≤ &#45;1.386</text>\n<text text-anchor=\"start\" x=\"1816.5\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.32</text>\n<text text-anchor=\"start\" x=\"1811.5\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4055</text>\n<text text-anchor=\"start\" x=\"1801.5\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [373, 6035]</text>\n<text text-anchor=\"start\" x=\"1834.5\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1863.5,-1412.8796C1863.5,-1404.6838 1863.5,-1395.9891 1863.5,-1387.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1867.0001,-1387.298 1863.5,-1377.2981 1860.0001,-1387.2981 1867.0001,-1387.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1562,-1250.5C1562,-1250.5 1485,-1250.5 1485,-1250.5 1479,-1250.5 1473,-1244.5 1473,-1238.5 1473,-1238.5 1473,-1194.5 1473,-1194.5 1473,-1188.5 1479,-1182.5 1485,-1182.5 1485,-1182.5 1562,-1182.5 1562,-1182.5 1568,-1182.5 1574,-1188.5 1574,-1194.5 1574,-1194.5 1574,-1238.5 1574,-1238.5 1574,-1244.5 1568,-1250.5 1562,-1250.5\"/>\n<text text-anchor=\"start\" x=\"1481\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1484\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1482\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"1494.5\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1606.0816,-1293.8796C1593.6421,-1282.2237 1580.1257,-1269.5587 1567.699,-1257.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1569.8121,-1255.0985 1560.1218,-1250.8149 1565.0259,-1260.2065 1569.8121,-1255.0985\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1696.5,-1250.5C1696.5,-1250.5 1604.5,-1250.5 1604.5,-1250.5 1598.5,-1250.5 1592.5,-1244.5 1592.5,-1238.5 1592.5,-1238.5 1592.5,-1194.5 1592.5,-1194.5 1592.5,-1188.5 1598.5,-1182.5 1604.5,-1182.5 1604.5,-1182.5 1696.5,-1182.5 1696.5,-1182.5 1702.5,-1182.5 1708.5,-1188.5 1708.5,-1194.5 1708.5,-1194.5 1708.5,-1238.5 1708.5,-1238.5 1708.5,-1244.5 1702.5,-1250.5 1696.5,-1250.5\"/>\n<text text-anchor=\"start\" x=\"1608\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1602.5\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 169</text>\n<text text-anchor=\"start\" x=\"1600.5\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [266, 0]</text>\n<text text-anchor=\"start\" x=\"1621.5\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1650.5,-1293.8796C1650.5,-1283.2134 1650.5,-1271.7021 1650.5,-1260.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1654.0001,-1260.8149 1650.5,-1250.8149 1647.0001,-1260.815 1654.0001,-1260.8149\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1830.5,-1250.5C1830.5,-1250.5 1738.5,-1250.5 1738.5,-1250.5 1732.5,-1250.5 1726.5,-1244.5 1726.5,-1238.5 1726.5,-1238.5 1726.5,-1194.5 1726.5,-1194.5 1726.5,-1188.5 1732.5,-1182.5 1738.5,-1182.5 1738.5,-1182.5 1830.5,-1182.5 1830.5,-1182.5 1836.5,-1182.5 1842.5,-1188.5 1842.5,-1194.5 1842.5,-1194.5 1842.5,-1238.5 1842.5,-1238.5 1842.5,-1244.5 1836.5,-1250.5 1830.5,-1250.5\"/>\n<text text-anchor=\"start\" x=\"1742\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1740.5\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 73</text>\n<text text-anchor=\"start\" x=\"1734.5\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [117, 0]</text>\n<text text-anchor=\"start\" x=\"1755.5\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1835.8696,-1293.8796C1828.4237,-1282.6636 1820.3575,-1270.5131 1812.8718,-1259.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1815.7273,-1257.2104 1807.2805,-1250.8149 1809.8954,-1261.082 1815.7273,-1257.2104\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#41a1e6\" stroke=\"#000000\" d=\"M1988.5,-1258C1988.5,-1258 1872.5,-1258 1872.5,-1258 1866.5,-1258 1860.5,-1252 1860.5,-1246 1860.5,-1246 1860.5,-1187 1860.5,-1187 1860.5,-1181 1866.5,-1175 1872.5,-1175 1872.5,-1175 1988.5,-1175 1988.5,-1175 1994.5,-1175 2000.5,-1181 2000.5,-1187 2000.5,-1187 2000.5,-1246 2000.5,-1246 2000.5,-1252 1994.5,-1258 1988.5,-1258\"/>\n<text text-anchor=\"start\" x=\"1901\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 1.78</text>\n<text text-anchor=\"start\" x=\"1879.5\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.245</text>\n<text text-anchor=\"start\" x=\"1878.5\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3982</text>\n<text text-anchor=\"start\" x=\"1868.5\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [256, 6035]</text>\n<text text-anchor=\"start\" x=\"1901.5\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1886.9333,-1293.8796C1891.8013,-1285.2335 1896.9819,-1276.0322 1902.0086,-1267.1042\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1905.1103,-1268.729 1906.9666,-1258.2981 1899.0107,-1265.2947 1905.1103,-1268.729\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#3fa0e6\" stroke=\"#000000\" d=\"M1762.5,-1139C1762.5,-1139 1646.5,-1139 1646.5,-1139 1640.5,-1139 1634.5,-1133 1634.5,-1127 1634.5,-1127 1634.5,-1068 1634.5,-1068 1634.5,-1062 1640.5,-1056 1646.5,-1056 1646.5,-1056 1762.5,-1056 1762.5,-1056 1768.5,-1056 1774.5,-1062 1774.5,-1068 1774.5,-1068 1774.5,-1127 1774.5,-1127 1774.5,-1133 1768.5,-1139 1762.5,-1139\"/>\n<text text-anchor=\"start\" x=\"1651\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 1.649</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.183</text>\n<text text-anchor=\"start\" x=\"1652.5\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3926</text>\n<text text-anchor=\"start\" x=\"1642.5\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [172, 6031]</text>\n<text text-anchor=\"start\" x=\"1675.5\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1860.231,-1179.5C1835.9963,-1166.7392 1808.6864,-1152.3592 1783.7819,-1139.2458\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1785.2046,-1136.0394 1774.7255,-1134.4772 1781.9432,-1142.2332 1785.2046,-1136.0394\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<path fill=\"#e68742\" stroke=\"#000000\" d=\"M1981.5,-1139C1981.5,-1139 1879.5,-1139 1879.5,-1139 1873.5,-1139 1867.5,-1133 1867.5,-1127 1867.5,-1127 1867.5,-1068 1867.5,-1068 1867.5,-1062 1873.5,-1056 1879.5,-1056 1879.5,-1056 1981.5,-1056 1981.5,-1056 1987.5,-1056 1993.5,-1062 1993.5,-1068 1993.5,-1068 1993.5,-1127 1993.5,-1127 1993.5,-1133 1987.5,-1139 1981.5,-1139\"/>\n<text text-anchor=\"start\" x=\"1875.5\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.282</text>\n<text text-anchor=\"start\" x=\"1879.5\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.267</text>\n<text text-anchor=\"start\" x=\"1886.5\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 56</text>\n<text text-anchor=\"start\" x=\"1885\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [84, 4]</text>\n<text text-anchor=\"start\" x=\"1901.5\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 7&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>7&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1930.5,-1174.8796C1930.5,-1166.6838 1930.5,-1157.9891 1930.5,-1149.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1934.0001,-1149.298 1930.5,-1139.2981 1927.0001,-1149.2981 1934.0001,-1149.298\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M1589.5,-1020C1589.5,-1020 1481.5,-1020 1481.5,-1020 1475.5,-1020 1469.5,-1014 1469.5,-1008 1469.5,-1008 1469.5,-949 1469.5,-949 1469.5,-943 1475.5,-937 1481.5,-937 1481.5,-937 1589.5,-937 1589.5,-937 1595.5,-937 1601.5,-943 1601.5,-949 1601.5,-949 1601.5,-1008 1601.5,-1008 1601.5,-1014 1595.5,-1020 1589.5,-1020\"/>\n<text text-anchor=\"start\" x=\"1482.5\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ 1.812</text>\n<text text-anchor=\"start\" x=\"1484.5\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.085</text>\n<text text-anchor=\"start\" x=\"1483.5\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3794</text>\n<text text-anchor=\"start\" x=\"1477.5\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [64, 5933]</text>\n<text text-anchor=\"start\" x=\"1506.5\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1645.392,-1055.8796C1631.6266,-1046.1868 1616.8701,-1035.7961 1602.7807,-1025.8752\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1604.7661,-1022.9926 1594.5746,-1020.0969 1600.7359,-1028.716 1604.7661,-1022.9926\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<path fill=\"#fdf3ed\" stroke=\"#000000\" d=\"M1754.5,-1020C1754.5,-1020 1654.5,-1020 1654.5,-1020 1648.5,-1020 1642.5,-1014 1642.5,-1008 1642.5,-1008 1642.5,-949 1642.5,-949 1642.5,-943 1648.5,-937 1654.5,-937 1654.5,-937 1754.5,-937 1754.5,-937 1760.5,-937 1766.5,-943 1766.5,-949 1766.5,-949 1766.5,-1008 1766.5,-1008 1766.5,-1014 1760.5,-1020 1754.5,-1020\"/>\n<text text-anchor=\"start\" x=\"1651\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 3.847</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.998</text>\n<text text-anchor=\"start\" x=\"1656.5\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 132</text>\n<text text-anchor=\"start\" x=\"1650.5\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [108, 98]</text>\n<text text-anchor=\"start\" x=\"1675.5\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 8&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>8&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1704.5,-1055.8796C1704.5,-1047.6838 1704.5,-1038.9891 1704.5,-1030.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1708.0001,-1030.298 1704.5,-1020.2981 1701.0001,-1030.2981 1708.0001,-1030.298\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M1388.5,-901C1388.5,-901 1280.5,-901 1280.5,-901 1274.5,-901 1268.5,-895 1268.5,-889 1268.5,-889 1268.5,-830 1268.5,-830 1268.5,-824 1274.5,-818 1280.5,-818 1280.5,-818 1388.5,-818 1388.5,-818 1394.5,-818 1400.5,-824 1400.5,-830 1400.5,-830 1400.5,-889 1400.5,-889 1400.5,-895 1394.5,-901 1388.5,-901\"/>\n<text text-anchor=\"start\" x=\"1281\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.595</text>\n<text text-anchor=\"start\" x=\"1283.5\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.066</text>\n<text text-anchor=\"start\" x=\"1282.5\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3785</text>\n<text text-anchor=\"start\" x=\"1276.5\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [47, 5933]</text>\n<text text-anchor=\"start\" x=\"1305.5\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1469.4067,-939.3701C1450.17,-927.9813 1429.0207,-915.46 1409.2889,-903.778\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1411.0211,-900.7362 1400.633,-898.6534 1407.4549,-906.7597 1411.0211,-900.7362\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1577,-893.5C1577,-893.5 1494,-893.5 1494,-893.5 1488,-893.5 1482,-887.5 1482,-881.5 1482,-881.5 1482,-837.5 1482,-837.5 1482,-831.5 1488,-825.5 1494,-825.5 1494,-825.5 1577,-825.5 1577,-825.5 1583,-825.5 1589,-831.5 1589,-837.5 1589,-837.5 1589,-881.5 1589,-881.5 1589,-887.5 1583,-893.5 1577,-893.5\"/>\n<text text-anchor=\"start\" x=\"1493\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1496\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1490\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 0]</text>\n<text text-anchor=\"start\" x=\"1506.5\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>9&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1535.5,-936.8796C1535.5,-926.2134 1535.5,-914.7021 1535.5,-903.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1539.0001,-903.8149 1535.5,-893.8149 1532.0001,-903.815 1539.0001,-903.8149\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#3a9de5\" stroke=\"#000000\" d=\"M1121.5,-782C1121.5,-782 1013.5,-782 1013.5,-782 1007.5,-782 1001.5,-776 1001.5,-770 1001.5,-770 1001.5,-711 1001.5,-711 1001.5,-705 1007.5,-699 1013.5,-699 1013.5,-699 1121.5,-699 1121.5,-699 1127.5,-699 1133.5,-705 1133.5,-711 1133.5,-711 1133.5,-770 1133.5,-770 1133.5,-776 1127.5,-782 1121.5,-782\"/>\n<text text-anchor=\"start\" x=\"1011.5\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ &#45;0.493</text>\n<text text-anchor=\"start\" x=\"1016.5\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.037</text>\n<text text-anchor=\"start\" x=\"1015.5\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3564</text>\n<text text-anchor=\"start\" x=\"1009.5\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 5603]</text>\n<text text-anchor=\"start\" x=\"1038.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1268.5,-830.0843C1230.4713,-813.1351 1182.5259,-791.7662 1143.0004,-774.15\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1144.2248,-770.8639 1133.6661,-769.9898 1141.3752,-777.2576 1144.2248,-770.8639\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<path fill=\"#48a4e7\" stroke=\"#000000\" d=\"M1404,-782C1404,-782 1265,-782 1265,-782 1259,-782 1253,-776 1253,-770 1253,-770 1253,-711 1253,-711 1253,-705 1259,-699 1265,-699 1265,-699 1404,-699 1404,-699 1410,-699 1416,-705 1416,-711 1416,-711 1416,-770 1416,-770 1416,-776 1410,-782 1404,-782\"/>\n<text text-anchor=\"start\" x=\"1261\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;0.142</text>\n<text text-anchor=\"start\" x=\"1283.5\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.367</text>\n<text text-anchor=\"start\" x=\"1286.5\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 221</text>\n<text text-anchor=\"start\" x=\"1280.5\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 330]</text>\n<text text-anchor=\"start\" x=\"1305.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>10&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1334.5,-817.8796C1334.5,-809.6838 1334.5,-800.9891 1334.5,-792.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1338.0001,-792.298 1334.5,-782.2981 1331.0001,-792.2981 1338.0001,-792.298\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#49a5e7\" stroke=\"#000000\" d=\"M647.5,-663C647.5,-663 547.5,-663 547.5,-663 541.5,-663 535.5,-657 535.5,-651 535.5,-651 535.5,-592 535.5,-592 535.5,-586 541.5,-580 547.5,-580 547.5,-580 647.5,-580 647.5,-580 653.5,-580 659.5,-586 659.5,-592 659.5,-592 659.5,-651 659.5,-651 659.5,-657 653.5,-663 647.5,-663\"/>\n<text text-anchor=\"start\" x=\"547.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ &#45;1.405</text>\n<text text-anchor=\"start\" x=\"546.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.376</text>\n<text text-anchor=\"start\" x=\"549.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 141</text>\n<text text-anchor=\"start\" x=\"543.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [16, 204]</text>\n<text text-anchor=\"start\" x=\"568.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1001.1573,-723.7026C913.5988,-701.5335 760.0182,-662.6482 669.6487,-639.7674\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"670.312,-636.325 659.7588,-637.2634 668.5938,-643.1109 670.312,-636.325\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1137,-663C1137,-663 998,-663 998,-663 992,-663 986,-657 986,-651 986,-651 986,-592 986,-592 986,-586 992,-580 998,-580 998,-580 1137,-580 1137,-580 1143,-580 1149,-586 1149,-592 1149,-592 1149,-651 1149,-651 1149,-657 1143,-663 1137,-663\"/>\n<text text-anchor=\"start\" x=\"994\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;0.773</text>\n<text text-anchor=\"start\" x=\"1016.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.012</text>\n<text text-anchor=\"start\" x=\"1015.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3423</text>\n<text text-anchor=\"start\" x=\"1013.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 5399]</text>\n<text text-anchor=\"start\" x=\"1038.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 11&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>11&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1067.5,-698.8796C1067.5,-690.6838 1067.5,-681.9891 1067.5,-673.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1071.0001,-673.298 1067.5,-663.2981 1064.0001,-673.2981 1071.0001,-673.298\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#b2d9f5\" stroke=\"#000000\" d=\"M443.5,-544C443.5,-544 341.5,-544 341.5,-544 335.5,-544 329.5,-538 329.5,-532 329.5,-532 329.5,-473 329.5,-473 329.5,-467 335.5,-461 341.5,-461 341.5,-461 443.5,-461 443.5,-461 449.5,-461 455.5,-467 455.5,-473 455.5,-473 455.5,-532 455.5,-532 455.5,-538 449.5,-544 443.5,-544\"/>\n<text text-anchor=\"start\" x=\"337.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.611</text>\n<text text-anchor=\"start\" x=\"341.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.957</text>\n<text text-anchor=\"start\" x=\"348.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"start\" x=\"342.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 23]</text>\n<text text-anchor=\"start\" x=\"363.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M535.4369,-585.4731C513.0749,-572.4922 487.6547,-557.7361 464.5149,-544.3038\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"466.1747,-541.2204 455.7691,-539.2269 462.6605,-547.2743 466.1747,-541.2204\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M648.5,-544C648.5,-544 546.5,-544 546.5,-544 540.5,-544 534.5,-538 534.5,-532 534.5,-532 534.5,-473 534.5,-473 534.5,-467 540.5,-461 546.5,-461 546.5,-461 648.5,-461 648.5,-461 654.5,-461 660.5,-467 660.5,-473 660.5,-473 660.5,-532 660.5,-532 660.5,-538 654.5,-544 648.5,-544\"/>\n<text text-anchor=\"start\" x=\"542.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.179</text>\n<text text-anchor=\"start\" x=\"546.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.087</text>\n<text text-anchor=\"start\" x=\"549.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 119</text>\n<text text-anchor=\"start\" x=\"547.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 181]</text>\n<text text-anchor=\"start\" x=\"568.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 12&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>12&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M597.5,-579.8796C597.5,-571.6838 597.5,-562.9891 597.5,-554.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"601.0001,-554.298 597.5,-544.2981 594.0001,-554.2981 601.0001,-554.298\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#53aae8\" stroke=\"#000000\" d=\"M308.5,-425C308.5,-425 214.5,-425 214.5,-425 208.5,-425 202.5,-419 202.5,-413 202.5,-413 202.5,-354 202.5,-354 202.5,-348 208.5,-342 214.5,-342 214.5,-342 308.5,-342 308.5,-342 314.5,-342 320.5,-348 320.5,-354 320.5,-354 320.5,-413 320.5,-413 320.5,-419 314.5,-425 308.5,-425\"/>\n<text text-anchor=\"start\" x=\"224\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 2.345</text>\n<text text-anchor=\"start\" x=\"210.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.516</text>\n<text text-anchor=\"start\" x=\"217.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n<text text-anchor=\"start\" x=\"216\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 23]</text>\n<text text-anchor=\"start\" x=\"232.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M346.6826,-460.8796C336.4706,-451.6031 325.555,-441.6874 315.0624,-432.1559\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"317.2684,-429.4313 307.513,-425.2981 312.5616,-434.6127 317.2684,-429.4313\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M434,-417.5C434,-417.5 351,-417.5 351,-417.5 345,-417.5 339,-411.5 339,-405.5 339,-405.5 339,-361.5 339,-361.5 339,-355.5 345,-349.5 351,-349.5 351,-349.5 434,-349.5 434,-349.5 440,-349.5 446,-355.5 446,-361.5 446,-361.5 446,-405.5 446,-405.5 446,-411.5 440,-417.5 434,-417.5\"/>\n<text text-anchor=\"start\" x=\"350\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"353\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"start\" x=\"347\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 0]</text>\n<text text-anchor=\"start\" x=\"363.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 13&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>13&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M392.5,-460.8796C392.5,-450.2134 392.5,-438.7021 392.5,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"396.0001,-427.8149 392.5,-417.8149 389.0001,-427.815 396.0001,-427.8149\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#42a1e6\" stroke=\"#000000\" d=\"M257,-306C257,-306 114,-306 114,-306 108,-306 102,-300 102,-294 102,-294 102,-235 102,-235 102,-229 108,-223 114,-223 114,-223 257,-223 257,-223 263,-223 269,-229 269,-235 269,-235 269,-294 269,-294 269,-300 263,-306 257,-306\"/>\n<text text-anchor=\"start\" x=\"110\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">days.with.cr.line ≤ &#45;1.35</text>\n<text text-anchor=\"start\" x=\"138.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.25</text>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16</text>\n<text text-anchor=\"start\" x=\"140\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 23]</text>\n<text text-anchor=\"start\" x=\"156.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.9189,-341.8796C229.3395,-333.1434 223.3981,-323.8404 217.6405,-314.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"220.5269,-312.8421 212.1946,-306.2981 214.6274,-316.6098 220.5269,-312.8421\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M376,-298.5C376,-298.5 299,-298.5 299,-298.5 293,-298.5 287,-292.5 287,-286.5 287,-286.5 287,-242.5 287,-242.5 287,-236.5 293,-230.5 299,-230.5 299,-230.5 376,-230.5 376,-230.5 382,-230.5 388,-236.5 388,-242.5 388,-242.5 388,-286.5 388,-286.5 388,-292.5 382,-298.5 376,-298.5\"/>\n<text text-anchor=\"start\" x=\"295\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"296\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"308.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 14&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>14&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M288.0811,-341.8796C295.174,-330.7735 302.8521,-318.7513 309.9937,-307.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.1518,-309.1267 315.5846,-298.8149 307.2523,-305.3589 313.1518,-309.1267\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#9ccef2\" stroke=\"#000000\" d=\"M179,-187C179,-187 40,-187 40,-187 34,-187 28,-181 28,-175 28,-175 28,-116 28,-116 28,-110 34,-104 40,-104 40,-104 179,-104 179,-104 185,-104 191,-110 191,-116 191,-116 191,-175 191,-175 191,-181 185,-187 179,-187\"/>\n<text text-anchor=\"start\" x=\"36\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;2.181</text>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.918</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"68\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 2]</text>\n<text text-anchor=\"start\" x=\"80.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.9189,-222.8796C153.3395,-214.1434 147.3981,-204.8404 141.6405,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.5269,-193.8421 136.1946,-187.2981 138.6274,-197.6098 144.5269,-193.8421\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M304,-179.5C304,-179.5 221,-179.5 221,-179.5 215,-179.5 209,-173.5 209,-167.5 209,-167.5 209,-123.5 209,-123.5 209,-117.5 215,-111.5 221,-111.5 221,-111.5 304,-111.5 304,-111.5 310,-111.5 316,-117.5 316,-123.5 316,-123.5 316,-167.5 316,-167.5 316,-173.5 310,-179.5 304,-179.5\"/>\n<text text-anchor=\"start\" x=\"220\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"218.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"217\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 21]</text>\n<text text-anchor=\"start\" x=\"233.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 15&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M212.4309,-222.8796C219.6883,-211.6636 227.5503,-199.5131 234.8465,-188.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.8022,-190.112 240.2962,-179.8149 231.9252,-186.3093 237.8022,-190.112\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M89,-68C89,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 89,0 89,0 95,0 101,-6 101,-12 101,-12 101,-56 101,-56 101,-62 95,-68 89,-68\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"11\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"9\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n<text text-anchor=\"start\" x=\"21.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M87.5306,-103.9815C82.9105,-95.2504 78.0264,-86.0202 73.374,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.4013,-75.4655 68.6306,-68.2637 70.2141,-78.7395 76.4013,-75.4655\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M208,-68C208,-68 131,-68 131,-68 125,-68 119,-62 119,-56 119,-56 119,-12 119,-12 119,-6 125,0 131,0 131,0 208,0 208,0 214,0 220,-6 220,-12 220,-12 220,-56 220,-56 220,-62 214,-68 208,-68\"/>\n<text text-anchor=\"start\" x=\"127\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"130\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"128\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n<text text-anchor=\"start\" x=\"140.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M131.8418,-103.9815C136.5402,-95.2504 141.5071,-86.0202 146.2383,-77.2281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.4056,-78.7282 151.0621,-68.2637 143.2414,-75.4111 149.4056,-78.7282\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M568.5,-417.5C568.5,-417.5 476.5,-417.5 476.5,-417.5 470.5,-417.5 464.5,-411.5 464.5,-405.5 464.5,-405.5 464.5,-361.5 464.5,-361.5 464.5,-355.5 470.5,-349.5 476.5,-349.5 476.5,-349.5 568.5,-349.5 568.5,-349.5 574.5,-349.5 580.5,-355.5 580.5,-361.5 580.5,-361.5 580.5,-405.5 580.5,-405.5 580.5,-411.5 574.5,-417.5 568.5,-417.5\"/>\n<text text-anchor=\"start\" x=\"480\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"474.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 105</text>\n<text text-anchor=\"start\" x=\"472.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 167]</text>\n<text text-anchor=\"start\" x=\"493.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M571.2686,-460.8796C564.269,-449.7735 556.692,-437.7513 549.6444,-426.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"552.42,-424.4087 544.1271,-417.8149 546.498,-428.1411 552.42,-424.4087\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#55abe9\" stroke=\"#000000\" d=\"M704.5,-425C704.5,-425 610.5,-425 610.5,-425 604.5,-425 598.5,-419 598.5,-413 598.5,-413 598.5,-354 598.5,-354 598.5,-348 604.5,-342 610.5,-342 610.5,-342 704.5,-342 704.5,-342 710.5,-342 716.5,-348 716.5,-354 716.5,-354 716.5,-413 716.5,-413 716.5,-419 710.5,-425 704.5,-425\"/>\n<text text-anchor=\"start\" x=\"607.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ &#45;0.542</text>\n<text text-anchor=\"start\" x=\"606.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.544</text>\n<text text-anchor=\"start\" x=\"613.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"612\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 14]</text>\n<text text-anchor=\"start\" x=\"628.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 22&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>22&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M618.4851,-460.8796C622.799,-452.3236 627.3872,-443.2238 631.8446,-434.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"635.0484,-435.8031 636.4253,-425.2981 628.7979,-432.6515 635.0484,-435.8031\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M574,-298.5C574,-298.5 497,-298.5 497,-298.5 491,-298.5 485,-292.5 485,-286.5 485,-286.5 485,-242.5 485,-242.5 485,-236.5 491,-230.5 497,-230.5 497,-230.5 574,-230.5 574,-230.5 580,-230.5 586,-236.5 586,-242.5 586,-242.5 586,-286.5 586,-286.5 586,-292.5 580,-298.5 574,-298.5\"/>\n<text text-anchor=\"start\" x=\"493\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"496\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"494\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"506.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M614.8303,-341.8796C602.8806,-330.2237 589.8963,-317.5587 577.9589,-305.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"580.2825,-303.292 570.68,-298.8149 575.3947,-308.303 580.2825,-303.292\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M699,-298.5C699,-298.5 616,-298.5 616,-298.5 610,-298.5 604,-292.5 604,-286.5 604,-286.5 604,-242.5 604,-242.5 604,-236.5 610,-230.5 616,-230.5 616,-230.5 699,-230.5 699,-230.5 705,-230.5 711,-236.5 711,-242.5 711,-242.5 711,-286.5 711,-286.5 711,-292.5 705,-298.5 699,-298.5\"/>\n<text text-anchor=\"start\" x=\"615\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"613.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12</text>\n<text text-anchor=\"start\" x=\"612\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 14]</text>\n<text text-anchor=\"start\" x=\"628.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 24&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>24&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M657.5,-341.8796C657.5,-331.2134 657.5,-319.7021 657.5,-308.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"661.0001,-308.8149 657.5,-298.8149 654.0001,-308.815 661.0001,-308.8149\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#3a9ee5\" stroke=\"#000000\" d=\"M987.5,-544C987.5,-544 887.5,-544 887.5,-544 881.5,-544 875.5,-538 875.5,-532 875.5,-532 875.5,-473 875.5,-473 875.5,-467 881.5,-461 887.5,-461 887.5,-461 987.5,-461 987.5,-461 993.5,-461 999.5,-467 999.5,-473 999.5,-473 999.5,-532 999.5,-532 999.5,-538 993.5,-544 987.5,-544\"/>\n<text text-anchor=\"start\" x=\"884\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.043</text>\n<text text-anchor=\"start\" x=\"886.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.049</text>\n<text text-anchor=\"start\" x=\"889.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 700</text>\n<text text-anchor=\"start\" x=\"883.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 1095]</text>\n<text text-anchor=\"start\" x=\"908.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 27&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>27&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1022.0323,-579.8796C1011.8983,-570.6031 1001.066,-560.6874 990.6535,-551.1559\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"992.9013,-548.4685 983.1618,-544.2981 988.1748,-553.6319 992.9013,-548.4685\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1129.5,-536.5C1129.5,-536.5 1029.5,-536.5 1029.5,-536.5 1023.5,-536.5 1017.5,-530.5 1017.5,-524.5 1017.5,-524.5 1017.5,-480.5 1017.5,-480.5 1017.5,-474.5 1023.5,-468.5 1029.5,-468.5 1029.5,-468.5 1129.5,-468.5 1129.5,-468.5 1135.5,-468.5 1141.5,-474.5 1141.5,-480.5 1141.5,-480.5 1141.5,-524.5 1141.5,-524.5 1141.5,-530.5 1135.5,-536.5 1129.5,-536.5\"/>\n<text text-anchor=\"start\" x=\"1037\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1027.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2723</text>\n<text text-anchor=\"start\" x=\"1025.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4304]</text>\n<text text-anchor=\"start\" x=\"1050.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 27&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>27&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1071.697,-579.8796C1072.7726,-569.2134 1073.9334,-557.7021 1075.0225,-546.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1078.5186,-547.1157 1076.0397,-536.8149 1071.5539,-546.4133 1078.5186,-547.1157\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M978,-425C978,-425 839,-425 839,-425 833,-425 827,-419 827,-413 827,-413 827,-354 827,-354 827,-348 833,-342 839,-342 839,-342 978,-342 978,-342 984,-342 990,-348 990,-354 990,-354 990,-413 990,-413 990,-419 984,-425 978,-425\"/>\n<text text-anchor=\"start\" x=\"835\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;2.969</text>\n<text text-anchor=\"start\" x=\"861.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.02</text>\n<text text-anchor=\"start\" x=\"860.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 668</text>\n<text text-anchor=\"start\" x=\"854.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 1046]</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M927.3572,-460.8796C925.338,-452.5938 923.1945,-443.798 921.1044,-435.2216\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"924.4543,-434.185 918.6861,-425.2981 917.6534,-435.8425 924.4543,-434.185\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<path fill=\"#49a5e7\" stroke=\"#000000\" d=\"M1159,-425C1159,-425 1020,-425 1020,-425 1014,-425 1008,-419 1008,-413 1008,-413 1008,-354 1008,-354 1008,-348 1014,-342 1020,-342 1020,-342 1159,-342 1159,-342 1165,-342 1171,-348 1171,-354 1171,-354 1171,-413 1171,-413 1171,-419 1165,-425 1159,-425\"/>\n<text text-anchor=\"start\" x=\"1016\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;1.539</text>\n<text text-anchor=\"start\" x=\"1038.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.386</text>\n<text text-anchor=\"start\" x=\"1045.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32</text>\n<text text-anchor=\"start\" x=\"1044\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 49]</text>\n<text text-anchor=\"start\" x=\"1060.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 28&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>28&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M990.6622,-460.8796C1002.8115,-451.368 1015.8192,-441.1843 1028.276,-431.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1030.6514,-434.0173 1036.3678,-425.0969 1026.3362,-428.5055 1030.6514,-434.0173\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#4ba6e7\" stroke=\"#000000\" d=\"M845.5,-306C845.5,-306 741.5,-306 741.5,-306 735.5,-306 729.5,-300 729.5,-294 729.5,-294 729.5,-235 729.5,-235 729.5,-229 735.5,-223 741.5,-223 741.5,-223 845.5,-223 845.5,-223 851.5,-223 857.5,-229 857.5,-235 857.5,-235 857.5,-294 857.5,-294 857.5,-300 851.5,-306 845.5,-306\"/>\n<text text-anchor=\"start\" x=\"737.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ &#45;0.266</text>\n<text text-anchor=\"start\" x=\"742.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.414</text>\n<text text-anchor=\"start\" x=\"754\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9</text>\n<text text-anchor=\"start\" x=\"748\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 11]</text>\n<text text-anchor=\"start\" x=\"764.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 29&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>29&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M868.2786,-341.8796C859.488,-332.7832 850.1034,-323.0722 841.0574,-313.7116\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"843.3591,-311.0568 833.8931,-306.2981 838.3255,-315.9212 843.3591,-311.0568\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M987.5,-306C987.5,-306 887.5,-306 887.5,-306 881.5,-306 875.5,-300 875.5,-294 875.5,-294 875.5,-235 875.5,-235 875.5,-229 881.5,-223 887.5,-223 887.5,-223 987.5,-223 987.5,-223 993.5,-223 999.5,-229 999.5,-235 999.5,-235 999.5,-294 999.5,-294 999.5,-300 993.5,-306 987.5,-306\"/>\n<text text-anchor=\"start\" x=\"884.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ 1.668</text>\n<text text-anchor=\"start\" x=\"886.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.011</text>\n<text text-anchor=\"start\" x=\"889.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 659</text>\n<text text-anchor=\"start\" x=\"883.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1035]</text>\n<text text-anchor=\"start\" x=\"908.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 29&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>29&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M918.6428,-341.8796C920.662,-333.5938 922.8055,-324.798 924.8956,-316.2216\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"928.3466,-316.8425 927.3139,-306.2981 921.5457,-315.185 928.3466,-316.8425\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M713,-179.5C713,-179.5 630,-179.5 630,-179.5 624,-179.5 618,-173.5 618,-167.5 618,-167.5 618,-123.5 618,-123.5 618,-117.5 624,-111.5 630,-111.5 630,-111.5 713,-111.5 713,-111.5 719,-111.5 725,-117.5 725,-123.5 725,-123.5 725,-167.5 725,-167.5 725,-173.5 719,-179.5 713,-179.5\"/>\n<text text-anchor=\"start\" x=\"629\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"632\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"626\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 11]</text>\n<text text-anchor=\"start\" x=\"642.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 30&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>30&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M750.8303,-222.8796C738.8806,-211.2237 725.8963,-198.5587 713.9589,-186.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"716.2825,-184.292 706.68,-179.8149 711.3947,-189.303 716.2825,-184.292\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M832,-179.5C832,-179.5 755,-179.5 755,-179.5 749,-179.5 743,-173.5 743,-167.5 743,-167.5 743,-123.5 743,-123.5 743,-117.5 749,-111.5 755,-111.5 755,-111.5 832,-111.5 832,-111.5 838,-111.5 844,-117.5 844,-123.5 844,-123.5 844,-167.5 844,-167.5 844,-173.5 838,-179.5 832,-179.5\"/>\n<text text-anchor=\"start\" x=\"751\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"754\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"752\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n<text text-anchor=\"start\" x=\"764.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 30&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>30&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M793.5,-222.8796C793.5,-212.2134 793.5,-200.7021 793.5,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"797.0001,-189.8149 793.5,-179.8149 790.0001,-189.815 797.0001,-189.8149\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M974.5,-179.5C974.5,-179.5 874.5,-179.5 874.5,-179.5 868.5,-179.5 862.5,-173.5 862.5,-167.5 862.5,-167.5 862.5,-123.5 862.5,-123.5 862.5,-117.5 868.5,-111.5 874.5,-111.5 874.5,-111.5 974.5,-111.5 974.5,-111.5 980.5,-111.5 986.5,-117.5 986.5,-123.5 986.5,-123.5 986.5,-167.5 986.5,-167.5 986.5,-173.5 980.5,-179.5 974.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"882\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"876.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 644</text>\n<text text-anchor=\"start\" x=\"870.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1016]</text>\n<text text-anchor=\"start\" x=\"895.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M932.9532,-222.8796C931.788,-212.2134 930.5305,-200.7021 929.3506,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"932.8141,-189.3757 928.2487,-179.8149 925.8555,-190.1359 932.8141,-189.3757\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<path fill=\"#43a2e6\" stroke=\"#000000\" d=\"M1156,-187C1156,-187 1017,-187 1017,-187 1011,-187 1005,-181 1005,-175 1005,-175 1005,-116 1005,-116 1005,-110 1011,-104 1017,-104 1017,-104 1156,-104 1156,-104 1162,-104 1168,-110 1168,-116 1168,-116 1168,-175 1168,-175 1168,-181 1162,-187 1156,-187\"/>\n<text text-anchor=\"start\" x=\"1013\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ &#45;0.883</text>\n<text text-anchor=\"start\" x=\"1035.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.286</text>\n<text text-anchor=\"start\" x=\"1042.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1041\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 19]</text>\n<text text-anchor=\"start\" x=\"1057.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 33&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>33&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M989.613,-222.8796C1001.5225,-213.368 1014.2734,-203.1843 1026.4844,-193.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1028.7868,-196.0724 1034.4165,-187.0969 1024.4184,-190.6027 1028.7868,-196.0724\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1084,-68C1084,-68 1001,-68 1001,-68 995,-68 989,-62 989,-56 989,-56 989,-12 989,-12 989,-6 995,0 1001,0 1001,0 1084,0 1084,0 1090,0 1096,-6 1096,-12 1096,-12 1096,-56 1096,-56 1096,-62 1090,-68 1084,-68\"/>\n<text text-anchor=\"start\" x=\"1000\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"998.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"997\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 19]</text>\n<text text-anchor=\"start\" x=\"1013.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 35&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>35&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1070.116,-103.9815C1066.7431,-95.4342 1063.1814,-86.4086 1059.778,-77.7839\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1062.9475,-76.2808 1056.0211,-68.2637 1056.4362,-78.8504 1062.9475,-76.2808\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1203,-68C1203,-68 1126,-68 1126,-68 1120,-68 1114,-62 1114,-56 1114,-56 1114,-12 1114,-12 1114,-6 1120,0 1126,0 1126,0 1203,0 1203,0 1209,0 1215,-6 1215,-12 1215,-12 1215,-56 1215,-56 1215,-62 1209,-68 1203,-68\"/>\n<text text-anchor=\"start\" x=\"1122\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1125\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1123\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n<text text-anchor=\"start\" x=\"1135.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 35&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>35&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1115.5443,-103.9815C1121.7808,-95.0666 1128.3813,-85.6313 1134.6478,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1137.6665,-78.464 1140.5308,-68.2637 1131.9307,-74.4515 1137.6665,-78.464\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1128,-298.5C1128,-298.5 1051,-298.5 1051,-298.5 1045,-298.5 1039,-292.5 1039,-286.5 1039,-286.5 1039,-242.5 1039,-242.5 1039,-236.5 1045,-230.5 1051,-230.5 1051,-230.5 1128,-230.5 1128,-230.5 1134,-230.5 1140,-236.5 1140,-242.5 1140,-242.5 1140,-286.5 1140,-286.5 1140,-292.5 1134,-298.5 1128,-298.5\"/>\n<text text-anchor=\"start\" x=\"1047\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1050\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1048\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"1060.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 38&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>38&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1089.5,-341.8796C1089.5,-331.2134 1089.5,-319.7021 1089.5,-308.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1093.0001,-308.8149 1089.5,-298.8149 1086.0001,-308.815 1093.0001,-308.8149\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<path fill=\"#41a1e6\" stroke=\"#000000\" d=\"M1289,-306C1289,-306 1190,-306 1190,-306 1184,-306 1178,-300 1178,-294 1178,-294 1178,-235 1178,-235 1178,-229 1184,-223 1190,-223 1190,-223 1289,-223 1289,-223 1295,-223 1301,-229 1301,-235 1301,-235 1301,-294 1301,-294 1301,-300 1295,-306 1289,-306\"/>\n<text text-anchor=\"start\" x=\"1186\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 0.284</text>\n<text text-anchor=\"start\" x=\"1188.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.239</text>\n<text text-anchor=\"start\" x=\"1195.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30</text>\n<text text-anchor=\"start\" x=\"1194\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 49]</text>\n<text text-anchor=\"start\" x=\"1210.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 38&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>38&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1141.9627,-341.8796C1153.9521,-332.368 1166.7887,-322.1843 1179.0816,-312.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.4081,-315.054 1187.0669,-306.0969 1177.0575,-309.5701 1181.4081,-315.054\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1281,-179.5C1281,-179.5 1198,-179.5 1198,-179.5 1192,-179.5 1186,-173.5 1186,-167.5 1186,-167.5 1186,-123.5 1186,-123.5 1186,-117.5 1192,-111.5 1198,-111.5 1198,-111.5 1281,-111.5 1281,-111.5 1287,-111.5 1293,-117.5 1293,-123.5 1293,-123.5 1293,-167.5 1293,-167.5 1293,-173.5 1287,-179.5 1281,-179.5\"/>\n<text text-anchor=\"start\" x=\"1197\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1195.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26</text>\n<text text-anchor=\"start\" x=\"1194\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 45]</text>\n<text text-anchor=\"start\" x=\"1210.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 40&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>40&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1239.5,-222.8796C1239.5,-212.2134 1239.5,-200.7021 1239.5,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1243.0001,-189.8149 1239.5,-179.8149 1236.0001,-189.815 1243.0001,-189.8149\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<path fill=\"#9ccef2\" stroke=\"#000000\" d=\"M1461.5,-187C1461.5,-187 1323.5,-187 1323.5,-187 1317.5,-187 1311.5,-181 1311.5,-175 1311.5,-175 1311.5,-116 1311.5,-116 1311.5,-110 1317.5,-104 1323.5,-104 1323.5,-104 1461.5,-104 1461.5,-104 1467.5,-104 1473.5,-110 1473.5,-116 1473.5,-116 1473.5,-175 1473.5,-175 1473.5,-181 1467.5,-187 1461.5,-187\"/>\n<text text-anchor=\"start\" x=\"1319.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">inq.last.6mths ≤ &#45;0.039</text>\n<text text-anchor=\"start\" x=\"1341.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.918</text>\n<text text-anchor=\"start\" x=\"1353\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1351\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 4]</text>\n<text text-anchor=\"start\" x=\"1363.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 40&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>40&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1293.012,-222.8796C1305.2412,-213.368 1318.3344,-203.1843 1330.8732,-193.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1333.2735,-195.9991 1339.0182,-187.0969 1328.9759,-190.4736 1333.2735,-195.9991\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1356,-68C1356,-68 1279,-68 1279,-68 1273,-68 1267,-62 1267,-56 1267,-56 1267,-12 1267,-12 1267,-6 1273,0 1279,0 1279,0 1356,0 1356,0 1362,0 1368,-6 1368,-12 1368,-12 1368,-56 1368,-56 1368,-62 1362,-68 1356,-68\"/>\n<text text-anchor=\"start\" x=\"1275\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1278\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1276\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n<text text-anchor=\"start\" x=\"1288.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 42&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>42&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1364.5728,-103.9815C1358.5762,-95.0666 1352.2296,-85.6313 1346.2041,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1349.0328,-74.6078 1340.5473,-68.2637 1343.2245,-78.5147 1349.0328,-74.6078\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1475,-68C1475,-68 1398,-68 1398,-68 1392,-68 1386,-62 1386,-56 1386,-56 1386,-12 1386,-12 1386,-6 1392,0 1398,0 1398,0 1475,0 1475,0 1481,0 1487,-6 1487,-12 1487,-12 1487,-56 1487,-56 1487,-62 1481,-68 1475,-68\"/>\n<text text-anchor=\"start\" x=\"1394\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1397\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1395\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4]</text>\n<text text-anchor=\"start\" x=\"1407.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 42&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>42&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1408.884,-103.9815C1412.2569,-95.4342 1415.8186,-86.4086 1419.222,-77.7839\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1422.5638,-78.8504 1422.9789,-68.2637 1416.0525,-76.2808 1422.5638,-78.8504\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<path fill=\"#e99254\" stroke=\"#000000\" d=\"M1401.5,-663C1401.5,-663 1195.5,-663 1195.5,-663 1189.5,-663 1183.5,-657 1183.5,-651 1183.5,-651 1183.5,-592 1183.5,-592 1183.5,-586 1189.5,-580 1195.5,-580 1195.5,-580 1401.5,-580 1401.5,-580 1407.5,-580 1413.5,-586 1413.5,-592 1413.5,-592 1413.5,-651 1413.5,-651 1413.5,-657 1407.5,-663 1401.5,-663\"/>\n<text text-anchor=\"start\" x=\"1191.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">purpose_small_business ≤ 1.782</text>\n<text text-anchor=\"start\" x=\"1247.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.529</text>\n<text text-anchor=\"start\" x=\"1254.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16</text>\n<text text-anchor=\"start\" x=\"1253\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 3]</text>\n<text text-anchor=\"start\" x=\"1269.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1321.9089,-698.8796C1319.3751,-690.5037 1316.6835,-681.6067 1314.0623,-672.942\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1317.3905,-671.8562 1311.1448,-663.2981 1310.6904,-673.8832 1317.3905,-671.8562\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M1577.5,-663C1577.5,-663 1443.5,-663 1443.5,-663 1437.5,-663 1431.5,-657 1431.5,-651 1431.5,-651 1431.5,-592 1431.5,-592 1431.5,-586 1437.5,-580 1443.5,-580 1443.5,-580 1577.5,-580 1577.5,-580 1583.5,-580 1589.5,-586 1589.5,-592 1589.5,-592 1589.5,-651 1589.5,-651 1589.5,-657 1583.5,-663 1577.5,-663\"/>\n<text text-anchor=\"start\" x=\"1439.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 0.277</text>\n<text text-anchor=\"start\" x=\"1459.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.075</text>\n<text text-anchor=\"start\" x=\"1462.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 205</text>\n<text text-anchor=\"start\" x=\"1460.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 327]</text>\n<text text-anchor=\"start\" x=\"1481.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 46&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>46&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1396.0563,-698.8796C1410.3918,-689.1868 1425.7595,-678.7961 1440.4325,-668.8752\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1442.6548,-671.5976 1448.9785,-663.0969 1438.7339,-665.7987 1442.6548,-671.5976\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<path fill=\"#e68742\" stroke=\"#000000\" d=\"M1300,-544C1300,-544 1185,-544 1185,-544 1179,-544 1173,-538 1173,-532 1173,-532 1173,-473 1173,-473 1173,-467 1179,-461 1185,-461 1185,-461 1300,-461 1300,-461 1306,-461 1312,-467 1312,-473 1312,-473 1312,-532 1312,-532 1312,-538 1306,-544 1300,-544\"/>\n<text text-anchor=\"start\" x=\"1181\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">delinq.2yrs ≤ 0.604</text>\n<text text-anchor=\"start\" x=\"1191.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.258</text>\n<text text-anchor=\"start\" x=\"1198.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n<text text-anchor=\"start\" x=\"1197\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 1]</text>\n<text text-anchor=\"start\" x=\"1213.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 47&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>47&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1278.9139,-579.8796C1274.8876,-571.3236 1270.6053,-562.2238 1266.4451,-553.3833\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1269.5946,-551.856 1262.1697,-544.2981 1263.2608,-554.8366 1269.5946,-551.856\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1419,-536.5C1419,-536.5 1342,-536.5 1342,-536.5 1336,-536.5 1330,-530.5 1330,-524.5 1330,-524.5 1330,-480.5 1330,-480.5 1330,-474.5 1336,-468.5 1342,-468.5 1342,-468.5 1419,-468.5 1419,-468.5 1425,-468.5 1431,-474.5 1431,-480.5 1431,-480.5 1431,-524.5 1431,-524.5 1431,-530.5 1425,-536.5 1419,-536.5\"/>\n<text text-anchor=\"start\" x=\"1338\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1341\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1339\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n<text text-anchor=\"start\" x=\"1351.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 47&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>47&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1327.1796,-579.8796C1334.9083,-568.6636 1343.2809,-556.5131 1351.0508,-545.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1354.0623,-547.0353 1356.8544,-536.8149 1348.2982,-543.0634 1354.0623,-547.0353\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1284,-417.5C1284,-417.5 1201,-417.5 1201,-417.5 1195,-417.5 1189,-411.5 1189,-405.5 1189,-405.5 1189,-361.5 1189,-361.5 1189,-355.5 1195,-349.5 1201,-349.5 1201,-349.5 1284,-349.5 1284,-349.5 1290,-349.5 1296,-355.5 1296,-361.5 1296,-361.5 1296,-405.5 1296,-405.5 1296,-411.5 1290,-417.5 1284,-417.5\"/>\n<text text-anchor=\"start\" x=\"1200\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1198.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13</text>\n<text text-anchor=\"start\" x=\"1197\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [22, 0]</text>\n<text text-anchor=\"start\" x=\"1213.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 48&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>48&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1242.5,-460.8796C1242.5,-450.2134 1242.5,-438.7021 1242.5,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1246.0001,-427.8149 1242.5,-417.8149 1239.0001,-427.815 1246.0001,-427.8149\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1403,-417.5C1403,-417.5 1326,-417.5 1326,-417.5 1320,-417.5 1314,-411.5 1314,-405.5 1314,-405.5 1314,-361.5 1314,-361.5 1314,-355.5 1320,-349.5 1326,-349.5 1326,-349.5 1403,-349.5 1403,-349.5 1409,-349.5 1415,-355.5 1415,-361.5 1415,-361.5 1415,-405.5 1415,-405.5 1415,-411.5 1409,-417.5 1403,-417.5\"/>\n<text text-anchor=\"start\" x=\"1322\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1325\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1323\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"1335.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 48&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>48&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1285.1697,-460.8796C1297.1194,-449.2237 1310.1037,-436.5587 1322.0411,-424.9148\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1324.6053,-427.303 1329.32,-417.8149 1319.7175,-422.292 1324.6053,-427.303\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<path fill=\"#49a5e7\" stroke=\"#000000\" d=\"M1560,-544C1560,-544 1461,-544 1461,-544 1455,-544 1449,-538 1449,-532 1449,-532 1449,-473 1449,-473 1449,-467 1455,-461 1461,-461 1461,-461 1560,-461 1560,-461 1566,-461 1572,-467 1572,-473 1572,-473 1572,-532 1572,-532 1572,-538 1566,-544 1560,-544\"/>\n<text text-anchor=\"start\" x=\"1457\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 1.304</text>\n<text text-anchor=\"start\" x=\"1459.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.391</text>\n<text text-anchor=\"start\" x=\"1466.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 28</text>\n<text text-anchor=\"start\" x=\"1465\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 36]</text>\n<text text-anchor=\"start\" x=\"1481.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 52&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>52&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1510.5,-579.8796C1510.5,-571.6838 1510.5,-562.9891 1510.5,-554.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1514.0001,-554.298 1510.5,-544.2981 1507.0001,-554.2981 1514.0001,-554.298\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1694.5,-536.5C1694.5,-536.5 1602.5,-536.5 1602.5,-536.5 1596.5,-536.5 1590.5,-530.5 1590.5,-524.5 1590.5,-524.5 1590.5,-480.5 1590.5,-480.5 1590.5,-474.5 1596.5,-468.5 1602.5,-468.5 1602.5,-468.5 1694.5,-468.5 1694.5,-468.5 1700.5,-468.5 1706.5,-474.5 1706.5,-480.5 1706.5,-480.5 1706.5,-524.5 1706.5,-524.5 1706.5,-530.5 1700.5,-536.5 1694.5,-536.5\"/>\n<text text-anchor=\"start\" x=\"1606\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1600.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 177</text>\n<text text-anchor=\"start\" x=\"1598.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 291]</text>\n<text text-anchor=\"start\" x=\"1619.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 52&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>52&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1558.7657,-579.8796C1572.4101,-568.1138 1587.2469,-555.3197 1600.8546,-543.5855\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1603.4187,-545.9961 1608.7062,-536.8149 1598.8473,-540.6948 1603.4187,-545.9961\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1544,-417.5C1544,-417.5 1461,-417.5 1461,-417.5 1455,-417.5 1449,-411.5 1449,-405.5 1449,-405.5 1449,-361.5 1449,-361.5 1449,-355.5 1455,-349.5 1461,-349.5 1461,-349.5 1544,-349.5 1544,-349.5 1550,-349.5 1556,-355.5 1556,-361.5 1556,-361.5 1556,-405.5 1556,-405.5 1556,-411.5 1550,-417.5 1544,-417.5\"/>\n<text text-anchor=\"start\" x=\"1460\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1458.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 23</text>\n<text text-anchor=\"start\" x=\"1457\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 33]</text>\n<text text-anchor=\"start\" x=\"1473.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 53&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>53&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1507.702,-460.8796C1506.9849,-450.2134 1506.2111,-438.7021 1505.485,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1508.9699,-427.5576 1504.8069,-417.8149 1501.9856,-428.0272 1508.9699,-427.5576\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M1684.5,-425C1684.5,-425 1586.5,-425 1586.5,-425 1580.5,-425 1574.5,-419 1574.5,-413 1574.5,-413 1574.5,-354 1574.5,-354 1574.5,-348 1580.5,-342 1586.5,-342 1586.5,-342 1684.5,-342 1684.5,-342 1690.5,-342 1696.5,-348 1696.5,-354 1696.5,-354 1696.5,-413 1696.5,-413 1696.5,-419 1690.5,-425 1684.5,-425\"/>\n<text text-anchor=\"start\" x=\"1582.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ 0.504</text>\n<text text-anchor=\"start\" x=\"1593\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"1596\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1594\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 3]</text>\n<text text-anchor=\"start\" x=\"1606.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 53&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>53&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1554.2189,-460.8796C1563.8686,-451.6931 1574.1766,-441.8798 1584.0991,-432.4336\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1586.765,-434.7282 1591.5945,-425.2981 1581.9384,-429.6582 1586.765,-434.7282\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1565,-298.5C1565,-298.5 1488,-298.5 1488,-298.5 1482,-298.5 1476,-292.5 1476,-286.5 1476,-286.5 1476,-242.5 1476,-242.5 1476,-236.5 1482,-230.5 1488,-230.5 1488,-230.5 1565,-230.5 1565,-230.5 1571,-230.5 1577,-236.5 1577,-242.5 1577,-242.5 1577,-286.5 1577,-286.5 1577,-292.5 1571,-298.5 1565,-298.5\"/>\n<text text-anchor=\"start\" x=\"1484\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1487\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1485\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n<text text-anchor=\"start\" x=\"1497.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 55&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>55&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1597.3771,-341.8796C1586.8014,-330.3337 1575.3188,-317.7976 1564.7367,-306.2446\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1567.2667,-303.825 1557.9313,-298.8149 1562.1049,-308.5531 1567.2667,-303.825\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1684,-298.5C1684,-298.5 1607,-298.5 1607,-298.5 1601,-298.5 1595,-292.5 1595,-286.5 1595,-286.5 1595,-242.5 1595,-242.5 1595,-236.5 1601,-230.5 1607,-230.5 1607,-230.5 1684,-230.5 1684,-230.5 1690,-230.5 1696,-236.5 1696,-242.5 1696,-242.5 1696,-286.5 1696,-286.5 1696,-292.5 1690,-298.5 1684,-298.5\"/>\n<text text-anchor=\"start\" x=\"1603\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1606\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1604\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n<text text-anchor=\"start\" x=\"1616.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 55&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>55&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1638.9975,-341.8796C1639.8938,-331.2134 1640.8612,-319.7021 1641.7688,-308.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1645.2666,-309.0729 1642.6164,-298.8149 1638.2912,-308.4867 1645.2666,-309.0729\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<path fill=\"#94caf1\" stroke=\"#000000\" d=\"M1771.5,-901C1771.5,-901 1637.5,-901 1637.5,-901 1631.5,-901 1625.5,-895 1625.5,-889 1625.5,-889 1625.5,-830 1625.5,-830 1625.5,-824 1631.5,-818 1637.5,-818 1637.5,-818 1771.5,-818 1771.5,-818 1777.5,-818 1783.5,-824 1783.5,-830 1783.5,-830 1783.5,-889 1783.5,-889 1783.5,-895 1777.5,-901 1771.5,-901\"/>\n<text text-anchor=\"start\" x=\"1633.5\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 0.644</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.899</text>\n<text text-anchor=\"start\" x=\"1660.5\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 92</text>\n<text text-anchor=\"start\" x=\"1654.5\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [45, 98]</text>\n<text text-anchor=\"start\" x=\"1675.5\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 60&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>60&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1704.5,-936.8796C1704.5,-928.6838 1704.5,-919.9891 1704.5,-911.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1708.0001,-911.298 1704.5,-901.2981 1701.0001,-911.2981 1708.0001,-911.298\"/>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1896,-893.5C1896,-893.5 1813,-893.5 1813,-893.5 1807,-893.5 1801,-887.5 1801,-881.5 1801,-881.5 1801,-837.5 1801,-837.5 1801,-831.5 1807,-825.5 1813,-825.5 1813,-825.5 1896,-825.5 1896,-825.5 1902,-825.5 1908,-831.5 1908,-837.5 1908,-837.5 1908,-881.5 1908,-881.5 1908,-887.5 1902,-893.5 1896,-893.5\"/>\n<text text-anchor=\"start\" x=\"1812\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1810.5\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 40</text>\n<text text-anchor=\"start\" x=\"1809\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [63, 0]</text>\n<text text-anchor=\"start\" x=\"1825.5\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 60&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>60&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1756.9627,-936.8796C1771.9322,-925.0038 1788.2222,-912.0804 1803.1259,-900.2568\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1805.587,-902.772 1811.2459,-893.8149 1801.2365,-897.2881 1805.587,-902.772\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<path fill=\"#ea985c\" stroke=\"#000000\" d=\"M1751.5,-782C1751.5,-782 1657.5,-782 1657.5,-782 1651.5,-782 1645.5,-776 1645.5,-770 1645.5,-770 1645.5,-711 1645.5,-711 1645.5,-705 1651.5,-699 1657.5,-699 1657.5,-699 1751.5,-699 1751.5,-699 1757.5,-699 1763.5,-705 1763.5,-711 1763.5,-711 1763.5,-770 1763.5,-770 1763.5,-776 1757.5,-782 1751.5,-782\"/>\n<text text-anchor=\"start\" x=\"1667\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">fico ≤ 0.763</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.614</text>\n<text text-anchor=\"start\" x=\"1660.5\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1659\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [28, 5]</text>\n<text text-anchor=\"start\" x=\"1675.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 61&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>61&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1704.5,-817.8796C1704.5,-809.6838 1704.5,-800.9891 1704.5,-792.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1708.0001,-792.298 1704.5,-782.2981 1701.0001,-792.2981 1708.0001,-792.298\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<path fill=\"#5dafea\" stroke=\"#000000\" d=\"M1954,-782C1954,-782 1855,-782 1855,-782 1849,-782 1843,-776 1843,-770 1843,-770 1843,-711 1843,-711 1843,-705 1849,-699 1855,-699 1855,-699 1954,-699 1954,-699 1960,-699 1966,-705 1966,-711 1966,-711 1966,-770 1966,-770 1966,-776 1960,-782 1954,-782\"/>\n<text text-anchor=\"start\" x=\"1851\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 2.564</text>\n<text text-anchor=\"start\" x=\"1853.5\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.621</text>\n<text text-anchor=\"start\" x=\"1860.5\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 70</text>\n<text text-anchor=\"start\" x=\"1854.5\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 93]</text>\n<text text-anchor=\"start\" x=\"1875.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 61&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>61&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1774.4503,-817.8796C1793.7918,-806.3714 1814.7867,-793.8794 1834.1507,-782.3578\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1836.117,-785.2606 1842.9212,-777.1394 1832.5376,-779.2449 1836.117,-785.2606\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1702,-655.5C1702,-655.5 1619,-655.5 1619,-655.5 1613,-655.5 1607,-649.5 1607,-643.5 1607,-643.5 1607,-599.5 1607,-599.5 1607,-593.5 1613,-587.5 1619,-587.5 1619,-587.5 1702,-587.5 1702,-587.5 1708,-587.5 1714,-593.5 1714,-599.5 1714,-599.5 1714,-643.5 1714,-643.5 1714,-649.5 1708,-655.5 1702,-655.5\"/>\n<text text-anchor=\"start\" x=\"1618\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1616.5\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18</text>\n<text text-anchor=\"start\" x=\"1615\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [28, 0]</text>\n<text text-anchor=\"start\" x=\"1631.5\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 62&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>62&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1689.1109,-698.8796C1685.0858,-687.9935 1680.7352,-676.227 1676.6707,-665.2344\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1679.9387,-663.9805 1673.1879,-655.8149 1673.3732,-666.4082 1679.9387,-663.9805\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1821,-655.5C1821,-655.5 1744,-655.5 1744,-655.5 1738,-655.5 1732,-649.5 1732,-643.5 1732,-643.5 1732,-599.5 1732,-599.5 1732,-593.5 1738,-587.5 1744,-587.5 1744,-587.5 1821,-587.5 1821,-587.5 1827,-587.5 1833,-593.5 1833,-599.5 1833,-599.5 1833,-643.5 1833,-643.5 1833,-649.5 1827,-655.5 1821,-655.5\"/>\n<text text-anchor=\"start\" x=\"1740\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1743\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1741\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5]</text>\n<text text-anchor=\"start\" x=\"1753.5\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 62&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>62&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1731.7806,-698.8796C1739.1323,-687.6636 1747.0964,-675.5131 1754.4874,-664.2372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1757.4531,-666.0972 1760.0079,-655.8149 1751.5986,-662.2598 1757.4531,-666.0972\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1946,-655.5C1946,-655.5 1863,-655.5 1863,-655.5 1857,-655.5 1851,-649.5 1851,-643.5 1851,-643.5 1851,-599.5 1851,-599.5 1851,-593.5 1857,-587.5 1863,-587.5 1863,-587.5 1946,-587.5 1946,-587.5 1952,-587.5 1958,-593.5 1958,-599.5 1958,-599.5 1958,-643.5 1958,-643.5 1958,-649.5 1952,-655.5 1946,-655.5\"/>\n<text text-anchor=\"start\" x=\"1862\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1860.5\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 42</text>\n<text text-anchor=\"start\" x=\"1859\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 66]</text>\n<text text-anchor=\"start\" x=\"1875.5\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 65&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>65&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1904.5,-698.8796C1904.5,-688.2134 1904.5,-676.7021 1904.5,-665.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1908.0001,-665.8149 1904.5,-655.8149 1901.0001,-665.815 1908.0001,-665.8149\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<path fill=\"#b6dbf5\" stroke=\"#000000\" d=\"M2122.5,-663C2122.5,-663 1988.5,-663 1988.5,-663 1982.5,-663 1976.5,-657 1976.5,-651 1976.5,-651 1976.5,-592 1976.5,-592 1976.5,-586 1982.5,-580 1988.5,-580 1988.5,-580 2122.5,-580 2122.5,-580 2128.5,-580 2134.5,-586 2134.5,-592 2134.5,-592 2134.5,-651 2134.5,-651 2134.5,-657 2128.5,-663 2122.5,-663\"/>\n<text text-anchor=\"start\" x=\"1984.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">log.annual.inc ≤ 1.628</text>\n<text text-anchor=\"start\" x=\"2004.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.962</text>\n<text text-anchor=\"start\" x=\"2011.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 28</text>\n<text text-anchor=\"start\" x=\"2005.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 27]</text>\n<text text-anchor=\"start\" x=\"2026.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 65&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>65&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1957.3125,-698.8796C1969.3818,-689.368 1982.3039,-679.1843 1994.6788,-669.432\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1997.0296,-672.0356 2002.7173,-663.0969 1992.6968,-666.5377 1997.0296,-672.0356\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<path fill=\"#f3c4a2\" stroke=\"#000000\" d=\"M1977.5,-544C1977.5,-544 1883.5,-544 1883.5,-544 1877.5,-544 1871.5,-538 1871.5,-532 1871.5,-532 1871.5,-473 1871.5,-473 1871.5,-467 1877.5,-461 1883.5,-461 1883.5,-461 1977.5,-461 1977.5,-461 1983.5,-461 1989.5,-467 1989.5,-473 1989.5,-473 1989.5,-532 1989.5,-532 1989.5,-538 1983.5,-544 1977.5,-544\"/>\n<text text-anchor=\"start\" x=\"1882.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">int.rate ≤ 0.154</text>\n<text text-anchor=\"start\" x=\"1879.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.931</text>\n<text text-anchor=\"start\" x=\"1886.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1885\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 9]</text>\n<text text-anchor=\"start\" x=\"1901.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 67&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>67&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2011.7811,-579.8796C2002.1314,-570.6931 1991.8234,-560.8798 1981.9009,-551.4336\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1984.0616,-548.6582 1974.4055,-544.2981 1979.235,-553.7282 1984.0616,-548.6582\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2103,-536.5C2103,-536.5 2020,-536.5 2020,-536.5 2014,-536.5 2008,-530.5 2008,-524.5 2008,-524.5 2008,-480.5 2008,-480.5 2008,-474.5 2014,-468.5 2020,-468.5 2020,-468.5 2103,-468.5 2103,-468.5 2109,-468.5 2115,-474.5 2115,-480.5 2115,-480.5 2115,-524.5 2115,-524.5 2115,-530.5 2109,-536.5 2103,-536.5\"/>\n<text text-anchor=\"start\" x=\"2019\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2017.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2016\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 18]</text>\n<text text-anchor=\"start\" x=\"2032.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 67&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>67&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2057.5985,-579.8796C2058.1363,-569.2134 2058.7167,-557.7021 2059.2613,-546.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2062.7617,-546.9785 2059.7698,-536.8149 2055.7706,-546.626 2062.7617,-546.9785\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<path fill=\"#a7d3f3\" stroke=\"#000000\" d=\"M1853.5,-425C1853.5,-425 1735.5,-425 1735.5,-425 1729.5,-425 1723.5,-419 1723.5,-413 1723.5,-413 1723.5,-354 1723.5,-354 1723.5,-348 1729.5,-342 1735.5,-342 1735.5,-342 1853.5,-342 1853.5,-342 1859.5,-342 1865.5,-348 1865.5,-354 1865.5,-354 1865.5,-413 1865.5,-413 1865.5,-419 1859.5,-425 1853.5,-425\"/>\n<text text-anchor=\"start\" x=\"1731.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">installment ≤ &#45;0.578</text>\n<text text-anchor=\"start\" x=\"1747.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.94</text>\n<text text-anchor=\"start\" x=\"1755\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7</text>\n<text text-anchor=\"start\" x=\"1753\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 9]</text>\n<text text-anchor=\"start\" x=\"1765.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1882.9338,-460.8796C1872.3321,-451.6031 1860.9998,-441.6874 1850.1067,-432.1559\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1852.0998,-429.2491 1842.2692,-425.2981 1847.4902,-434.5172 1852.0998,-429.2491\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1979,-417.5C1979,-417.5 1896,-417.5 1896,-417.5 1890,-417.5 1884,-411.5 1884,-405.5 1884,-405.5 1884,-361.5 1884,-361.5 1884,-355.5 1890,-349.5 1896,-349.5 1896,-349.5 1979,-349.5 1979,-349.5 1985,-349.5 1991,-355.5 1991,-361.5 1991,-361.5 1991,-405.5 1991,-405.5 1991,-411.5 1985,-417.5 1979,-417.5\"/>\n<text text-anchor=\"start\" x=\"1895\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1898\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1892\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [12, 0]</text>\n<text text-anchor=\"start\" x=\"1908.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 68&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>68&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1932.9483,-460.8796C1933.5757,-450.2134 1934.2528,-438.7021 1934.8881,-427.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1938.3881,-428.0032 1935.4815,-417.8149 1931.4002,-427.5921 1938.3881,-428.0032\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M1823,-298.5C1823,-298.5 1746,-298.5 1746,-298.5 1740,-298.5 1734,-292.5 1734,-286.5 1734,-286.5 1734,-242.5 1734,-242.5 1734,-236.5 1740,-230.5 1746,-230.5 1746,-230.5 1823,-230.5 1823,-230.5 1829,-230.5 1835,-236.5 1835,-242.5 1835,-242.5 1835,-286.5 1835,-286.5 1835,-292.5 1829,-298.5 1823,-298.5\"/>\n<text text-anchor=\"start\" x=\"1742\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1745\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1743\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 0]</text>\n<text text-anchor=\"start\" x=\"1755.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 69&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>69&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1791.0025,-341.8796C1790.1062,-331.2134 1789.1388,-319.7021 1788.2312,-308.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1791.7088,-308.4867 1787.3836,-298.8149 1784.7334,-309.0729 1791.7088,-308.4867\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1942,-298.5C1942,-298.5 1865,-298.5 1865,-298.5 1859,-298.5 1853,-292.5 1853,-286.5 1853,-286.5 1853,-242.5 1853,-242.5 1853,-236.5 1859,-230.5 1865,-230.5 1865,-230.5 1942,-230.5 1942,-230.5 1948,-230.5 1954,-236.5 1954,-242.5 1954,-242.5 1954,-286.5 1954,-286.5 1954,-292.5 1948,-298.5 1942,-298.5\"/>\n<text text-anchor=\"start\" x=\"1861\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1864\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1862\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 9]</text>\n<text text-anchor=\"start\" x=\"1874.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 69&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>69&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1832.6229,-341.8796C1843.1986,-330.3337 1854.6812,-317.7976 1865.2633,-306.2446\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1867.8951,-308.5531 1872.0687,-298.8149 1862.7333,-303.825 1867.8951,-308.5531\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1874,-1012.5C1874,-1012.5 1797,-1012.5 1797,-1012.5 1791,-1012.5 1785,-1006.5 1785,-1000.5 1785,-1000.5 1785,-956.5 1785,-956.5 1785,-950.5 1791,-944.5 1797,-944.5 1797,-944.5 1874,-944.5 1874,-944.5 1880,-944.5 1886,-950.5 1886,-956.5 1886,-956.5 1886,-1000.5 1886,-1000.5 1886,-1006.5 1880,-1012.5 1874,-1012.5\"/>\n<text text-anchor=\"start\" x=\"1793\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1796\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1794\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n<text text-anchor=\"start\" x=\"1806.5\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 75&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>75&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1897.2736,-1055.8796C1888.2319,-1044.5536 1878.4295,-1032.2748 1869.3534,-1020.9058\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1871.8685,-1018.4464 1862.8943,-1012.8149 1866.398,-1022.8137 1871.8685,-1018.4464\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<path fill=\"#e5823b\" stroke=\"#000000\" d=\"M2097,-1020C2097,-1020 1916,-1020 1916,-1020 1910,-1020 1904,-1014 1904,-1008 1904,-1008 1904,-949 1904,-949 1904,-943 1910,-937 1916,-937 1916,-937 2097,-937 2097,-937 2103,-937 2109,-943 2109,-949 2109,-949 2109,-1008 2109,-1008 2109,-1014 2103,-1020 2097,-1020\"/>\n<text text-anchor=\"start\" x=\"1912\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">purpose_educational ≤ 2.526</text>\n<text text-anchor=\"start\" x=\"1955.5\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.092</text>\n<text text-anchor=\"start\" x=\"1962.5\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n<text text-anchor=\"start\" x=\"1961\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [84, 1]</text>\n<text text-anchor=\"start\" x=\"1977.5\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 75&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>75&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1957.0811,-1055.8796C1962.6605,-1047.1434 1968.6019,-1037.8404 1974.3595,-1028.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1977.3726,-1030.6098 1979.8054,-1020.2981 1971.4731,-1026.8421 1977.3726,-1030.6098\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2035,-893.5C2035,-893.5 1952,-893.5 1952,-893.5 1946,-893.5 1940,-887.5 1940,-881.5 1940,-881.5 1940,-837.5 1940,-837.5 1940,-831.5 1946,-825.5 1952,-825.5 1952,-825.5 2035,-825.5 2035,-825.5 2041,-825.5 2047,-831.5 2047,-837.5 2047,-837.5 2047,-881.5 2047,-881.5 2047,-887.5 2041,-893.5 2035,-893.5\"/>\n<text text-anchor=\"start\" x=\"1951\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"1949.5\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 51</text>\n<text text-anchor=\"start\" x=\"1948\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [77, 0]</text>\n<text text-anchor=\"start\" x=\"1964.5\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 77&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>77&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2001.9532,-936.8796C2000.788,-926.2134 1999.5305,-914.7021 1998.3506,-903.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2001.8141,-903.3757 1997.2487,-893.8149 1994.8555,-904.1359 2001.8141,-903.3757\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<path fill=\"#e99355\" stroke=\"#000000\" d=\"M2171.5,-901C2171.5,-901 2077.5,-901 2077.5,-901 2071.5,-901 2065.5,-895 2065.5,-889 2065.5,-889 2065.5,-830 2065.5,-830 2065.5,-824 2071.5,-818 2077.5,-818 2077.5,-818 2171.5,-818 2171.5,-818 2177.5,-818 2183.5,-824 2183.5,-830 2183.5,-830 2183.5,-889 2183.5,-889 2183.5,-895 2177.5,-901 2171.5,-901\"/>\n<text text-anchor=\"start\" x=\"2091\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ 2.191</text>\n<text text-anchor=\"start\" x=\"2073.5\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.544</text>\n<text text-anchor=\"start\" x=\"2085\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2083\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 1]</text>\n<text text-anchor=\"start\" x=\"2095.5\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 77&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>77&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2047.7707,-936.8796C2056.8799,-927.6931 2066.6108,-917.8798 2075.9776,-908.4336\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2078.4973,-910.8634 2083.0532,-901.2981 2073.5267,-905.9345 2078.4973,-910.8634\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2102,-774.5C2102,-774.5 2025,-774.5 2025,-774.5 2019,-774.5 2013,-768.5 2013,-762.5 2013,-762.5 2013,-718.5 2013,-718.5 2013,-712.5 2019,-706.5 2025,-706.5 2025,-706.5 2102,-706.5 2102,-706.5 2108,-706.5 2114,-712.5 2114,-718.5 2114,-718.5 2114,-762.5 2114,-762.5 2114,-768.5 2108,-774.5 2102,-774.5\"/>\n<text text-anchor=\"start\" x=\"2021\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2024\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2022\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n<text text-anchor=\"start\" x=\"2034.5\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 79&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>79&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2103.1652,-817.8796C2097.5285,-806.8835 2091.4315,-794.9893 2085.7478,-783.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2088.7663,-782.1173 2081.09,-774.8149 2082.5371,-785.3105 2088.7663,-782.1173\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2221,-774.5C2221,-774.5 2144,-774.5 2144,-774.5 2138,-774.5 2132,-768.5 2132,-762.5 2132,-762.5 2132,-718.5 2132,-718.5 2132,-712.5 2138,-706.5 2144,-706.5 2144,-706.5 2221,-706.5 2221,-706.5 2227,-706.5 2233,-712.5 2233,-718.5 2233,-718.5 2233,-762.5 2233,-762.5 2233,-768.5 2227,-774.5 2221,-774.5\"/>\n<text text-anchor=\"start\" x=\"2140\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2143\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2141\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 0]</text>\n<text text-anchor=\"start\" x=\"2153.5\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 79&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>79&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2144.7856,-817.8796C2150.145,-806.8835 2155.9422,-794.9893 2161.3463,-783.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2164.54,-785.3375 2165.7751,-774.8149 2158.2476,-782.2706 2164.54,-785.3375\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2097.5,-1369.5C2097.5,-1369.5 2005.5,-1369.5 2005.5,-1369.5 1999.5,-1369.5 1993.5,-1363.5 1993.5,-1357.5 1993.5,-1357.5 1993.5,-1313.5 1993.5,-1313.5 1993.5,-1307.5 1999.5,-1301.5 2005.5,-1301.5 2005.5,-1301.5 2097.5,-1301.5 2097.5,-1301.5 2103.5,-1301.5 2109.5,-1307.5 2109.5,-1313.5 2109.5,-1313.5 2109.5,-1357.5 2109.5,-1357.5 2109.5,-1363.5 2103.5,-1369.5 2097.5,-1369.5\"/>\n<text text-anchor=\"start\" x=\"2009\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2003.5\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 536</text>\n<text text-anchor=\"start\" x=\"2001.5\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [823, 0]</text>\n<text text-anchor=\"start\" x=\"2022.5\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 82&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>82&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2051.5,-1412.8796C2051.5,-1402.2134 2051.5,-1390.7021 2051.5,-1379.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2055.0001,-1379.8149 2051.5,-1369.8149 2048.0001,-1379.815 2055.0001,-1379.8149\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<path fill=\"#4ea8e8\" stroke=\"#000000\" d=\"M2298.5,-1377C2298.5,-1377 2164.5,-1377 2164.5,-1377 2158.5,-1377 2152.5,-1371 2152.5,-1365 2152.5,-1365 2152.5,-1306 2152.5,-1306 2152.5,-1300 2158.5,-1294 2164.5,-1294 2164.5,-1294 2298.5,-1294 2298.5,-1294 2304.5,-1294 2310.5,-1300 2310.5,-1306 2310.5,-1306 2310.5,-1365 2310.5,-1365 2310.5,-1371 2304.5,-1377 2298.5,-1377\"/>\n<text text-anchor=\"start\" x=\"2160.5\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">inq.last.6mths ≤ 3.124</text>\n<text text-anchor=\"start\" x=\"2180.5\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.461</text>\n<text text-anchor=\"start\" x=\"2187.5\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 96</text>\n<text text-anchor=\"start\" x=\"2177.5\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [16, 148]</text>\n<text text-anchor=\"start\" x=\"2202.5\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 82&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>82&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2114.4553,-1412.8796C2129.1166,-1403.1868 2144.8336,-1392.7961 2159.8401,-1382.8752\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2162.1687,-1385.5315 2168.5803,-1377.0969 2158.3082,-1379.6922 2162.1687,-1385.5315\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<path fill=\"#48a4e7\" stroke=\"#000000\" d=\"M2283.5,-1258C2283.5,-1258 2179.5,-1258 2179.5,-1258 2173.5,-1258 2167.5,-1252 2167.5,-1246 2167.5,-1246 2167.5,-1187 2167.5,-1187 2167.5,-1181 2173.5,-1175 2179.5,-1175 2179.5,-1175 2283.5,-1175 2283.5,-1175 2289.5,-1175 2295.5,-1181 2295.5,-1187 2295.5,-1187 2295.5,-1246 2295.5,-1246 2295.5,-1252 2289.5,-1258 2283.5,-1258\"/>\n<text text-anchor=\"start\" x=\"2175.5\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ &#45;0.493</text>\n<text text-anchor=\"start\" x=\"2180.5\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.363</text>\n<text text-anchor=\"start\" x=\"2187.5\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 92</text>\n<text text-anchor=\"start\" x=\"2177.5\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 148]</text>\n<text text-anchor=\"start\" x=\"2202.5\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 84&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>84&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2231.5,-1293.8796C2231.5,-1285.6838 2231.5,-1276.9891 2231.5,-1268.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2235.0001,-1268.298 2231.5,-1258.2981 2228.0001,-1268.2981 2235.0001,-1268.298\"/>\n</g>\n<!-- 94 -->\n<g id=\"node95\" class=\"node\">\n<title>94</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2403,-1250.5C2403,-1250.5 2326,-1250.5 2326,-1250.5 2320,-1250.5 2314,-1244.5 2314,-1238.5 2314,-1238.5 2314,-1194.5 2314,-1194.5 2314,-1188.5 2320,-1182.5 2326,-1182.5 2326,-1182.5 2403,-1182.5 2403,-1182.5 2409,-1182.5 2415,-1188.5 2415,-1194.5 2415,-1194.5 2415,-1238.5 2415,-1238.5 2415,-1244.5 2409,-1250.5 2403,-1250.5\"/>\n<text text-anchor=\"start\" x=\"2322\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2325\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2323\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 0]</text>\n<text text-anchor=\"start\" x=\"2335.5\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 84&#45;&gt;94 -->\n<g id=\"edge94\" class=\"edge\">\n<title>84&#45;&gt;94</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2278.0169,-1293.8796C2291.167,-1282.1138 2305.4663,-1269.3197 2318.5809,-1257.5855\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2321.0294,-1260.0913 2326.148,-1250.8149 2316.3618,-1254.8746 2321.0294,-1260.0913\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<path fill=\"#e6f3fc\" stroke=\"#000000\" d=\"M2278.5,-1139C2278.5,-1139 2184.5,-1139 2184.5,-1139 2178.5,-1139 2172.5,-1133 2172.5,-1127 2172.5,-1127 2172.5,-1068 2172.5,-1068 2172.5,-1062 2178.5,-1056 2184.5,-1056 2184.5,-1056 2278.5,-1056 2278.5,-1056 2284.5,-1056 2290.5,-1062 2290.5,-1068 2290.5,-1068 2290.5,-1127 2290.5,-1127 2290.5,-1133 2284.5,-1139 2278.5,-1139\"/>\n<text text-anchor=\"start\" x=\"2180.5\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.util ≤ &#45;1.59</text>\n<text text-anchor=\"start\" x=\"2180.5\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.997</text>\n<text text-anchor=\"start\" x=\"2187.5\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12</text>\n<text text-anchor=\"start\" x=\"2190\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 8]</text>\n<text text-anchor=\"start\" x=\"2202.5\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 85&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>85&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2231.5,-1174.8796C2231.5,-1166.6838 2231.5,-1157.9891 2231.5,-1149.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2235.0001,-1149.298 2231.5,-1139.2981 2228.0001,-1149.2981 2235.0001,-1149.298\"/>\n</g>\n<!-- 89 -->\n<g id=\"node90\" class=\"node\">\n<title>89</title>\n<path fill=\"#3fa0e6\" stroke=\"#000000\" d=\"M2473,-1139C2473,-1139 2374,-1139 2374,-1139 2368,-1139 2362,-1133 2362,-1127 2362,-1127 2362,-1068 2362,-1068 2362,-1062 2368,-1056 2374,-1056 2374,-1056 2473,-1056 2473,-1056 2479,-1056 2485,-1062 2485,-1068 2485,-1068 2485,-1127 2485,-1127 2485,-1133 2479,-1139 2473,-1139\"/>\n<text text-anchor=\"start\" x=\"2370\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">revol.bal ≤ 1.375</text>\n<text text-anchor=\"start\" x=\"2372.5\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.183</text>\n<text text-anchor=\"start\" x=\"2379.5\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 80</text>\n<text text-anchor=\"start\" x=\"2373.5\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 140]</text>\n<text text-anchor=\"start\" x=\"2394.5\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 85&#45;&gt;89 -->\n<g id=\"edge89\" class=\"edge\">\n<title>85&#45;&gt;89</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2295.7002,-1176.7093C2314.2293,-1165.225 2334.5403,-1152.6365 2353.4081,-1140.9424\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2355.308,-1143.8826 2361.964,-1135.6395 2351.6203,-1137.9327 2355.308,-1143.8826\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2216,-1012.5C2216,-1012.5 2139,-1012.5 2139,-1012.5 2133,-1012.5 2127,-1006.5 2127,-1000.5 2127,-1000.5 2127,-956.5 2127,-956.5 2127,-950.5 2133,-944.5 2139,-944.5 2139,-944.5 2216,-944.5 2216,-944.5 2222,-944.5 2228,-950.5 2228,-956.5 2228,-956.5 2228,-1000.5 2228,-1000.5 2228,-1006.5 2222,-1012.5 2216,-1012.5\"/>\n<text text-anchor=\"start\" x=\"2135\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2138\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2136\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 8]</text>\n<text text-anchor=\"start\" x=\"2148.5\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 86&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>86&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2212.6134,-1055.8796C2207.6735,-1044.9935 2202.3341,-1033.227 2197.3459,-1022.2344\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2200.391,-1020.4749 2193.0715,-1012.8149 2194.0166,-1023.3675 2200.391,-1020.4749\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2335,-1012.5C2335,-1012.5 2258,-1012.5 2258,-1012.5 2252,-1012.5 2246,-1006.5 2246,-1000.5 2246,-1000.5 2246,-956.5 2246,-956.5 2246,-950.5 2252,-944.5 2258,-944.5 2258,-944.5 2335,-944.5 2335,-944.5 2341,-944.5 2347,-950.5 2347,-956.5 2347,-956.5 2347,-1000.5 2347,-1000.5 2347,-1006.5 2341,-1012.5 2335,-1012.5\"/>\n<text text-anchor=\"start\" x=\"2254\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2257\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2255\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 0]</text>\n<text text-anchor=\"start\" x=\"2267.5\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 86&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>86&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2254.2338,-1055.8796C2260.2401,-1044.8835 2266.737,-1032.9893 2272.7933,-1021.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2276.0345,-1023.2689 2277.7565,-1012.8149 2269.8912,-1019.9133 2276.0345,-1023.2689\"/>\n</g>\n<!-- 90 -->\n<g id=\"node91\" class=\"node\">\n<title>90</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2469.5,-1012.5C2469.5,-1012.5 2377.5,-1012.5 2377.5,-1012.5 2371.5,-1012.5 2365.5,-1006.5 2365.5,-1000.5 2365.5,-1000.5 2365.5,-956.5 2365.5,-956.5 2365.5,-950.5 2371.5,-944.5 2377.5,-944.5 2377.5,-944.5 2469.5,-944.5 2469.5,-944.5 2475.5,-944.5 2481.5,-950.5 2481.5,-956.5 2481.5,-956.5 2481.5,-1000.5 2481.5,-1000.5 2481.5,-1006.5 2475.5,-1012.5 2469.5,-1012.5\"/>\n<text text-anchor=\"start\" x=\"2381\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2379.5\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 74</text>\n<text text-anchor=\"start\" x=\"2373.5\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 137]</text>\n<text text-anchor=\"start\" x=\"2394.5\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 89&#45;&gt;90 -->\n<g id=\"edge90\" class=\"edge\">\n<title>89&#45;&gt;90</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2423.5,-1055.8796C2423.5,-1045.2134 2423.5,-1033.7021 2423.5,-1022.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2427.0001,-1022.8149 2423.5,-1012.8149 2420.0001,-1022.815 2427.0001,-1022.8149\"/>\n</g>\n<!-- 91 -->\n<g id=\"node92\" class=\"node\">\n<title>91</title>\n<path fill=\"#f8e0ce\" stroke=\"#000000\" d=\"M2605.5,-1020C2605.5,-1020 2511.5,-1020 2511.5,-1020 2505.5,-1020 2499.5,-1014 2499.5,-1008 2499.5,-1008 2499.5,-949 2499.5,-949 2499.5,-943 2505.5,-937 2511.5,-937 2511.5,-937 2605.5,-937 2605.5,-937 2611.5,-937 2617.5,-943 2617.5,-949 2617.5,-949 2617.5,-1008 2617.5,-1008 2617.5,-1014 2611.5,-1020 2605.5,-1020\"/>\n<text text-anchor=\"start\" x=\"2526.5\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">dti ≤ &#45;0.07</text>\n<text text-anchor=\"start\" x=\"2507.5\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.985</text>\n<text text-anchor=\"start\" x=\"2519\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2517\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 3]</text>\n<text text-anchor=\"start\" x=\"2529.5\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 89&#45;&gt;91 -->\n<g id=\"edge91\" class=\"edge\">\n<title>89&#45;&gt;91</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2470.7164,-1055.8796C2481.2402,-1046.6031 2492.4891,-1036.6874 2503.3021,-1027.1559\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2505.8948,-1029.5362 2511.082,-1020.2981 2501.266,-1024.2851 2505.8948,-1029.5362\"/>\n</g>\n<!-- 92 -->\n<g id=\"node93\" class=\"node\">\n<title>92</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M2537,-893.5C2537,-893.5 2460,-893.5 2460,-893.5 2454,-893.5 2448,-887.5 2448,-881.5 2448,-881.5 2448,-837.5 2448,-837.5 2448,-831.5 2454,-825.5 2460,-825.5 2460,-825.5 2537,-825.5 2537,-825.5 2543,-825.5 2549,-831.5 2549,-837.5 2549,-837.5 2549,-881.5 2549,-881.5 2549,-887.5 2543,-893.5 2537,-893.5\"/>\n<text text-anchor=\"start\" x=\"2456\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2459\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2457\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n<text text-anchor=\"start\" x=\"2469.5\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 91&#45;&gt;92 -->\n<g id=\"edge92\" class=\"edge\">\n<title>91&#45;&gt;92</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2537.5149,-936.8796C2531.9707,-925.8835 2525.9736,-913.9893 2520.3831,-902.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2523.4291,-901.1684 2515.8016,-893.8149 2517.1786,-904.3199 2523.4291,-901.1684\"/>\n</g>\n<!-- 93 -->\n<g id=\"node94\" class=\"node\">\n<title>93</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M2656,-893.5C2656,-893.5 2579,-893.5 2579,-893.5 2573,-893.5 2567,-887.5 2567,-881.5 2567,-881.5 2567,-837.5 2567,-837.5 2567,-831.5 2573,-825.5 2579,-825.5 2579,-825.5 2656,-825.5 2656,-825.5 2662,-825.5 2668,-831.5 2668,-837.5 2668,-837.5 2668,-881.5 2668,-881.5 2668,-887.5 2662,-893.5 2656,-893.5\"/>\n<text text-anchor=\"start\" x=\"2575\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"2578\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2576\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0]</text>\n<text text-anchor=\"start\" x=\"2588.5\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 91&#45;&gt;93 -->\n<g id=\"edge93\" class=\"edge\">\n<title>91&#45;&gt;93</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2579.1353,-936.8796C2584.5872,-925.8835 2590.4843,-913.9893 2595.9816,-902.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.1804,-904.3289 2600.4867,-893.8149 2592.9089,-901.2195 2599.1804,-904.3289\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZfcssiimLXhG"
      },
      "source": [
        "### Questions\n",
        "1. How did the DT compare to the RF in performance? Why?\n",
        "    - The Decision Tree performed slightly worse than Random Forest\n",
        "    - Reason: Becuase Random Forest is comprised of multiple Decision Trees where then we aggregate the DTs averages. Also the randomness in feature selection helps RF avoid over fitting and get better predictions\n",
        "2. After fine-tuning, how does the max depth in DT compare to RF? Why?\n",
        "    - DT max depth: 10\n",
        "    - RF max depth: 16\n",
        "    - Reason: RF max depth is larger because it is falls under the bagging technique. Where the trees get fitted on bootstrap samples from the training set. This produces a big depth because it tries to drop the variance.\n",
        "3. What is ensemble learning? What are its pros and cons?\n",
        "    - Ensemble learning captializes on combining decisions from multiple different models to achive better predictive performance than could be attained from any of the individual learning methods alone.\n",
        "    - According to empirical studies, predictions made using several models frequently perform better. “Wisdom of crowds”\n",
        "    - Pros: \n",
        "      - Better predictions\n",
        "      - Stable and robust\n",
        "      - Captures linear and non-linear relationships\n",
        "    - Cons: \n",
        "      - Hard to interpret \n",
        "      - Computationally expensive\n",
        "      - Selecting the models is a hard problem\n",
        "4. Briefly explain 2 types of boosting methods and 2 types of bagging methods.\n",
        "Which of these categories does RF fall under?\n",
        "    - Boosting: \n",
        "      - AdaBoost: a statistical classification meta-algorithm. It is used with other learning algorithms to improve performance by combining the output of the other learning algorithms into a weighted sum that represents the final output.\n",
        "      - Gradient Boosting: a technique where it ensembles weak prediction models and produces a model which is usually in the form of decision trees.\n",
        "    - Bagging:\n",
        "      - Bagging Meta-Estimator: produces several instances of an estimator on random portions of the training set and aggregates the individual predictions to make a final prediction\n",
        "      - Random Forest: a meta estimator which fits decision tree classifiers on different sub-samples of the dataset. Uses averaging to avoid overfitting and to have better predictions\n",
        "    - RF falls under bagging\n",
        "\n",
        "- References:\n",
        "  - https://towardsdatascience.com/random-forest-3a55c3aca46d\n",
        "  - https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5\n",
        "  - https://www.kdnuggets.com/2022/02/random-forest-decision-tree-key-differences.html\n",
        "  - https://www.soa.org/4a6af7/globalassets/assets/files/e-business/pd/events/2020/predictive-analytics-4-0/pd-2020-09-pas-session-014.pdf\n",
        "  - https://blog.knoldus.com/ensemble-learning-its-methods-in-machine-learning/\n",
        "  - https://medium.com/@aravanshad/ensemble-methods-95533944783f\n",
        "  - https://en.wikipedia.org/wiki/Ensemble_learning\n",
        "  - https://scikit-learn.org/stable/modules/ensemble.html\n",
        "  - https://www.geeksforgeeks.org/bagging-vs-boosting-in-machine-learning/#:~:text=The%20Random%20Forest%20model%20uses,trees%20make%20a%20Random%20Forest.\n",
        "  - https://en.wikipedia.org/wiki/AdaBoost\n",
        "  -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V_Ea-QL1LXhG"
      },
      "source": [
        "# Task 4: Domain Gap (15%)\n",
        "\n",
        "Evaluate your CNN model from task 2 on SVHN data without retraining your model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file\n",
        "\n",
        "with zipfile.ZipFile('svhn.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/task4/')"
      ],
      "metadata": {
        "id": "btZsq4dqJcII"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust parse_data function to adapt for new directory structure\n",
        "\n",
        "def parse_data(dir):\n",
        "  X = []\n",
        "  y = []\n",
        "  for img in os.listdir(dir):\n",
        "    datum = plt.imread(f'{dir}/{img}')\n",
        "    datum = rgb2gray(datum)\n",
        "    tr = transforms.ToTensor()\n",
        "    datum = tr(datum)  \n",
        "    rs = transforms.Resize((84,84))\n",
        "    datum = rs(datum)\n",
        "    X.append(datum)\n",
        "    y.append(img.split('.')[0])\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "ZnZAh3YEJMFH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse data\n",
        "\n",
        "X_test, y_test = parse_data('/task4/svhn')\n",
        "\n",
        "test_data = CustumData(X_test, y_test)"
      ],
      "metadata": {
        "id": "VyQjGwChJfC5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c952ZMspLXhG"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "\n",
        "def testing(net, device, testloader):\n",
        "  net.eval()\n",
        "  test_corrects = 0\n",
        "  for data, targets in testloader:\n",
        "    with torch.no_grad():\n",
        "      data = data.to(device).float()\n",
        "      targets = torch.tensor([[int(target[0]), int(target[1]), int(target[2])] for target in targets])\n",
        "      targets = targets.to(device)\n",
        "      \n",
        "      outputs = net(data) \n",
        "\n",
        "      for i in range(3):\n",
        "        preds = torch.max(outputs[i], 1)[1]\n",
        "        test_corrects += torch.sum(preds == targets[:, i])\n",
        "  acc = test_corrects.double() / (len(test_data)*3)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main\n",
        "\n",
        "def main_task4():\n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  testloader = DataLoader(test_data, batch_size=1024, shuffle=True)\n",
        "  acc = testing(best_cnn, device, testloader)\n",
        "  print(f'Accuracy: {acc}')\n",
        "\n",
        "main_task4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyZisFimJiXG",
        "outputId": "390dd398-709d-439b-b554-ebf982c00e48"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.08333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qD9lUjG7LXhH"
      },
      "source": [
        "### Questions\n",
        "1. How did your model perform? Why is it better/worse?\n",
        "    - Accuracy: 0.08333333333333333\n",
        "    - The model performed much worse.\n",
        "    - Reason: \n",
        "      - Although the idea of the problem the model is trying to solve is the same, it is still a much different problem.\n",
        "      - The testing data is extremely different from triple_mnist, where the images contain various other objects of different colors and the pictures of the numbers are taken from different angles which adjusts how the numbers look. Where on the other hand mnist dataset is only handwritten numbers with the samle color due to how the pictures look and my grayscaling, and it was trained to predict only that kind of pictures with slight modifications in rotation due to the augmentation I implemented.\n",
        "2. What is domain gap in the context of ML?\n",
        "    - A domain gap or also known as domain shift is a shift in the data distribution between a dataset used for training an algorithm and the dataset it will encounter when it is used. These domain changes occur often in real-world AI applications. Traditional machine learning methods frequently don't adapt well to domain changes.\n",
        "3. Suggest two ways through which the problem of domain gap can be tackled.\n",
        "    - There are multiple ways to tackle this problem In the field of Domain Adaptation.\n",
        "    - Note: Because I don't fully understand if you want 2 algorithms or 2 general descriptions of Domain Adaptation methods I will just write 2 algorithms and 2 general descriptions.\n",
        "    - General ways:\n",
        "      - 1) Unsupervised Domain Adaptation\n",
        "        - Where learning includes two sets of labeled and unlabeled source examples, and a set of unlabled target examples \n",
        "      - 2) Semi-Supervised Domain Adaptation\n",
        "        - Where in this situation, we also include a small set of labeled target examples.\n",
        "    - Algorthims:\n",
        "      - 1) Reweighting\n",
        "        - Where we try to reweight the source labeled sample so it would resemble the target sample.\n",
        "      - 2) Search of a common representation space\n",
        "        - Where we try to make a common representation space where the two domains are close but keep a good performance in the source task. \n",
        "\n",
        "- References: \n",
        "    - https://en.wikipedia.org/wiki/Domain_adaptation#:~:text=Domain%20adaptation%20is%20the%20ability,a%20subcategory%20of%20transfer%20learning.\n",
        "    - https://machinelearning.apple.com/research/bridging-the-domain-gap-for-neural-models "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wv-v1oymLXhF",
        "ZfcssiimLXhG",
        "qD9lUjG7LXhH"
      ]
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}