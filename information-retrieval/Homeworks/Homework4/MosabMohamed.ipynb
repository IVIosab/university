{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sugges_\n",
    "\n",
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest.\n",
    "\n",
    "Today we will practice generating suggestions using [Trie](https://en.wikipedia.org/wiki/Trie) data structure (prefix tree), see the example below.\n",
    "\n",
    "Plan of your homework:\n",
    "\n",
    "1. Build Trie based on real search query data, provided by AOL company;\n",
    "2. Generate suggestion based on a trie;\n",
    "3. Measure suggestion speed;\n",
    "\n",
    "![image](https://www.ritambhara.in/wp-content/uploads/2017/05/Screen-Shot-2017-05-01-at-4.01.38-PM.png)\n",
    "\n",
    "## 0. Install Trie data structure support\n",
    "\n",
    "You are free to use any library implementation of Trie, as well as the one we suggest (read the docs before asking any questions!): https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygtrie in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (2.5.0)\n",
      "Requirement already satisfied: tqdm in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: pyspellchecker in /home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygtrie\n",
    "!pip install tqdm\n",
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a trie upon a dataset\n",
    "\n",
    "### 1.1. [5] Read the dataset\n",
    "\n",
    "Download the [dataset](https://github.com/IUCVLab/information-retrieval/tree/main/datasets/aol) (we provide only the first part of the original data for simplicity (~3.5 mln queries)).\n",
    "\n",
    "Explore the data, see readme file. Load the dataset. Pass the assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aol_data = pd.read_csv('aol/user-ct-test-collection-01.txt', sep='\\t', header=0)\n",
    "\n",
    "assert aol_data.shape[0] == 3558411, \"Dataset size does not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. [10] Build a Trie\n",
    "\n",
    "We want a suggest function to be **non-sensitive to stop words** because we don't want to upset the users if they confuses/omits prepositions. Consider *\"public events in Innopolis\"* vs *\"public events at Innopolis\"* or *\"public events Innopolis\"* - they all mean the same.\n",
    "\n",
    "Build a Trie based on the dataset, **storing query statistics such as query _frequency_, urls and ranks in the nodes**. Some queries may have no associated urls, others may have multiple ranked urls. Think of the way to store this information.\n",
    "\n",
    "Pass the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnonID                int64\n",
       "Query        string[python]\n",
       "QueryTime            object\n",
       "ItemRank            float64\n",
       "ClickURL             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "aol_data = aol_data.dropna(subset=['Query']) #drop empty queries\n",
    "aol_data = aol_data.astype({'Query': 'string'}) #convert from object to string\n",
    "aol_data = aol_data[aol_data.Query.str.len() > 1] #drop single character queries\n",
    "aol_data['Query'] = aol_data['Query'].str.lower() # make all queries lowercase\n",
    "\n",
    "aol_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452322/3452322 [01:28<00:00, 38926.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample question surveys ~ TrieNode(freq=6, urls=['http://www.surveyconnect.com', 'http://www.custominsight.com', 'http://www.askemployees.com', 'http://www.lg-employers.gov.uk', nan], ranks=[7.0, 4.0, 10.0, 1.0, nan])\n",
      "sample questions immigration interview ~ TrieNode(freq=2, urls=[nan], ranks=[nan])\n",
      "sample questions interview ~ TrieNode(freq=2, urls=['http://www.quintcareers.com'], ranks=[1.0])\n",
      "sample questions family interview ~ TrieNode(freq=4, urls=['http://www.grandparents-day.com', 'http://www.quintcareers.com', 'http://jobsearchtech.about.com'], ranks=[2.0, 5.0, 3.0])\n",
      "sample questions sociology race ethnicity ~ TrieNode(freq=2, urls=[nan], ranks=[nan])\n",
      "sample questions biology ~ TrieNode(freq=3, urls=['http://www.utexas.edu', 'http://www.troy.k12.ny.us'], ranks=[3.0, 6.0])\n",
      "sample questions us citizenship test ~ TrieNode(freq=2, urls=['http://uscis.gov'], ranks=[1.0])\n",
      "sample questionarie teaching evaluation ~ TrieNode(freq=2, urls=[nan], ranks=[nan])\n",
      "sample questionnaire teaching evaluation ~ TrieNode(freq=6, urls=['http://www.surveyconsole.com', 'http://www.usask.ca', 'http://teaching.berkeley.edu', 'http://www.flinders.edu.au', 'http://oregonstate.edu'], ranks=[1.0, 2.0, 6.0, 9.0, 10.0])\n",
      "sample questionnaire clinical research coordinators certification ~ TrieNode(freq=2, urls=['http://www.pharmatech.com'], ranks=[9.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pygtrie\n",
    "import tqdm\n",
    "\n",
    "stops = set('a on at of to is from for and with using the in &'.split())\n",
    "\n",
    "aol_trie = pygtrie.CharTrie()\n",
    "\n",
    "class TrieNode():\n",
    "    def __init__(self):\n",
    "        self.queries = []\n",
    "        self.urls = []\n",
    "        self.ranks = []\n",
    "        self.freq = 1\n",
    "    def __repr__(self):\n",
    "        return f'TrieNode(freq={self.freq}, urls={self.urls}, ranks={self.ranks})'\n",
    "\n",
    "def build_trie(data):\n",
    "    for row in tqdm.tqdm(data.itertuples(), total=data.shape[0]):\n",
    "        query, url, rank = row.Query, row.ClickURL, row.ItemRank\n",
    "        key = ' '.join([word for word in query.split() if word not in stops])\n",
    "        if not key:\n",
    "            continue\n",
    "        if key not in aol_trie:\n",
    "            aol_trie[key] = TrieNode()\n",
    "        aol_trie[key].queries.append(query)\n",
    "        aol_trie[key].urls.append(url)\n",
    "        aol_trie[key].ranks.append(rank)\n",
    "        aol_trie[key].freq += 1\n",
    "\n",
    "build_trie(aol_data)\n",
    "\n",
    "# test trie\n",
    "bag = []\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)\n",
    "    \n",
    "    #NB: here we assume you store urls in a property of list type. But you can do something different. \n",
    "    bag += val.urls\n",
    "    \n",
    "    assert \"sample question\" in key, \"All examples have `sample question` substring\"\n",
    "    assert key[:len(\"sample question\")] == \"sample question\", \"All examples have `sample question` starting string\"\n",
    "\n",
    "for url in [\"http://www.surveyconnect.com\", \"http://www.custominsight.com\", \n",
    "            \"http://jobsearchtech.about.com\", \"http://www.troy.k12.ny.us\",\n",
    "            \"http://www.flinders.edu.au\", \"http://uscis.gov\"]:\n",
    "    assert url in bag, \"This url should be in a try\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [15] Write a suggest function which is non-sensitive to stop words\n",
    "\n",
    "Suggest options for user query based on Trie you just built.\n",
    "Output results sorted by frequency, print query count for each suggestion. If there is an url available, print the url too. If multiple url-s are available, print the one with the highest rank (the less the better).\n",
    "\n",
    "Pass the asserts.\n",
    "\n",
    "Question for analysis: What is the empirical threshold for minimal prefix for suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: trie\n",
      "Results:\n",
      "['tried and true tattoo', 'triest', 'triethanalomine', 'tried and failed', \"tried and truechildren's consignment sale\"]\n"
     ]
    }
   ],
   "source": [
    "def complete_user_query(query: str, trie, top_k=5) -> list[str]:\n",
    "    query = query.lower()\n",
    "    results = []\n",
    "    try: \n",
    "        for key, node in trie.items(query):\n",
    "            url = max(node.urls, key=node.urls.count)\n",
    "            rank = node.ranks[node.urls.index(url)]\n",
    "            freq = node.freq\n",
    "            queries = max(node.queries, key=node.queries.count)\n",
    "            results.append((key, url, rank, freq, queries))\n",
    "    except KeyError:\n",
    "        return []\n",
    "    results = sorted(results, key=lambda x: x[3], reverse=True)\n",
    "    q = [queries for key, url, rank, freq, queries in results[:top_k]]\n",
    "    f = [freq for key, url, rank, freq, queries in results[:top_k]]\n",
    "    return (q, f)\n",
    " \n",
    "        \n",
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "print(\"Results:\")\n",
    "res, _ = complete_user_query(inp, aol_trie) # i added _ because i return a tuple of queries and frequncies\n",
    "print(res)\n",
    "\n",
    "#NB we assume you return suggested query string only\n",
    "assert res[0] == \"tried and true tattoo\"\n",
    "assert res[1] == \"triest\" or res[1] == \"triethanalomine\"\n",
    "\n",
    "assert \"boys and girls club of conyers georgia\" \\\n",
    "            in complete_user_query(\"boys girls club conyers\", aol_trie, 10)[0], \"Should be here\" # i added [0] because i return a tuple of queries and frequncies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure suggest speed ##\n",
    "\n",
    "### 3.1. [10] Full Trie test\n",
    "\n",
    "Check how fast your search is working. Consider changing your code if it takes too long on average.\n",
    "\n",
    "Sucess criterion:\n",
    "- there is an average and a standard deviation for **multiple runs** of the given bucket.\n",
    "- there is an average and a standard deviation for **multiple runs** of naive search in the unindexed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_user_query() but implemented without a trie (for comparison)\n",
    "def complete_user_query_without_trie(query, dataset, top_k=5):\n",
    "    freq = {}\n",
    "    results, indexed_results = set(), []\n",
    "    \n",
    "    for item in dataset.itertuples():\n",
    "        query = item.Query\n",
    "        freq[query] = freq.get(query, 0) + 1\n",
    "        if query.startswith(key) or (' ' + key in query):\n",
    "            results.add(query)\n",
    "            \n",
    "    for result in results:\n",
    "        indexed_results.append((freq[result], result))\n",
    "        \n",
    "    indexed_results = sorted(indexed_results, key=lambda x: -x[0])\n",
    "    return [q[1] for q in indexed_results][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 Started ... Run 1 Ended\n",
      "Run 2 Started ... Run 2 Ended\n",
      "Run 3 Started ... Run 3 Ended\n",
      "Run 4 Started ... Run 4 Ended\n",
      "Run 5 Started ... Run 5 Ended\n",
      "Run 6 Started ... Run 6 Ended\n",
      "Run 7 Started ... Run 7 Ended\n",
      "Run 8 Started ... Run 8 Ended\n",
      "Run 9 Started ... Run 9 Ended\n",
      "Run 10 Started ... Run 10 Ended\n",
      "\n",
      "\n",
      "-+-+-+-+- With index -+-+-+-+-\n",
      "Avg of Avg times in 10 runs: 33.30709783380682\n",
      "Avg of Standard deviation in 10 runs: 92.71177075761953\n",
      "-+-+-+-+- Without index -+-+-+-+-\n",
      "Avg of Avg times in 10 runs: 4253.428506747159\n",
      "Avg of Standard deviation times in 10 runs: 88.89297017894665\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "index_runs_averges = []\n",
    "index_runs_standard_deviation = []\n",
    "no_index_runs_averages = []\n",
    "no_index_runs_standard_deviation = []\n",
    "\n",
    "index_times = []\n",
    "no_index_times = []\n",
    "def time_test(runs):\n",
    "    for i in range(runs):\n",
    "        print(f\"Run {i+1} Started ... \", end='')\n",
    "        for inp in inp_queries:\n",
    "            start = time.time() * 1000 #convert to milliseconds\n",
    "            _ = complete_user_query(inp, aol_trie)\n",
    "            end = time.time() * 1000 #convert to milliseconds\n",
    "            index_times.append(end - start)\n",
    "\n",
    "            start = time.time() * 1000 #convert to milliseconds\n",
    "            _ = complete_user_query_without_trie(inp, aol_data)\n",
    "            end = time.time() * 1000 #convert to milliseconds\n",
    "            no_index_times.append(end - start)\n",
    "        print(f\"Run {i+1} Ended\")\n",
    "        index_runs_averges.append(np.mean(index_times))\n",
    "        index_runs_standard_deviation.append(np.var(index_times) ** 0.5)\n",
    "        no_index_runs_averages.append(np.mean(no_index_times))\n",
    "        no_index_runs_standard_deviation.append(np.var(no_index_times) ** 0.5)\n",
    "\n",
    "#each run takes ~50 seconds\n",
    "num_runs = 10   \n",
    "time_test(num_runs)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-+-+-+-+- With index -+-+-+-+-\")\n",
    "print(f\"Avg of Avg times in {num_runs} runs: {np.mean(index_times)}\")\n",
    "print(f\"Avg of Standard deviation in {num_runs} runs: {np.var(index_times) ** 0.5}\")\n",
    "print(\"-+-+-+-+- Without index -+-+-+-+-\")\n",
    "print(f\"Avg of Avg times in {num_runs} runs: {np.mean(no_index_times)}\")\n",
    "print(f\"Avg of Standard deviation times in {num_runs} runs: {np.var(no_index_times) ** 0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [10] Add spellchecking to your suggest\n",
    "\n",
    "Try to make your search results as close as possible. Compare top-5 results of each query with top-5 results for corrected.\n",
    "\n",
    "You can use use [pyspellchecker](https://pypi.org/project/pyspellchecker/) `candidates()` call, or use any other spellchecker implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spellchecker as sc\n",
    "\n",
    "def complete_user_query_with_spellchecker(query, trie, top_k=5) -> list[str]:\n",
    "    results = []\n",
    "    words = query.split()\n",
    "    spell = sc.SpellChecker()\n",
    "    for i in range(len(words)):\n",
    "        for correction in spell.candidates(words[i]):\n",
    "            if words[i] == correction: # word is already correct\n",
    "                continue\n",
    "            words[i] = correction  # try that correction\n",
    "            res = complete_user_query(' '.join(words), trie, top_k)\n",
    "            if res:\n",
    "                results.append(res)\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    if results:\n",
    "        return results[0]\n",
    "    else: \n",
    "        return []\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inormation retrieval\", \"shelrock hol\", \"carnagie mell\", \"babis r\", \"Barrbara \"]\n",
    "inp_queries_corrected = [\"information retrieval\", \"sherlock hol\", \"carnegie mell\", \"babies r\", \"Barbara \"]\n",
    "\n",
    "for q, qc in zip(inp_queries, inp_queries_corrected):\n",
    "    assert  complete_user_query(qc, aol_trie, 5) == \\\n",
    "            complete_user_query_with_spellchecker(q, aol_trie, 5), \"Assert {} and {} give different results\".format(q, qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
