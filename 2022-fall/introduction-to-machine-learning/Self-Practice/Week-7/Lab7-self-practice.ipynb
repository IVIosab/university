{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-6 : Self-Practice\n",
    "\n",
    "In this week self-practice, you will implement a neural network model for a regression problem. You will use the [*admission*](./Admission_Predict.csv) dataset attached, used in the previous lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and do all the necessary preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create custom pytorch `Dataset`\n",
    "\n",
    "You should create a class `CustomDataset` that inherits  the abstract class `torch.utils.data.Dataset` from pytorch. \n",
    "\n",
    "> **Note** You should overwrite `__getitem__`, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite `__len__`, which is expected to return the size of the dataset by many `~torch.utils.data.Sampler` implementations and the default options of `~torch.utils.data.DataLoader`.\n",
    "\n",
    "#### Split your dataset into train and test data loaders\n",
    "You can create a `CustomDataset` instance with the entire dataframe and use [`random_split`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) to split it into training and testing datasets. And then, create test and train dataloader. Or you can split using `train_test_split` from sklearn and past the splitted sets to your Custom dataset class. \n",
    "\n",
    "Create train and test dataloader with `batch_size = 32` each complete the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustumData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        #initaliaze the variable\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the len of the dataset\n",
    "        pass \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # return a tuple samples and labels with the corresponding index idx\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_dataset = CustumData(X_train, y_train)\n",
    "test_dataset = CustumData(X_test, y_test) \n",
    "\n",
    "# Create the dataloaders\n",
    "train_dataloader = None\n",
    "test_dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = next(iter(train_dataloader))\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the model\n",
    "\n",
    "Using `nn`, Create a neural network with 1 hidden layers of size 100, each must be followed by a `leaky_relu` activation function and define the forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# complete the code\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_hidden_unit = 100):\n",
    "        super(Net, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net(n_hidden_unit = 100).to(device)\n",
    "#model = nn.Sequential(nn.Linear(7, 1)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training loop\n",
    "\n",
    "Define the appropriate loss function and the training loop for the training and the testing dataloader (as done in the lab). Use SGD optimizer with learning rate 0.01 and momentum 0.5\n",
    "\n",
    "Print the final loss on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare your Neural network model to a Linear Regression\n",
    "Train a simple linear regression model on the training set and print MSE on the testing set (`X_test`). Also print the MSE on the test set using the your neural model. \n",
    "\n",
    "> Compare the results (which performs best) and justify why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
